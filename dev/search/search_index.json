{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Fides Ecosystem Fides (pronounced /fee-dhez/ , from Latin: Fid\u0113s) is an open-source privacy engineering platform for managing the fulfillment of data privacy requests in your runtime environment, and the enforcement of privacy regulations in your code. The Fides developer tools allow engineers and legal teams to label system privacy characteristics, orchestrate programmatic rights fulfillment, and audit stored personal identifiable information (PII) throughout application systems and infrastructure. This includes support for major privacy regulations (e.g. GDPR , CCPA and LGPD ), and standards like ISO 19944 by default. Key Features Privacy-as-Code Fides' extensible description language allows you to describe your datasets and code in human-readable manifest files. Create a consistent, versioned definition of your system's privacy characteristics and resources for use in your CI/CD pipeline , when processing privacy requests , or in the Fides UI . Compliance-minded Data Mapping Export a data map of your connected databases and services, or run an audit of your resources to generate an Article 30-compliant Record of Processing Activities (RoPA). Programmable Data Privacy When your organization receives a privacy request, Fides will automatically fulfill it according to the execution policies your legal and business owners have created. Fides orchestrates connections to both your owned databases and third-party systems to access, update, and delete sensitive data. Third-Party Integrations Fides' core services are open source and extensible. Integrate Fides into your existing privacy compliance management tools like OneTrust to fulfill data subject requests and return results, automatically. Comprehensive Privacy Standard Support The default 'efficiently describe the privacy behaviors of your system for major regulations, including GDPR , CCPA and LGPD as well as major standards like ISO 19944 . Why is it called Fides? Fides was the goddess of trust and good faith in Roman paganism. Fides represented everything that was required for \"honor and credibility\" in every aspect of Roman life. In addition to this, Fides means \"reliability\": reliability between two parties, which is always reciprocal . Fides stood out for her embodiment of this project's philosophy - to provide developers with a powerful tool to make privacy a default feature of any software. If you'd like a brief Roman mythology lesson, check out Fides on Wikipedia .","title":"What is Fides?"},{"location":"#the-fides-ecosystem","text":"Fides (pronounced /fee-dhez/ , from Latin: Fid\u0113s) is an open-source privacy engineering platform for managing the fulfillment of data privacy requests in your runtime environment, and the enforcement of privacy regulations in your code. The Fides developer tools allow engineers and legal teams to label system privacy characteristics, orchestrate programmatic rights fulfillment, and audit stored personal identifiable information (PII) throughout application systems and infrastructure. This includes support for major privacy regulations (e.g. GDPR , CCPA and LGPD ), and standards like ISO 19944 by default.","title":"The Fides Ecosystem"},{"location":"#key-features","text":"","title":"Key Features"},{"location":"#privacy-as-code","text":"Fides' extensible description language allows you to describe your datasets and code in human-readable manifest files. Create a consistent, versioned definition of your system's privacy characteristics and resources for use in your CI/CD pipeline , when processing privacy requests , or in the Fides UI .","title":"Privacy-as-Code"},{"location":"#compliance-minded-data-mapping","text":"Export a data map of your connected databases and services, or run an audit of your resources to generate an Article 30-compliant Record of Processing Activities (RoPA).","title":"Compliance-minded Data Mapping"},{"location":"#programmable-data-privacy","text":"When your organization receives a privacy request, Fides will automatically fulfill it according to the execution policies your legal and business owners have created. Fides orchestrates connections to both your owned databases and third-party systems to access, update, and delete sensitive data.","title":"Programmable Data Privacy"},{"location":"#third-party-integrations","text":"Fides' core services are open source and extensible. Integrate Fides into your existing privacy compliance management tools like OneTrust to fulfill data subject requests and return results, automatically.","title":"Third-Party Integrations"},{"location":"#comprehensive-privacy-standard-support","text":"The default 'efficiently describe the privacy behaviors of your system for major regulations, including GDPR , CCPA and LGPD as well as major standards like ISO 19944 .","title":"Comprehensive Privacy Standard Support"},{"location":"#why-is-it-called-fides","text":"Fides was the goddess of trust and good faith in Roman paganism. Fides represented everything that was required for \"honor and credibility\" in every aspect of Roman life. In addition to this, Fides means \"reliability\": reliability between two parties, which is always reciprocal . Fides stood out for her embodiment of this project's philosophy - to provide developers with a powerful tool to make privacy a default feature of any software. If you'd like a brief Roman mythology lesson, check out Fides on Wikipedia .","title":"Why is it called Fides?"},{"location":"cicd/","text":"CI/CD Overview Fides provides a CLI for integrating with your existing CI pipeline configurations. These commands are designed to help evaluate code changes against defined Fides Policies , and flag developers in advance if any updates or merges are no longer in compliance. Implementation To integrate Fides with your CI pipeline, you should plan to implement at least two commands in your CI actions: fides evaluate --dry <resource_dir> evaluate --dry checks if code changes will be accepted without pushing those changes to the Fides server. Run this against the latest commit on code changesets (pull requests, merge requests, etc). fides evaluate <resource_dir> evaluate synchronizes the latest changes to the Fides server. Run this against commits representing merges into the default branch to keep your server in sync. Example Integrations The following code snippets are meant as simple example implementations, and illustrate Fides can integrate with various popular CI pipeline tools. They are not designed for immediate production use. Always inspect, understand, and test your production CI configuration files. GitHub Actions .github/workflows/fides_ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 name : Fides CI # Only check on Pull Requests that target main on : pull_request : branches : - main paths : # Only run checks when the resource files change or the workflow file changes - .fides/** - .github/workflows/fides_ci.yml jobs : fides_ci : runs-on : ubuntu-latest container : image : ethyca/fides:latest steps : - name : Dry Evaluation uses : actions/checkout@v2 run : fides evaluate --dry .fides/ env : FIDES__CLI__SERVER_HOST : \"fides.privacyco.com\" .github/workflows/fides_cd.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 name : Fides CD # Run the check every time a new commit hits the default branch on : push : branches : - main tags : - \"*\" jobs : fides_cd : runs-on : ubuntu-latest container : image : ethyca/fides:latest steps : - name : Evaluation uses : actions/checkout@v2 run : fides evaluate .fides/ env : FIDES__CLI__SERVER_HOST : \"fides.privacyco.com\" GitLab CI .gitlab-ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 stages : - test - deploy variables : &global-variables FIDES__CLI__SERVER_HOST : \"fides.privacyco.com\" fides-ci : stage : test image : ethyca/fides script : fides evaluate --dry .fides/ only : if : '$CI_PIPELINE_SOURCE = merge_request_event' changes : - .fides/** - .gitlab-ci.yml variables : << : *global-variables fides-cd : stage : deploy image : ethyca/fides script : fides evaluate .fides/ if : '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH' variables : << : *global-variables Jenkins Jenkinsfile (Declarative Syntax) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 pipeline { agent { docker { image 'ethyca/fides:latest' } } stages { stage ( 'test' ){ environment { FIDES__CLI__SERVER_HOST: 'fides.privacyco.com' } steps { sh 'fides evaluate --dry .fides/' } when { anyOf { changeset '.fides/**' changeset 'Jenkinsfile' } changeRequest () } } stage ( 'deploy' ) { environment { FIDES__CLI__SERVER_HOST: 'fides.privacyco.com' } steps { sh 'fides evaluate .fides/' } when { branch 'main' } } } } CircleCI .circleci/config.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 version : 2.1 executors : fides : docker : - image : ethyca/fides:latest environment : FIDES__CLI__SERVER_HOST : 'fides.privacyco.com' jobs : fides-evaluate-dry : executor : fides steps : - run : fides evaluate --dry .fides/ fides-evaluate : executor : fides steps : - run : fides evaluate .fides/ workflows : version : 2 test : jobs : - fides-evaluate-dry : filters : branches : ignore : main deploy : jobs : - fides-evaluate : filters : branches : only : main Azure Pipelines .azure-pipelines.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # Trigger a dry run of the evaluate job on pull requests that target main pr : - main jobs : - job : \"fides_evaluate_dry\" pool : vmImage : ubuntu-latest container : image : ethyca/fides:latest steps : - checkout : self - script : fides evaluate --dry .fides/ displayName : \"Fides Dry Evaluation\" # Trigger the evaluate job on commits to the default branch trigger : - main jobs : - job : \"fides_evaluate\" pool : vmImage : ubuntu-latest container : image : ethyca/fides:latest steps : - checkout : self - script : fides evaluate .fides/ displayName : \"Fides Evaluation\"","title":"CI/CD Integrations"},{"location":"cicd/#cicd-overview","text":"Fides provides a CLI for integrating with your existing CI pipeline configurations. These commands are designed to help evaluate code changes against defined Fides Policies , and flag developers in advance if any updates or merges are no longer in compliance.","title":"CI/CD Overview"},{"location":"cicd/#implementation","text":"To integrate Fides with your CI pipeline, you should plan to implement at least two commands in your CI actions: fides evaluate --dry <resource_dir> evaluate --dry checks if code changes will be accepted without pushing those changes to the Fides server. Run this against the latest commit on code changesets (pull requests, merge requests, etc). fides evaluate <resource_dir> evaluate synchronizes the latest changes to the Fides server. Run this against commits representing merges into the default branch to keep your server in sync.","title":"Implementation"},{"location":"cicd/#example-integrations","text":"The following code snippets are meant as simple example implementations, and illustrate Fides can integrate with various popular CI pipeline tools. They are not designed for immediate production use. Always inspect, understand, and test your production CI configuration files.","title":"Example Integrations"},{"location":"cicd/#github-actions","text":".github/workflows/fides_ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 name : Fides CI # Only check on Pull Requests that target main on : pull_request : branches : - main paths : # Only run checks when the resource files change or the workflow file changes - .fides/** - .github/workflows/fides_ci.yml jobs : fides_ci : runs-on : ubuntu-latest container : image : ethyca/fides:latest steps : - name : Dry Evaluation uses : actions/checkout@v2 run : fides evaluate --dry .fides/ env : FIDES__CLI__SERVER_HOST : \"fides.privacyco.com\" .github/workflows/fides_cd.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 name : Fides CD # Run the check every time a new commit hits the default branch on : push : branches : - main tags : - \"*\" jobs : fides_cd : runs-on : ubuntu-latest container : image : ethyca/fides:latest steps : - name : Evaluation uses : actions/checkout@v2 run : fides evaluate .fides/ env : FIDES__CLI__SERVER_HOST : \"fides.privacyco.com\"","title":"GitHub Actions"},{"location":"cicd/#gitlab-ci","text":".gitlab-ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 stages : - test - deploy variables : &global-variables FIDES__CLI__SERVER_HOST : \"fides.privacyco.com\" fides-ci : stage : test image : ethyca/fides script : fides evaluate --dry .fides/ only : if : '$CI_PIPELINE_SOURCE = merge_request_event' changes : - .fides/** - .gitlab-ci.yml variables : << : *global-variables fides-cd : stage : deploy image : ethyca/fides script : fides evaluate .fides/ if : '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH' variables : << : *global-variables","title":"GitLab CI"},{"location":"cicd/#jenkins","text":"Jenkinsfile (Declarative Syntax) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 pipeline { agent { docker { image 'ethyca/fides:latest' } } stages { stage ( 'test' ){ environment { FIDES__CLI__SERVER_HOST: 'fides.privacyco.com' } steps { sh 'fides evaluate --dry .fides/' } when { anyOf { changeset '.fides/**' changeset 'Jenkinsfile' } changeRequest () } } stage ( 'deploy' ) { environment { FIDES__CLI__SERVER_HOST: 'fides.privacyco.com' } steps { sh 'fides evaluate .fides/' } when { branch 'main' } } } }","title":"Jenkins"},{"location":"cicd/#circleci","text":".circleci/config.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 version : 2.1 executors : fides : docker : - image : ethyca/fides:latest environment : FIDES__CLI__SERVER_HOST : 'fides.privacyco.com' jobs : fides-evaluate-dry : executor : fides steps : - run : fides evaluate --dry .fides/ fides-evaluate : executor : fides steps : - run : fides evaluate .fides/ workflows : version : 2 test : jobs : - fides-evaluate-dry : filters : branches : ignore : main deploy : jobs : - fides-evaluate : filters : branches : only : main","title":"CircleCI"},{"location":"cicd/#azure-pipelines","text":".azure-pipelines.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # Trigger a dry run of the evaluate job on pull requests that target main pr : - main jobs : - job : \"fides_evaluate_dry\" pool : vmImage : ubuntu-latest container : image : ethyca/fides:latest steps : - checkout : self - script : fides evaluate --dry .fides/ displayName : \"Fides Dry Evaluation\" # Trigger the evaluate job on commits to the default branch trigger : - main jobs : - job : \"fides_evaluate\" pool : vmImage : ubuntu-latest container : image : ethyca/fides:latest steps : - checkout : self - script : fides evaluate .fides/ displayName : \"Fides Evaluation\"","title":"Azure Pipelines"},{"location":"cli/","text":"CLI These docs reflect the latest PyPI release. fides 1 The parent group for the Fides CLI. Usage: 1 fides [OPTIONS] COMMAND [ARGS]... Options: 1 2 3 4 5 6 7 8 --version Show the version and exit. -f, --config-path TEXT Path to a configuration file. Use 'fides view- config' to print the config. Not compatible with the 'fides webserver' subcommand. --local Run in 'local_mode'. This mode doesn't make API calls and can be used without the API server/database. --help Show this message and exit. fides annotate 1 Annotate fides resource types Usage: 1 fides annotate [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides annotate dataset 1 Guided flow for annotating datasets. The dataset file will be edited in-place. Usage: 1 fides annotate dataset [OPTIONS] INPUT_FILENAME Options: 1 2 3 -a, --all-members Annotate all dataset members, not just fields -v, --validate Strictly validate annotation inputs. --help Show this message and exit. fides db 1 Database utility commands Usage: 1 fides db [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides db init 1 Initialize the fides database. Usage: 1 fides db init [OPTIONS] Options: 1 --help Show this message and exit. fides db reset 1 Wipes all user-created data and resets the database back to its freshly initialized state. Usage: 1 fides db reset [OPTIONS] Options: 1 2 -y, --yes Automatically responds 'yes' to any prompts. --help Show this message and exit. fides delete 1 Delete a resource on the server. Usage: 1 2 fides delete [OPTIONS] {data_category|data_qualifier|data_subject|data_use|dat aset|organization|policy|registry|system|evaluation} FIDES_KEY Options: 1 --help Show this message and exit. fides evaluate 1 2 3 4 5 6 Compare your System's Privacy Declarations with your Organization's Policy Rules. All local resources are applied to the server before evaluation. If your policy evaluation fails, it is expected that you will need to either adjust your Privacy Declarations, Datasets, or Policies before trying again. Usage: 1 fides evaluate [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 5 6 7 8 -k, --fides-key TEXT The fides_key of the single policy that you wish to evaluate. -m, --message TEXT A message that you can supply to describe the context of this evaluation. -a, --audit Raise errors if resources are missing attributes required for building a data map. --dry Prevent the persistance of any changes. --help Show this message and exit. fides export 1 Export fides resource types Usage: 1 fides export [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides export datamap 1 2 3 4 5 6 7 8 9 10 11 Export a formatted data map to excel using the fides template. The data map is comprised of an Organization, Systems, and Datasets. The default organization is used, however a custom one can be passed if required. A custom manifest directory can be provided for the output location. The csv flag can be used to output data as csv, while the dry flag can be used to return data to the console instead. Usage: 1 fides export datamap [OPTIONS] Options: 1 2 3 4 5 6 7 -d, --output-dir TEXT The output directory for the data map to be exported to. -k, --org-key TEXT The organization_fides_key you wish to export resources for. --dry Prevent the persistance of any changes. --csv Export using csv format --help Show this message and exit. fides export dataset 1 Export a dataset in a data map format. Usage: 1 fides export dataset [OPTIONS] [MANIFESTS_DIR] Options: 1 2 --dry Prevent the persistance of any changes. --help Show this message and exit. fides export organization 1 Export an organization in a data map format. Usage: 1 fides export organization [OPTIONS] [MANIFESTS_DIR] Options: 1 2 --dry Prevent the persistance of any changes. --help Show this message and exit. fides export system 1 Export a system in a data map format. Usage: 1 fides export system [OPTIONS] [MANIFESTS_DIR] Options: 1 2 --dry Prevent the persistance of any changes. --help Show this message and exit. fides generate 1 Generate fides resource types Usage: 1 fides generate [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides generate dataset 1 Generate fides Dataset resources Usage: 1 fides generate dataset [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides generate dataset db 1 2 3 4 5 6 7 Connect to a database directly via a SQLAlchemy-style connection string and generate a dataset manifest file that consists of every schema/table/field. Connection string can be supplied as an option or a credentials reference to fides config. This is a one-time operation that does not track the state of the database. It will need to be run again if the database schema changes. Usage: 1 fides generate dataset db [OPTIONS] OUTPUT_FILENAME Options: 1 2 3 4 5 --credentials-id TEXT Use credentials defined within fides config --connection-string TEXT Use connection string option to connect to a database --include-null Includes attributes that would otherwise be null. --help Show this message and exit. fides generate dataset gcp 1 Generate fides Dataset resources for Google Cloud Platform Usage: 1 fides generate dataset gcp [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides generate dataset gcp bigquery 1 2 3 4 5 6 7 Connect to a BigQuery dataset directly via a SQLAlchemy connection and generate a dataset manifest file that consists of every schema/table/field. A path to a google authorization keyfile can be supplied as an option, or a credentials reference to fides config. This is a one-time operation that does not track the state of the dataset. It will need to be run again if the dataset schema changes. Usage: 1 fides generate dataset gcp bigquery [OPTIONS] DATASET_NAME OUTPUT_FILENAME Options: 1 2 3 4 --credentials-id TEXT Use credentials defined within fides config --keyfile-path TEXT --include-null Includes attributes that would otherwise be null. --help Show this message and exit. fides generate system 1 Generate fides System resources Usage: 1 fides generate system [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides generate system aws 1 2 3 4 5 6 7 8 Connect to an aws account and generate a system manifest file that consists of every tracked resource. Credentials can be supplied as options, a credentials reference to fides config, or boto3 environment configuration. Tracked resources: [Redshift, RDS, DynamoDb, S3] This is a one-time operation that does not track the state of the aws resources. It will need to be run again if the tracked resources change. Usage: 1 fides generate system aws [OPTIONS] OUTPUT_FILENAME Options: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 --credentials-id TEXT Use credentials defined within fides config --access_key_id TEXT Use access key id option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --secret_access_key TEXT Use access key option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --region TEXT Use region option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --include-null Includes attributes that would otherwise be null. -k, --org-key TEXT The organization_fides_key you wish to export resources for. --help Show this message and exit. fides generate system okta 1 2 3 4 5 6 7 Generates systems for your Okta applications. Connect to an Okta admin account by providing an organization url and auth token or a credentials reference to fides config. Auth token and organization url can also be supplied by setting environment variables as defined by the okta python sdk. This is a one-time operation that does not track the state of the okta resources. It will need to be run again if the tracked resources change. Usage: 1 fides generate system okta [OPTIONS] OUTPUT_FILENAME Options: 1 2 3 4 5 6 7 8 9 --credentials-id TEXT Use credentials defined within fides config --org-url TEXT Use org url option to connect to okta. Requires options --org-url and --token --token TEXT Use token option to connect to okta. Requires options --org-url and --token --include-null Includes attributes that would otherwise be null. -k, --org-key TEXT The organization_fides_key you wish to export resources for. --help Show this message and exit. fides get 1 View a resource from the server as a JSON object. Usage: 1 2 fides get [OPTIONS] {data_category|data_qualifier|data_subject|data_use|datase t|organization|policy|registry|system|evaluation} FIDES_KEY Options: 1 --help Show this message and exit. fides init 1 2 3 4 Initializes a fides instance, creating the default directory (`.fides/`) and the configuration file (`fides.toml`) if necessary. Additionally, requests the ability to respectfully collect anonymous usage data. Usage: 1 fides init [OPTIONS] [FIDES_DIRECTORY_LOCATION] Options: 1 --help Show this message and exit. fides ls 1 Get a list of all resources of this type from the server and display them as JSON. Usage: 1 2 fides ls [OPTIONS] {data_category|data_qualifier|data_subject|data_use|dataset |organization|policy|registry|system|evaluation} Options: 1 --help Show this message and exit. fides parse 1 2 3 4 Reads the resource files that are stored in MANIFESTS_DIR and its subdirectories to verify the validity of all manifest files. If the taxonomy is invalid, this command prints the error messages and triggers a non-zero exit code. Usage: 1 fides parse [OPTIONS] [MANIFESTS_DIR] Options: 1 2 -v, --verbose Enable verbose output. --help Show this message and exit. fides pull 1 2 3 4 5 6 Update local resource files by their fides_key to match their server versions. Alternatively, with the \"--all\" flag all resources from the server will be pulled down into a local file. The pull is aborted if there are unstaged or untracked files in the manifests dir. Usage: 1 fides pull [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 -a, --all-resources TEXT Pulls all locally missing resources from the server into this file. --help Show this message and exit. fides push 1 Validate local manifest files and persist any changes via the API server. Usage: 1 fides push [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 --dry Prevent the persistance of any changes. --diff Include any changes between server and local resources in the command output --help Show this message and exit. fides scan 1 Scan external resource coverage against fides resources Usage: 1 fides scan [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides scan dataset 1 Scan fides Dataset resources Usage: 1 fides scan dataset [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides scan dataset db 1 2 3 4 5 6 7 8 9 Connect to a database directly via a SQLAlchemy-style connection string and compare the database objects to existing datasets. Connection string can be supplied as an option or a credentials reference to fides config. If there are fields within the database that aren't listed and categorized within one of the datasets, this counts as lacking coverage. Outputs missing fields and has a non-zero exit if coverage is under the stated threshold. Usage: 1 fides scan dataset db [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 5 6 --credentials-id TEXT Use credentials defined within fides config --connection-string TEXT Use connection string option to connect to a database -c, --coverage-threshold INTEGER RANGE [0<=x<=100] --help Show this message and exit. fides scan system 1 Scan fides System resources Usage: 1 fides scan system [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides scan system aws 1 2 3 4 5 6 7 Connect to an aws account and compares tracked resources to existing systems. Credentials can be supplied as options, a credentials reference to fides config, or boto3 environment configuration. Tracked resources: [Redshift, RDS, DynamoDb, S3] Outputs missing resources and has a non-zero exit if coverage is under the stated threshold. Usage: 1 fides scan system aws [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 --credentials-id TEXT Use credentials defined within fides config --access_key_id TEXT Use access key id option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --secret_access_key TEXT Use access key option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --region TEXT Use region option to connect to aws. Requires options --access_key_id, --secret_access_key and --region -k, --org-key TEXT The organization_fides_key you wish to export resources for. -c, --coverage-threshold INTEGER RANGE [0<=x<=100] --help Show this message and exit. fides scan system okta 1 2 3 4 5 6 7 8 Scans your existing systems and compares them to found Okta applications. Connect to an Okta admin account by providing an organization url and auth token or a credentials reference to fides config. Auth token and organization url can also be supplied by setting environment variables as defined by the okta python sdk. Outputs missing resources and has a non-zero exit if coverage is under the stated threshold. Usage: 1 fides scan system okta [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 5 6 7 8 9 10 --credentials-id TEXT Use credentials defined within fides config --org-url TEXT Use org url option to connect to okta. Requires options --org-url and --token --token TEXT Use token option to connect to okta. Requires options --org-url and --token -k, --org-key TEXT The organization_fides_key you wish to export resources for. -c, --coverage-threshold INTEGER RANGE [0<=x<=100] --help Show this message and exit. fides status 1 Sends a request to the fides API healthcheck endpoint and prints the response. Usage: 1 fides status [OPTIONS] Options: 1 --help Show this message and exit. fides view 1 View various resources types. Usage: 1 fides view [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit. fides view config 1 2 3 4 Prints the fides configuration values. To only view a specific section of the config, supply the section name as an argument. Usage: 1 fides view config [OPTIONS] [SECTION] Options: 1 2 --exclude-unset Only print configuration values explicitly set by the user. --help Show this message and exit. fides webserver 1 Starts the fides API server using Uvicorn on port 8080. Usage: 1 fides webserver [OPTIONS] Options: 1 --help Show this message and exit. fides worker 1 Starts a celery worker. Usage: 1 fides worker [OPTIONS] Options: 1 --help Show this message and exit.","title":"CLI"},{"location":"cli/#cli","text":"These docs reflect the latest PyPI release.","title":"CLI"},{"location":"cli/#fides","text":"1 The parent group for the Fides CLI. Usage: 1 fides [OPTIONS] COMMAND [ARGS]... Options: 1 2 3 4 5 6 7 8 --version Show the version and exit. -f, --config-path TEXT Path to a configuration file. Use 'fides view- config' to print the config. Not compatible with the 'fides webserver' subcommand. --local Run in 'local_mode'. This mode doesn't make API calls and can be used without the API server/database. --help Show this message and exit.","title":"fides"},{"location":"cli/#fides-annotate","text":"1 Annotate fides resource types Usage: 1 fides annotate [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"annotate"},{"location":"cli/#fides-annotate-dataset","text":"1 Guided flow for annotating datasets. The dataset file will be edited in-place. Usage: 1 fides annotate dataset [OPTIONS] INPUT_FILENAME Options: 1 2 3 -a, --all-members Annotate all dataset members, not just fields -v, --validate Strictly validate annotation inputs. --help Show this message and exit.","title":"dataset"},{"location":"cli/#fides-db","text":"1 Database utility commands Usage: 1 fides db [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"db"},{"location":"cli/#fides-db-init","text":"1 Initialize the fides database. Usage: 1 fides db init [OPTIONS] Options: 1 --help Show this message and exit.","title":"init"},{"location":"cli/#fides-db-reset","text":"1 Wipes all user-created data and resets the database back to its freshly initialized state. Usage: 1 fides db reset [OPTIONS] Options: 1 2 -y, --yes Automatically responds 'yes' to any prompts. --help Show this message and exit.","title":"reset"},{"location":"cli/#fides-delete","text":"1 Delete a resource on the server. Usage: 1 2 fides delete [OPTIONS] {data_category|data_qualifier|data_subject|data_use|dat aset|organization|policy|registry|system|evaluation} FIDES_KEY Options: 1 --help Show this message and exit.","title":"delete"},{"location":"cli/#fides-evaluate","text":"1 2 3 4 5 6 Compare your System's Privacy Declarations with your Organization's Policy Rules. All local resources are applied to the server before evaluation. If your policy evaluation fails, it is expected that you will need to either adjust your Privacy Declarations, Datasets, or Policies before trying again. Usage: 1 fides evaluate [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 5 6 7 8 -k, --fides-key TEXT The fides_key of the single policy that you wish to evaluate. -m, --message TEXT A message that you can supply to describe the context of this evaluation. -a, --audit Raise errors if resources are missing attributes required for building a data map. --dry Prevent the persistance of any changes. --help Show this message and exit.","title":"evaluate"},{"location":"cli/#fides-export","text":"1 Export fides resource types Usage: 1 fides export [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"export"},{"location":"cli/#fides-export-datamap","text":"1 2 3 4 5 6 7 8 9 10 11 Export a formatted data map to excel using the fides template. The data map is comprised of an Organization, Systems, and Datasets. The default organization is used, however a custom one can be passed if required. A custom manifest directory can be provided for the output location. The csv flag can be used to output data as csv, while the dry flag can be used to return data to the console instead. Usage: 1 fides export datamap [OPTIONS] Options: 1 2 3 4 5 6 7 -d, --output-dir TEXT The output directory for the data map to be exported to. -k, --org-key TEXT The organization_fides_key you wish to export resources for. --dry Prevent the persistance of any changes. --csv Export using csv format --help Show this message and exit.","title":"datamap"},{"location":"cli/#fides-export-dataset","text":"1 Export a dataset in a data map format. Usage: 1 fides export dataset [OPTIONS] [MANIFESTS_DIR] Options: 1 2 --dry Prevent the persistance of any changes. --help Show this message and exit.","title":"dataset"},{"location":"cli/#fides-export-organization","text":"1 Export an organization in a data map format. Usage: 1 fides export organization [OPTIONS] [MANIFESTS_DIR] Options: 1 2 --dry Prevent the persistance of any changes. --help Show this message and exit.","title":"organization"},{"location":"cli/#fides-export-system","text":"1 Export a system in a data map format. Usage: 1 fides export system [OPTIONS] [MANIFESTS_DIR] Options: 1 2 --dry Prevent the persistance of any changes. --help Show this message and exit.","title":"system"},{"location":"cli/#fides-generate","text":"1 Generate fides resource types Usage: 1 fides generate [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"generate"},{"location":"cli/#fides-generate-dataset","text":"1 Generate fides Dataset resources Usage: 1 fides generate dataset [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"dataset"},{"location":"cli/#fides-generate-dataset-db","text":"1 2 3 4 5 6 7 Connect to a database directly via a SQLAlchemy-style connection string and generate a dataset manifest file that consists of every schema/table/field. Connection string can be supplied as an option or a credentials reference to fides config. This is a one-time operation that does not track the state of the database. It will need to be run again if the database schema changes. Usage: 1 fides generate dataset db [OPTIONS] OUTPUT_FILENAME Options: 1 2 3 4 5 --credentials-id TEXT Use credentials defined within fides config --connection-string TEXT Use connection string option to connect to a database --include-null Includes attributes that would otherwise be null. --help Show this message and exit.","title":"db"},{"location":"cli/#fides-generate-dataset-gcp","text":"1 Generate fides Dataset resources for Google Cloud Platform Usage: 1 fides generate dataset gcp [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"gcp"},{"location":"cli/#fides-generate-dataset-gcp-bigquery","text":"1 2 3 4 5 6 7 Connect to a BigQuery dataset directly via a SQLAlchemy connection and generate a dataset manifest file that consists of every schema/table/field. A path to a google authorization keyfile can be supplied as an option, or a credentials reference to fides config. This is a one-time operation that does not track the state of the dataset. It will need to be run again if the dataset schema changes. Usage: 1 fides generate dataset gcp bigquery [OPTIONS] DATASET_NAME OUTPUT_FILENAME Options: 1 2 3 4 --credentials-id TEXT Use credentials defined within fides config --keyfile-path TEXT --include-null Includes attributes that would otherwise be null. --help Show this message and exit.","title":"bigquery"},{"location":"cli/#fides-generate-system","text":"1 Generate fides System resources Usage: 1 fides generate system [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"system"},{"location":"cli/#fides-generate-system-aws","text":"1 2 3 4 5 6 7 8 Connect to an aws account and generate a system manifest file that consists of every tracked resource. Credentials can be supplied as options, a credentials reference to fides config, or boto3 environment configuration. Tracked resources: [Redshift, RDS, DynamoDb, S3] This is a one-time operation that does not track the state of the aws resources. It will need to be run again if the tracked resources change. Usage: 1 fides generate system aws [OPTIONS] OUTPUT_FILENAME Options: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 --credentials-id TEXT Use credentials defined within fides config --access_key_id TEXT Use access key id option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --secret_access_key TEXT Use access key option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --region TEXT Use region option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --include-null Includes attributes that would otherwise be null. -k, --org-key TEXT The organization_fides_key you wish to export resources for. --help Show this message and exit.","title":"aws"},{"location":"cli/#fides-generate-system-okta","text":"1 2 3 4 5 6 7 Generates systems for your Okta applications. Connect to an Okta admin account by providing an organization url and auth token or a credentials reference to fides config. Auth token and organization url can also be supplied by setting environment variables as defined by the okta python sdk. This is a one-time operation that does not track the state of the okta resources. It will need to be run again if the tracked resources change. Usage: 1 fides generate system okta [OPTIONS] OUTPUT_FILENAME Options: 1 2 3 4 5 6 7 8 9 --credentials-id TEXT Use credentials defined within fides config --org-url TEXT Use org url option to connect to okta. Requires options --org-url and --token --token TEXT Use token option to connect to okta. Requires options --org-url and --token --include-null Includes attributes that would otherwise be null. -k, --org-key TEXT The organization_fides_key you wish to export resources for. --help Show this message and exit.","title":"okta"},{"location":"cli/#fides-get","text":"1 View a resource from the server as a JSON object. Usage: 1 2 fides get [OPTIONS] {data_category|data_qualifier|data_subject|data_use|datase t|organization|policy|registry|system|evaluation} FIDES_KEY Options: 1 --help Show this message and exit.","title":"get"},{"location":"cli/#fides-init","text":"1 2 3 4 Initializes a fides instance, creating the default directory (`.fides/`) and the configuration file (`fides.toml`) if necessary. Additionally, requests the ability to respectfully collect anonymous usage data. Usage: 1 fides init [OPTIONS] [FIDES_DIRECTORY_LOCATION] Options: 1 --help Show this message and exit.","title":"init"},{"location":"cli/#fides-ls","text":"1 Get a list of all resources of this type from the server and display them as JSON. Usage: 1 2 fides ls [OPTIONS] {data_category|data_qualifier|data_subject|data_use|dataset |organization|policy|registry|system|evaluation} Options: 1 --help Show this message and exit.","title":"ls"},{"location":"cli/#fides-parse","text":"1 2 3 4 Reads the resource files that are stored in MANIFESTS_DIR and its subdirectories to verify the validity of all manifest files. If the taxonomy is invalid, this command prints the error messages and triggers a non-zero exit code. Usage: 1 fides parse [OPTIONS] [MANIFESTS_DIR] Options: 1 2 -v, --verbose Enable verbose output. --help Show this message and exit.","title":"parse"},{"location":"cli/#fides-pull","text":"1 2 3 4 5 6 Update local resource files by their fides_key to match their server versions. Alternatively, with the \"--all\" flag all resources from the server will be pulled down into a local file. The pull is aborted if there are unstaged or untracked files in the manifests dir. Usage: 1 fides pull [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 -a, --all-resources TEXT Pulls all locally missing resources from the server into this file. --help Show this message and exit.","title":"pull"},{"location":"cli/#fides-push","text":"1 Validate local manifest files and persist any changes via the API server. Usage: 1 fides push [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 --dry Prevent the persistance of any changes. --diff Include any changes between server and local resources in the command output --help Show this message and exit.","title":"push"},{"location":"cli/#fides-scan","text":"1 Scan external resource coverage against fides resources Usage: 1 fides scan [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"scan"},{"location":"cli/#fides-scan-dataset","text":"1 Scan fides Dataset resources Usage: 1 fides scan dataset [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"dataset"},{"location":"cli/#fides-scan-dataset-db","text":"1 2 3 4 5 6 7 8 9 Connect to a database directly via a SQLAlchemy-style connection string and compare the database objects to existing datasets. Connection string can be supplied as an option or a credentials reference to fides config. If there are fields within the database that aren't listed and categorized within one of the datasets, this counts as lacking coverage. Outputs missing fields and has a non-zero exit if coverage is under the stated threshold. Usage: 1 fides scan dataset db [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 5 6 --credentials-id TEXT Use credentials defined within fides config --connection-string TEXT Use connection string option to connect to a database -c, --coverage-threshold INTEGER RANGE [0<=x<=100] --help Show this message and exit.","title":"db"},{"location":"cli/#fides-scan-system","text":"1 Scan fides System resources Usage: 1 fides scan system [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"system"},{"location":"cli/#fides-scan-system-aws","text":"1 2 3 4 5 6 7 Connect to an aws account and compares tracked resources to existing systems. Credentials can be supplied as options, a credentials reference to fides config, or boto3 environment configuration. Tracked resources: [Redshift, RDS, DynamoDb, S3] Outputs missing resources and has a non-zero exit if coverage is under the stated threshold. Usage: 1 fides scan system aws [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 --credentials-id TEXT Use credentials defined within fides config --access_key_id TEXT Use access key id option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --secret_access_key TEXT Use access key option to connect to aws. Requires options --access_key_id, --secret_access_key and --region --region TEXT Use region option to connect to aws. Requires options --access_key_id, --secret_access_key and --region -k, --org-key TEXT The organization_fides_key you wish to export resources for. -c, --coverage-threshold INTEGER RANGE [0<=x<=100] --help Show this message and exit.","title":"aws"},{"location":"cli/#fides-scan-system-okta","text":"1 2 3 4 5 6 7 8 Scans your existing systems and compares them to found Okta applications. Connect to an Okta admin account by providing an organization url and auth token or a credentials reference to fides config. Auth token and organization url can also be supplied by setting environment variables as defined by the okta python sdk. Outputs missing resources and has a non-zero exit if coverage is under the stated threshold. Usage: 1 fides scan system okta [OPTIONS] [MANIFESTS_DIR] Options: 1 2 3 4 5 6 7 8 9 10 --credentials-id TEXT Use credentials defined within fides config --org-url TEXT Use org url option to connect to okta. Requires options --org-url and --token --token TEXT Use token option to connect to okta. Requires options --org-url and --token -k, --org-key TEXT The organization_fides_key you wish to export resources for. -c, --coverage-threshold INTEGER RANGE [0<=x<=100] --help Show this message and exit.","title":"okta"},{"location":"cli/#fides-status","text":"1 Sends a request to the fides API healthcheck endpoint and prints the response. Usage: 1 fides status [OPTIONS] Options: 1 --help Show this message and exit.","title":"status"},{"location":"cli/#fides-view","text":"1 View various resources types. Usage: 1 fides view [OPTIONS] COMMAND [ARGS]... Options: 1 --help Show this message and exit.","title":"view"},{"location":"cli/#fides-view-config","text":"1 2 3 4 Prints the fides configuration values. To only view a specific section of the config, supply the section name as an argument. Usage: 1 fides view config [OPTIONS] [SECTION] Options: 1 2 --exclude-unset Only print configuration values explicitly set by the user. --help Show this message and exit.","title":"config"},{"location":"cli/#fides-webserver","text":"1 Starts the fides API server using Uvicorn on port 8080. Usage: 1 fides webserver [OPTIONS] Options: 1 --help Show this message and exit.","title":"webserver"},{"location":"cli/#fides-worker","text":"1 Starts a celery worker. Usage: 1 fides worker [OPTIONS] Options: 1 --help Show this message and exit.","title":"worker"},{"location":"deployment/","text":"Deployment Guide This guide is intended for production deployments. To quickly experiment with Fides, clone the source repository , and use the built-in docker compose configuration to run a demo environment. A production-ready instance of Fides can be deployed leveraging the cloud infrastructure your organization is most familiar with. Fully deployed, Fides consists of the following individual systems: Hosted Database : A PostgreSQL database server used for permanent storage of configuration data for the webserver. Hosted Cache : A Redis database server used as a temporary cache during execution and task scheduling. Fides Weberver : The main application, which houses the Admin UI and API endpoints. Optionally, the Fides Privacy Center can be deployed as a pre-built way to receive privacy requests. Set up the hosted database Fides uses an application database for persistent storage. Any hosted PostgreSQL database that meets the current project requirements is acceptable, as long as it's accessible. Options include: A managed PostgreSQL database services (e.g., AWS RDS, GCP Cloud SQL, Azure Database) A self-hosted PostgreSQL Docker container with a persistent volume mount (e.g., a Kubernetes cluster) A self-hosted PostgreSQL server (e.g., an EC2 server) As long as your database will be accessible by your Fides webserver, there is no need to expose it to the public Internet. Configure your database Follow the documentation for the option of your choice to configure a production-grade PostgreSQL database. Once your database is up and running, create a unique user and database for Fides to use, and assign your Fides user a secure password. Update your Fides configuration Use your database information to set the following values in your Fides configuration . The options for the [postgres] section of the fides.toml file are outlined below, but may be substituted with environment variables. Name Default Description user postgres The database user Fides will use to log in to the application database. password fides The password for the Fides user. server fides-db The hostname of the Postgres database server. port 5432 The port at which the Postgres database will be accessible. db fides The name of the Postgres database. Set up the hosted cache During privacy request execution, Fides collects result data in a temporary Redis cache that automatically expires to ensure personal data is never retained erroneously. Any hosted Redis database that meets the current project requirements is acceptable, from a Docker Redis container to a managed service (e.g., AWS ElastiCache, GCP Memorystore, Azure Cache, Redis Cloud). As long as your cache will be accessible by your Fides webserver, there is no need to expose it to the public Internet. Configure your cache Follow the documentation for the option of your choice to configure a production-grade Redis cache. Once your cache is available, ensure you enable a password (via Redis AUTH ) to provide additional security, and keep track of your connection credentials. Update your Fides configuration Use your database information to set the following values in your Fides configuration . The options for the [redis] section of the fides.toml file are outlined below, but may be substituted with environment variables. Config Variable Example Description host N/A The network address for the application Redis cache. port 6379 The port at which the application cache will be accessible. user N/A The user with which to login to the Redis cache. password N/A The password with which to login to the Redis cache. db_index N/A The application will use this index in the Redis cache to cache data. Set up the webserver The Fides webserver is a FastAPI application with a Uvicorn server to handle requests. The host requirements for the webserver are minimal: A general purpose webserver (e.g. for AWS EC2, a t2.small or larger) Docker version 20.10.8 or newer (if installing via Docker) OR Python 3.8 or newer (if installing via Python) No persistent storage requirements (this is handled by the hosted database) Using docker Ensure that Docker is running on your host, and satisfies the minimum requirements . Pull the docker image Run the following command to pull the latest image from Ethyca's DockerHub : 1 docker pull ethyca/fides Configure Fides A number of environment variables are required for a minimum working configuration . You can provide a configuration by creating an .env file and passing it in via the --env-file {file} option , by providing individual variables with the --env {VAR} option, or directly to your docker host. At a minimum, you'll need to configure the following: Config Variable Example Description FIDES__SECURITY__APP_ENCRYPTION_KEY athirtytwocharacterencryptionkey An AES256 encryption key used for DB & JWE encryption. Must be exactly 32 characters (256bits). FIDES__SECURITY__OAUTH_ROOT_CLIENT_ID fidesadmin The client ID used for the \"root\" OAuth client. FIDES__SECURITY__OAUTH_ROOT_CLIENT_SECRET fidesadminsecret The client secret used for the \"root\" OAuth client. FIDES__DATABASE__SERVER postgres.internal The hostname for your database server. FIDES__DATABASE__PORT 5432 The port for your database server. FIDES__DATABASE__USER fides The username Fides should use to access the database. FIDES__DATABASE__PASSWORD fidessecret The password Fides should use to access the database FIDES__DATABASE__DB fides The postgres database name. FIDES__REDIS__HOST redis.internal The hostname for your Redis server. FIDES__REDIS__PORT 6379 The port for your Redis server. FIDES__REDIS__PASSWORD fidessecret The password Fides should use to access Redis. Start your server Once pulled, you can start your server with: 1 docker run ethyca/fides -p 8080:8080 To include your environment variables, you can run the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 docker run \\ -p 8080 :8080 \\ --env FIDES__SECURITY__APP_ENCRYPTION_KEY = \"athirtytwocharacterencryptionkey\" \\ --env FIDES__SECURITY__OAUTH_ROOT_CLIENT_ID = \"fidesadmin\" \\ --env FIDES__SECURITY__OAUTH_ROOT_CLIENT_SECRET = \"fidesadminsecret\" \\ --env FIDES__DATABASE__SERVER = \"postgres.internal\" \\ --env FIDES__DATABASE__PORT = \"5432\" \\ --env FIDES__DATABASE__USER = \"fides\" \\ --env FIDES__DATABASE__PASSWORD = \"fidessecret\" \\ --env FIDES__DATABASE__DB = \"fides\" \\ --env FIDES__REDIS__HOST = \"redis.internal\" \\ --env FIDES__REDIS__PORT = 6379 \\ --env FIDES__REDIS__PASSWORD = \"fidessecret\" \\ ethyca/fides If you prefer to create your .env file and pass an --env-file variable: 1 2 3 4 docker run \\ -p 8080:8080 \\ --env-file=<ENV FILE NAME>.env \\ ethyca/fides config.env 1 2 3 4 5 6 7 8 9 10 11 FIDES__SECURITY__APP_ENCRYPTION_KEY=\"athirtytwocharacterencryptionkey\" FIDES__SECURITY__OAUTH_ROOT_CLIENT_ID=\"fidesadmin\" FIDES__SECURITY__OAUTH_ROOT_CLIENT_SECRET=\"fidesadminsecret\" FIDES__DATABASE__SERVER=\"postgres.internal\" FIDES__DATABASE__PORT=\"5432\" FIDES__DATABASE__USER=\"fides\" FIDES__DATABASE__PASSWORD=\"fidessecret\" FIDES__DATABASE__DB=\"fides\" FIDES__REDIS__HOST=\"redis.internal\" FIDES__REDIS__PORT=6379 FIDES__REDIS__PASSWORD=\"fidessecret\" Note that there's no need for a persistent volume mount. The webserver is fully ephemeral, and relies on the database for its permanent state. Using Python Follow the PyPI installation guide for initializing and configuring Fides on your host. Test the webserver To test that your server is running, visit http://{server_url}/health in your browser (e.g. http://0.0.0.0:8080/health) and you should see {\"webserver\": \"healthy\", \"database\": \"healthy\", \"cache\": \"healthy\"} . You can also visit the hosted UI at http://{server_url}/ . Set up the Privacy Center (Optional) Ensure that Docker is running on your host, and satisfies the minimum requirements . Run the following command to pull the latest image from Ethyca's DockerHub : 1 docker pull ethyca/fides-privacy-center More information about configuration options can be found here . Once pulled and configured, you can run the following within your project to start the server: 1 2 3 docker run --rm \\ -v $( pwd ) /config:/app/config \\ -p 3000 :3000 ethyca/fides-privacy-center:latest","title":"Deployment"},{"location":"deployment/#deployment-guide","text":"This guide is intended for production deployments. To quickly experiment with Fides, clone the source repository , and use the built-in docker compose configuration to run a demo environment. A production-ready instance of Fides can be deployed leveraging the cloud infrastructure your organization is most familiar with. Fully deployed, Fides consists of the following individual systems: Hosted Database : A PostgreSQL database server used for permanent storage of configuration data for the webserver. Hosted Cache : A Redis database server used as a temporary cache during execution and task scheduling. Fides Weberver : The main application, which houses the Admin UI and API endpoints. Optionally, the Fides Privacy Center can be deployed as a pre-built way to receive privacy requests.","title":"Deployment Guide"},{"location":"deployment/#set-up-the-hosted-database","text":"Fides uses an application database for persistent storage. Any hosted PostgreSQL database that meets the current project requirements is acceptable, as long as it's accessible. Options include: A managed PostgreSQL database services (e.g., AWS RDS, GCP Cloud SQL, Azure Database) A self-hosted PostgreSQL Docker container with a persistent volume mount (e.g., a Kubernetes cluster) A self-hosted PostgreSQL server (e.g., an EC2 server) As long as your database will be accessible by your Fides webserver, there is no need to expose it to the public Internet.","title":"Set up the hosted database"},{"location":"deployment/#configure-your-database","text":"Follow the documentation for the option of your choice to configure a production-grade PostgreSQL database. Once your database is up and running, create a unique user and database for Fides to use, and assign your Fides user a secure password.","title":"Configure your database"},{"location":"deployment/#update-your-fides-configuration","text":"Use your database information to set the following values in your Fides configuration . The options for the [postgres] section of the fides.toml file are outlined below, but may be substituted with environment variables. Name Default Description user postgres The database user Fides will use to log in to the application database. password fides The password for the Fides user. server fides-db The hostname of the Postgres database server. port 5432 The port at which the Postgres database will be accessible. db fides The name of the Postgres database.","title":"Update your Fides configuration"},{"location":"deployment/#set-up-the-hosted-cache","text":"During privacy request execution, Fides collects result data in a temporary Redis cache that automatically expires to ensure personal data is never retained erroneously. Any hosted Redis database that meets the current project requirements is acceptable, from a Docker Redis container to a managed service (e.g., AWS ElastiCache, GCP Memorystore, Azure Cache, Redis Cloud). As long as your cache will be accessible by your Fides webserver, there is no need to expose it to the public Internet.","title":"Set up the hosted cache"},{"location":"deployment/#configure-your-cache","text":"Follow the documentation for the option of your choice to configure a production-grade Redis cache. Once your cache is available, ensure you enable a password (via Redis AUTH ) to provide additional security, and keep track of your connection credentials.","title":"Configure your cache"},{"location":"deployment/#update-your-fides-configuration_1","text":"Use your database information to set the following values in your Fides configuration . The options for the [redis] section of the fides.toml file are outlined below, but may be substituted with environment variables. Config Variable Example Description host N/A The network address for the application Redis cache. port 6379 The port at which the application cache will be accessible. user N/A The user with which to login to the Redis cache. password N/A The password with which to login to the Redis cache. db_index N/A The application will use this index in the Redis cache to cache data.","title":"Update your Fides configuration"},{"location":"deployment/#set-up-the-webserver","text":"The Fides webserver is a FastAPI application with a Uvicorn server to handle requests. The host requirements for the webserver are minimal: A general purpose webserver (e.g. for AWS EC2, a t2.small or larger) Docker version 20.10.8 or newer (if installing via Docker) OR Python 3.8 or newer (if installing via Python) No persistent storage requirements (this is handled by the hosted database)","title":"Set up the webserver"},{"location":"deployment/#using-docker","text":"Ensure that Docker is running on your host, and satisfies the minimum requirements .","title":"Using docker"},{"location":"deployment/#pull-the-docker-image","text":"Run the following command to pull the latest image from Ethyca's DockerHub : 1 docker pull ethyca/fides","title":"Pull the docker image"},{"location":"deployment/#configure-fides","text":"A number of environment variables are required for a minimum working configuration . You can provide a configuration by creating an .env file and passing it in via the --env-file {file} option , by providing individual variables with the --env {VAR} option, or directly to your docker host. At a minimum, you'll need to configure the following: Config Variable Example Description FIDES__SECURITY__APP_ENCRYPTION_KEY athirtytwocharacterencryptionkey An AES256 encryption key used for DB & JWE encryption. Must be exactly 32 characters (256bits). FIDES__SECURITY__OAUTH_ROOT_CLIENT_ID fidesadmin The client ID used for the \"root\" OAuth client. FIDES__SECURITY__OAUTH_ROOT_CLIENT_SECRET fidesadminsecret The client secret used for the \"root\" OAuth client. FIDES__DATABASE__SERVER postgres.internal The hostname for your database server. FIDES__DATABASE__PORT 5432 The port for your database server. FIDES__DATABASE__USER fides The username Fides should use to access the database. FIDES__DATABASE__PASSWORD fidessecret The password Fides should use to access the database FIDES__DATABASE__DB fides The postgres database name. FIDES__REDIS__HOST redis.internal The hostname for your Redis server. FIDES__REDIS__PORT 6379 The port for your Redis server. FIDES__REDIS__PASSWORD fidessecret The password Fides should use to access Redis.","title":"Configure Fides"},{"location":"deployment/#start-your-server","text":"Once pulled, you can start your server with: 1 docker run ethyca/fides -p 8080:8080 To include your environment variables, you can run the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 docker run \\ -p 8080 :8080 \\ --env FIDES__SECURITY__APP_ENCRYPTION_KEY = \"athirtytwocharacterencryptionkey\" \\ --env FIDES__SECURITY__OAUTH_ROOT_CLIENT_ID = \"fidesadmin\" \\ --env FIDES__SECURITY__OAUTH_ROOT_CLIENT_SECRET = \"fidesadminsecret\" \\ --env FIDES__DATABASE__SERVER = \"postgres.internal\" \\ --env FIDES__DATABASE__PORT = \"5432\" \\ --env FIDES__DATABASE__USER = \"fides\" \\ --env FIDES__DATABASE__PASSWORD = \"fidessecret\" \\ --env FIDES__DATABASE__DB = \"fides\" \\ --env FIDES__REDIS__HOST = \"redis.internal\" \\ --env FIDES__REDIS__PORT = 6379 \\ --env FIDES__REDIS__PASSWORD = \"fidessecret\" \\ ethyca/fides If you prefer to create your .env file and pass an --env-file variable: 1 2 3 4 docker run \\ -p 8080:8080 \\ --env-file=<ENV FILE NAME>.env \\ ethyca/fides config.env 1 2 3 4 5 6 7 8 9 10 11 FIDES__SECURITY__APP_ENCRYPTION_KEY=\"athirtytwocharacterencryptionkey\" FIDES__SECURITY__OAUTH_ROOT_CLIENT_ID=\"fidesadmin\" FIDES__SECURITY__OAUTH_ROOT_CLIENT_SECRET=\"fidesadminsecret\" FIDES__DATABASE__SERVER=\"postgres.internal\" FIDES__DATABASE__PORT=\"5432\" FIDES__DATABASE__USER=\"fides\" FIDES__DATABASE__PASSWORD=\"fidessecret\" FIDES__DATABASE__DB=\"fides\" FIDES__REDIS__HOST=\"redis.internal\" FIDES__REDIS__PORT=6379 FIDES__REDIS__PASSWORD=\"fidessecret\" Note that there's no need for a persistent volume mount. The webserver is fully ephemeral, and relies on the database for its permanent state.","title":"Start your server"},{"location":"deployment/#using-python","text":"Follow the PyPI installation guide for initializing and configuring Fides on your host.","title":"Using Python"},{"location":"deployment/#test-the-webserver","text":"To test that your server is running, visit http://{server_url}/health in your browser (e.g. http://0.0.0.0:8080/health) and you should see {\"webserver\": \"healthy\", \"database\": \"healthy\", \"cache\": \"healthy\"} . You can also visit the hosted UI at http://{server_url}/ .","title":"Test the webserver"},{"location":"deployment/#set-up-the-privacy-center-optional","text":"Ensure that Docker is running on your host, and satisfies the minimum requirements . Run the following command to pull the latest image from Ethyca's DockerHub : 1 docker pull ethyca/fides-privacy-center More information about configuration options can be found here . Once pulled and configured, you can run the following within your project to start the server: 1 2 3 docker run --rm \\ -v $( pwd ) /config:/app/config \\ -p 3000 :3000 ethyca/fides-privacy-center:latest","title":"Set up the Privacy Center (Optional)"},{"location":"ethyca/","text":"About Ethyca The mission of Ethyca is to make Internet-scale technology respectful and ethical. We're a venture-backed privacy technology team headquartered in New York, but working as a distributed team across the US to solve what we believe is the most important problem in technology today: the human right to privacy in vastly complex data-driven systems. What is Fides? Fides is a universally understandable, open-source language that can be used to describe privacy within tech infrastructure. Our existing tools use this language to power a low friction set of developer tools that integrate with your existing CI pipelines, making privacy a feature of your tech stack. With Fides, we hope everyone can build better tools for privacy in the next decade and beyond. What we Believe Data privacy is a human right that should be a native feature of any respectful technology. Today building great privacy as a feature in software is friction-filled and complicated. We're building open-source privacy tools for the developer community because we believe the only way to achieve a respectful internet is to make privacy an easy-to-implement layer of any tech stack. The Future We've been working on this problem since 2018 and have a clear view of our next five years. We're excited about the roadmap of features we'll add to Fides in order to make it the comprehensive tool for addressing the major challenges of privacy in both the code management and runtime environments. We'd love you to contribute to Fides, and you can do this directly as part of the open-source community. If you're interested in solving some of the toughest and most important problems facing internet scale data-driven software, join us now and get paid to work on this problem too! Your Participation Fides' success is predicated on your participation -- Privacy as Code can only become a reality if we ensure it's easy to understand, implement, and held as an interoperable standard for wide adoption. Your feedback, contributions, and improvements are encouraged as we build community with the sole objective of creating respectful software for everyone on the internet.","title":"About Ethyca"},{"location":"ethyca/#about-ethyca","text":"The mission of Ethyca is to make Internet-scale technology respectful and ethical. We're a venture-backed privacy technology team headquartered in New York, but working as a distributed team across the US to solve what we believe is the most important problem in technology today: the human right to privacy in vastly complex data-driven systems.","title":"About Ethyca"},{"location":"ethyca/#what-is-fides","text":"Fides is a universally understandable, open-source language that can be used to describe privacy within tech infrastructure. Our existing tools use this language to power a low friction set of developer tools that integrate with your existing CI pipelines, making privacy a feature of your tech stack. With Fides, we hope everyone can build better tools for privacy in the next decade and beyond.","title":"What is Fides?"},{"location":"ethyca/#what-we-believe","text":"Data privacy is a human right that should be a native feature of any respectful technology. Today building great privacy as a feature in software is friction-filled and complicated. We're building open-source privacy tools for the developer community because we believe the only way to achieve a respectful internet is to make privacy an easy-to-implement layer of any tech stack.","title":"What we Believe"},{"location":"ethyca/#the-future","text":"We've been working on this problem since 2018 and have a clear view of our next five years. We're excited about the roadmap of features we'll add to Fides in order to make it the comprehensive tool for addressing the major challenges of privacy in both the code management and runtime environments. We'd love you to contribute to Fides, and you can do this directly as part of the open-source community. If you're interested in solving some of the toughest and most important problems facing internet scale data-driven software, join us now and get paid to work on this problem too!","title":"The Future"},{"location":"ethyca/#your-participation","text":"Fides' success is predicated on your participation -- Privacy as Code can only become a reality if we ensure it's easy to understand, implement, and held as an interoperable standard for wide adoption. Your feedback, contributions, and improvements are encouraged as we build community with the sole objective of creating respectful software for everyone on the internet.","title":"Your Participation"},{"location":"glossary/","text":"Glossary of Key Terms Term Definition Connection A configuration for how to connect a database or application to Fides. Data Category What kind of data is it? For example, the Data Category user includes things like contact email and street address. Data Qualifier How is the data being protected? For example, it might be aggregated . Data Subjects Whose data is it? For example, a customer . Data Uses Why is it being used? For example, for advertising or to improve the system. Dataset An annotation of a database schema, which describes the Collections in a database, the Fields, the Data Categories of those fields, and the relationships between relevant Collections. Execution Policy Different from a Policy, this is a configuration that describes what happens when a privacy request is processed. An execution policy might define that when given an email, it locates all the related data the customer has provided to you, and uploads that to a specific S3 bucket. Identity A piece of information used to uniquely identify an individual, like an email or a phone number. Identity Graph A mapping that knows where personal data lives, and how to look it up. For example, you might have photos stored in a MySQL database, and customer information stored in a PostgreSQL database. The identity graph might say to get the customer ID from the PostgreSQL database, and use that to look up the customer's photo in the MySQL database. Masking Strategy How to erase or mask customer data. Pre-Webhook Webhooks triggered on an execution policy before a Privacy Request is executed. Policy A Policy controls what kinds of data you are permitted to commit to source code. Resource A Manifest file Fides uses to describe part of your infrastructure, written in fideslang . Post-Webhook Webhooks triggered on an execution policy after a Privacy Request is executed. Storage Where the customer's data will be sent after an access request is completed. Subject Request A privacy request is a Fides representation of what is more widely known as a Data Subject Request, or Data Subject Access Request. Access requests are made when a customer wants to see the data an organization has collected about them. Erasure requests are made when a customer wants an organization to delete the data they have collected about them. System Systems represent the applications, services, integrations, and any software that processes data for a specific use case. Traversal Created from an identity and an identity graph, a traversal defines how to best move through and retrieve information from your connected resources. Manifest YAML files that describe different types of objects within Fides, written in fideslang .","title":"Glossary"},{"location":"glossary/#glossary-of-key-terms","text":"Term Definition Connection A configuration for how to connect a database or application to Fides. Data Category What kind of data is it? For example, the Data Category user includes things like contact email and street address. Data Qualifier How is the data being protected? For example, it might be aggregated . Data Subjects Whose data is it? For example, a customer . Data Uses Why is it being used? For example, for advertising or to improve the system. Dataset An annotation of a database schema, which describes the Collections in a database, the Fields, the Data Categories of those fields, and the relationships between relevant Collections. Execution Policy Different from a Policy, this is a configuration that describes what happens when a privacy request is processed. An execution policy might define that when given an email, it locates all the related data the customer has provided to you, and uploads that to a specific S3 bucket. Identity A piece of information used to uniquely identify an individual, like an email or a phone number. Identity Graph A mapping that knows where personal data lives, and how to look it up. For example, you might have photos stored in a MySQL database, and customer information stored in a PostgreSQL database. The identity graph might say to get the customer ID from the PostgreSQL database, and use that to look up the customer's photo in the MySQL database. Masking Strategy How to erase or mask customer data. Pre-Webhook Webhooks triggered on an execution policy before a Privacy Request is executed. Policy A Policy controls what kinds of data you are permitted to commit to source code. Resource A Manifest file Fides uses to describe part of your infrastructure, written in fideslang . Post-Webhook Webhooks triggered on an execution policy after a Privacy Request is executed. Storage Where the customer's data will be sent after an access request is completed. Subject Request A privacy request is a Fides representation of what is more widely known as a Data Subject Request, or Data Subject Access Request. Access requests are made when a customer wants to see the data an organization has collected about them. Erasure requests are made when a customer wants an organization to delete the data they have collected about them. System Systems represent the applications, services, integrations, and any software that processes data for a specific use case. Traversal Created from an identity and an identity graph, a traversal defines how to best move through and retrieve information from your connected resources. Manifest YAML files that describe different types of objects within Fides, written in fideslang .","title":"Glossary of Key Terms"},{"location":"license/","text":"License 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2021- Ethyca, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"license/#license","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2021- Ethyca, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"api/","text":"API Reference You can view the live, interactive Swagger API docs for Fides by visiting /docs on a running instance. This is a great way to experiment with the APIs using Swagger's built-in \"Try it out\" functionality. Additionally, you can download the Postman collection and follow instructions to set up on your machine. Below, we've embedded the latest release's API documentation as a living reference. These work largely the same, but since this documentation site isn't connected to a live instance, the \"Try it out\" and \"Authorize\" buttons won't work, sorry! All API routes will automatically match with and without a trailing slash / . So /api/v1/config and /api/v1/config/ are both valid API calls. const ui = SwaggerUIBundle({ url: 'openapi.json', dom_id: '#swagger-ui', }) /* If there is an anchor tag, reload it after the page loads to scroll to * that section, since the Swagger UI takes some time to render. */ if (location.hash) { setTimeout(function() { location.href = location.href }, 200); }","title":"API"},{"location":"api/#api-reference","text":"You can view the live, interactive Swagger API docs for Fides by visiting /docs on a running instance. This is a great way to experiment with the APIs using Swagger's built-in \"Try it out\" functionality. Additionally, you can download the Postman collection and follow instructions to set up on your machine. Below, we've embedded the latest release's API documentation as a living reference. These work largely the same, but since this documentation site isn't connected to a live instance, the \"Try it out\" and \"Authorize\" buttons won't work, sorry! All API routes will automatically match with and without a trailing slash / . So /api/v1/config and /api/v1/config/ are both valid API calls. const ui = SwaggerUIBundle({ url: 'openapi.json', dom_id: '#swagger-ui', }) /* If there is an anchor tag, reload it after the page loads to scroll to * that section, since the Swagger UI takes some time to render. */ if (location.hash) { setTimeout(function() { location.href = location.href }, 200); }","title":"API Reference"},{"location":"community/code_of_conduct/","text":"Fides Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct that could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the Fides core team at fides@ethyca.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of Conduct"},{"location":"community/code_of_conduct/#fides-code-of-conduct","text":"","title":"Fides Code of Conduct"},{"location":"community/code_of_conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"community/code_of_conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct that could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"community/code_of_conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"community/code_of_conduct/#scope","text":"This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"community/code_of_conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the Fides core team at fides@ethyca.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"community/code_of_conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution"},{"location":"community/hints_tips/","text":"Community The Fides project welcomes issues, contributions and discussion from all users, regardless of background or experience level. In order to create a positive and welcoming environment, all interactions are governed by the Fides Code of Conduct . Guidelines Whether it's giving us feedback, raising a question, or showing your Fides-related work, we are looking forward to hearing from you. The Fides community is vibrant because of the quality of its members and the discussions they bring. To keep the workspace inviting and helpful for everyone, there are a few guidelines that we ask all members to follow. Rule 1: Assume Positive Intent Being nice is the most important pillar of the Fides community. We are considerate to each other's effort and time. It's also easy to misinterpret people through Slack, so we make an extra effort to chat in a positive tone. We assume that you are here to learn and exchange ideas, and we ask that you contribute to making a welcoming community. If someone is helping you, be mindful of the effort they are putting in. While we are always happy to help users, we can not help users with step-by-step debugging. Use your professional judgment in discerning whether requests are unreasonable. The Fides team always tries to listen to the community. Please be understanding if your issue or feature request is not deemed an immediate priority. Rule 2: Use threads for larger messages Because of the size of our community and frequency of posts, it's easy for large messages to drown out smaller messages. Using threads helps people see more messages on their screen. Larger code blocks should be posted in threads. Rule 3: Avoid posting sensitive information Community members sometimes need to post code snippets as they ask for help. Be sure to remove sensitive information from posts to the public channels. If your Fides account information is needed to help you, we will ask you to direct message such information. Be cautious of anyone asking for information through direct messages. Rule 4: Write high quality questions The Fides community is here to support you. That said, it is significantly easier to answer well-researched and clearly-written questions. Even adding potentially relevant links to a post helps tremendously. Informative Slack threads are archived by our resident bot Marvin. Having well-written threads helps future users encountering the same problem. Oftentimes your question may have been answered somewhere else; some good resources to start looking before asking a question: Fides Documentation GitHub Issues StackOverflow Rule 5: Don't abuse tagging users Requests for help will be seen by the Fides team, and will be directed to the appropriate person. Tagging individual users is highly discouraged unless it is in the context of a conversation thread. Rule 6: Avoid using DMs to ask for help Fides employees should not be sent questions in DMs unless we specifically ask you to send us private information. There are times when it makes sense to directly message another community member experiencing a similar issue, or working with similar technologies. Just be aware that some people may not want to be messaged. It also helps other people if you post your question publicly. Similar to above, informative Slack threads are archived. Having conversations in public channels drives better quality discussions that can be referenced in the future. Rule 7: Don't advertise material unrelated to Fides Our community is in the channel to learn more about Fides. Showing us Fides-related stuff that you're working on is highly encouraged. Advertising products and events unrelated to Fides will be removed.","title":"Community Hints and Tips"},{"location":"community/hints_tips/#community","text":"The Fides project welcomes issues, contributions and discussion from all users, regardless of background or experience level. In order to create a positive and welcoming environment, all interactions are governed by the Fides Code of Conduct .","title":"Community"},{"location":"community/hints_tips/#guidelines","text":"Whether it's giving us feedback, raising a question, or showing your Fides-related work, we are looking forward to hearing from you. The Fides community is vibrant because of the quality of its members and the discussions they bring. To keep the workspace inviting and helpful for everyone, there are a few guidelines that we ask all members to follow.","title":"Guidelines"},{"location":"community/hints_tips/#rule-1-assume-positive-intent","text":"Being nice is the most important pillar of the Fides community. We are considerate to each other's effort and time. It's also easy to misinterpret people through Slack, so we make an extra effort to chat in a positive tone. We assume that you are here to learn and exchange ideas, and we ask that you contribute to making a welcoming community. If someone is helping you, be mindful of the effort they are putting in. While we are always happy to help users, we can not help users with step-by-step debugging. Use your professional judgment in discerning whether requests are unreasonable. The Fides team always tries to listen to the community. Please be understanding if your issue or feature request is not deemed an immediate priority.","title":"Rule 1: Assume Positive Intent"},{"location":"community/hints_tips/#rule-2-use-threads-for-larger-messages","text":"Because of the size of our community and frequency of posts, it's easy for large messages to drown out smaller messages. Using threads helps people see more messages on their screen. Larger code blocks should be posted in threads.","title":"Rule 2: Use threads for larger messages"},{"location":"community/hints_tips/#rule-3-avoid-posting-sensitive-information","text":"Community members sometimes need to post code snippets as they ask for help. Be sure to remove sensitive information from posts to the public channels. If your Fides account information is needed to help you, we will ask you to direct message such information. Be cautious of anyone asking for information through direct messages.","title":"Rule 3: Avoid posting sensitive information"},{"location":"community/hints_tips/#rule-4-write-high-quality-questions","text":"The Fides community is here to support you. That said, it is significantly easier to answer well-researched and clearly-written questions. Even adding potentially relevant links to a post helps tremendously. Informative Slack threads are archived by our resident bot Marvin. Having well-written threads helps future users encountering the same problem. Oftentimes your question may have been answered somewhere else; some good resources to start looking before asking a question: Fides Documentation GitHub Issues StackOverflow","title":"Rule 4: Write high quality questions"},{"location":"community/hints_tips/#rule-5-dont-abuse-tagging-users","text":"Requests for help will be seen by the Fides team, and will be directed to the appropriate person. Tagging individual users is highly discouraged unless it is in the context of a conversation thread.","title":"Rule 5: Don't abuse tagging users"},{"location":"community/hints_tips/#rule-6-avoid-using-dms-to-ask-for-help","text":"Fides employees should not be sent questions in DMs unless we specifically ask you to send us private information. There are times when it makes sense to directly message another community member experiencing a similar issue, or working with similar technologies. Just be aware that some people may not want to be messaged. It also helps other people if you post your question publicly. Similar to above, informative Slack threads are archived. Having conversations in public channels drives better quality discussions that can be referenced in the future.","title":"Rule 6: Avoid using DMs to ask for help"},{"location":"community/hints_tips/#rule-7-dont-advertise-material-unrelated-to-fides","text":"Our community is in the channel to learn more about Fides. Showing us Fides-related stuff that you're working on is highly encouraged. Advertising products and events unrelated to Fides will be removed.","title":"Rule 7: Don't advertise material unrelated to Fides"},{"location":"community/overview/","text":"Join the Fides Community We believe the only way to solve privacy is as a community of likeminded developers that care to solve these problems for the rest of the world. To make it easier to connect and share ideas, we've created a set of community channels which we'd love to hear from you on: Start Contributing \u2003 Chat on Slack \u2003 Chat on Discord","title":"Github, Slack, and Discord"},{"location":"community/overview/#join-the-fides-community","text":"We believe the only way to solve privacy is as a community of likeminded developers that care to solve these problems for the rest of the world. To make it easier to connect and share ideas, we've created a set of community channels which we'd love to hear from you on: Start Contributing \u2003 Chat on Slack \u2003 Chat on Discord","title":"Join the Fides Community"},{"location":"development/code_style/","text":"Code Style General Docstrings Docstrings are required for every function, class, and method. No specific style is required or encouraged, as we expect that most of the relevant information can be gleaned from both the function signature's type-hints as well as descriptive parameter names. The docstring should serve to give additional context/flavour beyond that which can be gained from the code itself. Docstring Example 1 2 3 4 5 6 7 8 9 10 11 12 # Bad def execute_evaluation ( taxonomy : Taxonomy ) -> Evaluation : \"\"\" Execute an evaluation. \"\"\" # Good def execute_evaluation ( taxonomy : Taxonomy ) -> Evaluation : \"\"\" Check the stated constraints of each Privacy Policy's rules against each system's privacy declarations. \"\"\" Variable and parameter naming Variable and parameter names should be as self-describing as possible. Brevity is not a concern here. Here are some common examples for writing good self-documenting code: Single Letter Variable Names 1 2 3 4 5 6 7 8 9 10 11 12 13 # Incorrect s = 726 # Correct elapsed_time_seconds = 726 # Incorrect for n in nodes : print ( n ) # Correct for node in nodes : print ( node ) Abbreviated Variable Names 1 2 3 4 5 6 7 8 # Incorrect r = requests . get ( url ) # Incorrect resp = reqeusts . get ( url ) # Correct response = requests . get ( url ) Type Ambiguous Variable Names 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Incorrect food = [ \"apple\" , \"banana\" ] # Incorrect foods = [ \"apple\" , \"banana\" ] # Correct # Use type annotations if the name is somewhat ambiguous foods : List [ str ] = [ \"apple\" , \"banana\" ] # Correct # The type is contained in the name foods_list = [ \"apple\" , \"banana\" ] # Correct # Both of the above styles foods_list : List [ str ] = [ \"apple\" , \"banana\" ] Pre-commit hooks Fides includes a .pre-commit-config.yaml to facilitate running CI checks before pushing up to a PR. The pre-commit package is included in the dev-requirements.txt . Once that is installed, follow these steps to get up and running: pre-commit install - This is a one-time setup step to create the git pre-commit hooks. These pre-commit hooks will now run automatically. However you can also use pre-commit run to run them manually once all of your changes have been staged. NOTE : A Python interpreter must be available from wherever the git commands are being run, as this is required to run the pre-commit package. CI checks CI checks are stored as targets within the Noxfile, and can be run from the top-level fides directory with the following pattern: Pattern 1 nox -s <lowercased_name> Examples 1 2 3 nox -s black nox -s mypy nox -s xenon Black formatting Fides' code is formatted using the black style. This style is checked in a CI step, and merges to master are prevented if code does not conform. A number of extensions are available for popular editors that will automatically apply black to your code. Pylint Fides' code is linted using pylint . Linter checks run as part of a CI step and merges to master are prevented if code does not conform. Mypy Fides' code is statically-typed using mypy . Type checking is validated as a CI step, and merges to master are prevented if code does not pass type checks. As a general rule, mypy typing requires all function arguments and return values to be annotated. Xenon Fides' code is checked for its cyclomatic-complexity by Xenon. If a single logical piece of code is deemed too complex, then a CI step will fail, at which point the focus should be on breaking up said complex function/method/class.","title":"Code Style"},{"location":"development/code_style/#code-style","text":"","title":"Code Style"},{"location":"development/code_style/#general","text":"","title":"General"},{"location":"development/code_style/#docstrings","text":"Docstrings are required for every function, class, and method. No specific style is required or encouraged, as we expect that most of the relevant information can be gleaned from both the function signature's type-hints as well as descriptive parameter names. The docstring should serve to give additional context/flavour beyond that which can be gained from the code itself. Docstring Example 1 2 3 4 5 6 7 8 9 10 11 12 # Bad def execute_evaluation ( taxonomy : Taxonomy ) -> Evaluation : \"\"\" Execute an evaluation. \"\"\" # Good def execute_evaluation ( taxonomy : Taxonomy ) -> Evaluation : \"\"\" Check the stated constraints of each Privacy Policy's rules against each system's privacy declarations. \"\"\"","title":"Docstrings"},{"location":"development/code_style/#variable-and-parameter-naming","text":"Variable and parameter names should be as self-describing as possible. Brevity is not a concern here. Here are some common examples for writing good self-documenting code: Single Letter Variable Names 1 2 3 4 5 6 7 8 9 10 11 12 13 # Incorrect s = 726 # Correct elapsed_time_seconds = 726 # Incorrect for n in nodes : print ( n ) # Correct for node in nodes : print ( node ) Abbreviated Variable Names 1 2 3 4 5 6 7 8 # Incorrect r = requests . get ( url ) # Incorrect resp = reqeusts . get ( url ) # Correct response = requests . get ( url ) Type Ambiguous Variable Names 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Incorrect food = [ \"apple\" , \"banana\" ] # Incorrect foods = [ \"apple\" , \"banana\" ] # Correct # Use type annotations if the name is somewhat ambiguous foods : List [ str ] = [ \"apple\" , \"banana\" ] # Correct # The type is contained in the name foods_list = [ \"apple\" , \"banana\" ] # Correct # Both of the above styles foods_list : List [ str ] = [ \"apple\" , \"banana\" ]","title":"Variable and parameter naming"},{"location":"development/code_style/#pre-commit-hooks","text":"Fides includes a .pre-commit-config.yaml to facilitate running CI checks before pushing up to a PR. The pre-commit package is included in the dev-requirements.txt . Once that is installed, follow these steps to get up and running: pre-commit install - This is a one-time setup step to create the git pre-commit hooks. These pre-commit hooks will now run automatically. However you can also use pre-commit run to run them manually once all of your changes have been staged. NOTE : A Python interpreter must be available from wherever the git commands are being run, as this is required to run the pre-commit package.","title":"Pre-commit hooks"},{"location":"development/code_style/#ci-checks","text":"CI checks are stored as targets within the Noxfile, and can be run from the top-level fides directory with the following pattern: Pattern 1 nox -s <lowercased_name> Examples 1 2 3 nox -s black nox -s mypy nox -s xenon","title":"CI checks"},{"location":"development/code_style/#black-formatting","text":"Fides' code is formatted using the black style. This style is checked in a CI step, and merges to master are prevented if code does not conform. A number of extensions are available for popular editors that will automatically apply black to your code.","title":"Black formatting"},{"location":"development/code_style/#pylint","text":"Fides' code is linted using pylint . Linter checks run as part of a CI step and merges to master are prevented if code does not conform.","title":"Pylint"},{"location":"development/code_style/#mypy","text":"Fides' code is statically-typed using mypy . Type checking is validated as a CI step, and merges to master are prevented if code does not pass type checks. As a general rule, mypy typing requires all function arguments and return values to be annotated.","title":"Mypy"},{"location":"development/code_style/#xenon","text":"Fides' code is checked for its cyclomatic-complexity by Xenon. If a single logical piece of code is deemed too complex, then a CI step will fail, at which point the focus should be on breaking up said complex function/method/class.","title":"Xenon"},{"location":"development/contributing_details/","text":"Contributing Details API Endpoints Postman API collection The fides Postman Collection ) can be used to test a variety of privacy request endpoints. Follow the Using Postman guide to learn more about the how to use the collection. API URLs We define API URLs for specific API versions as constants within fides.api.ops.api.v1.urn_registry (where v1 can be substituted for that particular API version), then import those URLs into their specific API views. Since we are on the first version, there is no clear precedent set for overriding URLs between versions yet. The most likely change is that we'll override the APIRouter class instantiation with a different base path (ie. /api/v2 instead of /api/v1 ). For example: 1 2 PRIVACY_REQUEST = \"/privacy-request\" PRIVACY_REQUEST_DETAIL = \"/privacy-request/{privacy_request_id}\" would both resolve as /api/v1/privacy-request and /api/v1/privacy-request/{privacy_request_id} respectively. Database and Models The ORM -- SQLAlchemy SQLAlchemy is an Object Relational Mapper, allowing us to avoid writing direct database queries within our codebase, and access the database via Python code instead. The ORM provides an additional configuration layer allowing user-defined Python classes to be mapped to database tables and other constructs, as well as an object persistence mechanism known as the Session . Some common uses cases are listed below, for a more comprehensive guide see: https://docs.sqlalchemy.org/en/14/tutorial/index.html Adding models Database tables are defined with model classes. Model files should live in src/app/models/ . Individual model classes must inherit from our custom base class at app.db.base_class.Base to ensure uniformity within the database. Multiple models per file are encouraged so long as they fit the same logical delineation within the project. An example model declaration is added below. For a comprehensive guide see: https://docs.sqlalchemy.org/en/14/orm/mapping_styles.html#declarative-mapping You should also import your model in src/fides/api/ops/db/base.py so it is visible for alembic. 1 2 3 4 5 6 7 class Book(Base): __tablename__ = 'book' id = Column(Integer, primary_key=True) name = Column(String, index=True) page_count = Column(Integer, nullable=True) author_id = Column(Integer, ForeignKey(\"author.id\"), nullable=False) When models are added to the project, we must then add them to the database in a recordable and repeatable fashion using migrations. Using the database via models Once you've added database tables via project models, you're ready to read, write, and update them via Python code. Some examples of common use cases here are listed below. Official documentation is here: https://docs.sqlalchemy.org/en/14/orm/query.html#sqlalchemy.orm.Query . Import our application's database session: from fides.api.ops.db.session import get_db_session Instantiate the database interaction object: 1 2 SessionLocal = get_db_session(config) db = SessionLocal() Create a new row in a table: 1 2 3 4 5 6 7 8 9 db_obj = User( email=\"admin@fides.app\", full_name=\"Fides Admin\", is_superuser=True, is_active=True, ) db.add(db_obj) db.commit() db.refresh(db_obj) Fetch all objects in a table: users = db.query(User).all() Fetch all objects in a table that meet some criteria: active_users = db.query(User).filter(User.is_active == True) Get a specific row in a table: user = db.query(User).get(User.email == \"admin@fides.app\") Update a specific row in a table: 1 2 3 4 user.email = \"updated@fides.app\" db.add(user) db.commit() db.refresh() Connecting to the database When you run nox -s dev , the database will spin up in a Docker container with port 5432 exposed on localhost. You can connect to it using the credentials found in .fides.toml , e.g. Hostname: localhost Port: 5432 Username: see database.user in .fides.toml Password: see database.password in .fides.toml Alembic migrations Some common Alembic commands are listed below. For a comprehensive guide see: https://alembic.sqlalchemy.org/en/latest/tutorial.html . The commands will need to be run inside a shell on your Docker containers, which can be opened with nox -s dev -- shell . In the /src/fides directory: Migrate your database to the latest state: alembic upgrade head Get revision id of previous migration: alembic current Automatically generate a new migration: alembic revision --autogenerate -m \"<a message describing your changes>\" Create a new migration file to manually fill out: alembic revision -m \"<a message describing your changes>\" Migrate your database to a specific state alembic upgrade <revision-id> or alembic downgrade <revision-id> , (or if you want to be smart alembic upgrade <revision-id> || alembic downgrade <revision-id> is handy when you don't know whether the target revision is an upgrade or downgrade) NB. You can find the revision-id inside each migration file in alembic/versions/ on line 3 next to Revision ID: ... When working on a PR with a migration, ensure that down_revision in the generated migration file correctly references the previous migration before submitting/merging the PR. Exception Handling Our preference for exception handling is by overriding the nearest sensible error, for example: 1 2 3 4 5 6 class SomeException(ValueError): \"a docstring\" def some_method(): raise SomeException(\"a message\") General debugging -- pdb The project uses pdb for debugging as a dev-requirement . You can set breakpoints with pdb in much the same way you'd set them using debugger in Javascript. Insert import pdb; pdb.set_trace() into the line where you want the breakpoint to set, then run your Python code. Docker Occasionally when developing you'll run into issues where it's beneficial to remove all existing Docker instances in order to recreate them based on some updated spec. Some commands to do this are below: Stop all running containers: docker-compose down Delete all local containers: docker rm -f $(docker ps -a -q) Delete all local Docker volumes: docker volume rm $(docker volume ls -q) Remove temp. files, installed dependencies, all local Docker containers and all local Docker volumes: nox -s clean Delete all stopped containers, all networks not used by a container, all dangling images, and all build cache: docker system prune Recreate the project: nox -s \"build(dev)\"","title":"Contributing Details"},{"location":"development/contributing_details/#contributing-details","text":"","title":"Contributing Details"},{"location":"development/contributing_details/#api-endpoints","text":"","title":"API Endpoints"},{"location":"development/contributing_details/#postman-api-collection","text":"The fides Postman Collection ) can be used to test a variety of privacy request endpoints. Follow the Using Postman guide to learn more about the how to use the collection.","title":"Postman API collection"},{"location":"development/contributing_details/#api-urls","text":"We define API URLs for specific API versions as constants within fides.api.ops.api.v1.urn_registry (where v1 can be substituted for that particular API version), then import those URLs into their specific API views. Since we are on the first version, there is no clear precedent set for overriding URLs between versions yet. The most likely change is that we'll override the APIRouter class instantiation with a different base path (ie. /api/v2 instead of /api/v1 ). For example: 1 2 PRIVACY_REQUEST = \"/privacy-request\" PRIVACY_REQUEST_DETAIL = \"/privacy-request/{privacy_request_id}\" would both resolve as /api/v1/privacy-request and /api/v1/privacy-request/{privacy_request_id} respectively.","title":"API URLs"},{"location":"development/contributing_details/#database-and-models","text":"","title":"Database and Models"},{"location":"development/contributing_details/#the-orm-sqlalchemy","text":"SQLAlchemy is an Object Relational Mapper, allowing us to avoid writing direct database queries within our codebase, and access the database via Python code instead. The ORM provides an additional configuration layer allowing user-defined Python classes to be mapped to database tables and other constructs, as well as an object persistence mechanism known as the Session . Some common uses cases are listed below, for a more comprehensive guide see: https://docs.sqlalchemy.org/en/14/tutorial/index.html","title":"The ORM -- SQLAlchemy"},{"location":"development/contributing_details/#adding-models","text":"Database tables are defined with model classes. Model files should live in src/app/models/ . Individual model classes must inherit from our custom base class at app.db.base_class.Base to ensure uniformity within the database. Multiple models per file are encouraged so long as they fit the same logical delineation within the project. An example model declaration is added below. For a comprehensive guide see: https://docs.sqlalchemy.org/en/14/orm/mapping_styles.html#declarative-mapping You should also import your model in src/fides/api/ops/db/base.py so it is visible for alembic. 1 2 3 4 5 6 7 class Book(Base): __tablename__ = 'book' id = Column(Integer, primary_key=True) name = Column(String, index=True) page_count = Column(Integer, nullable=True) author_id = Column(Integer, ForeignKey(\"author.id\"), nullable=False) When models are added to the project, we must then add them to the database in a recordable and repeatable fashion using migrations.","title":"Adding models"},{"location":"development/contributing_details/#using-the-database-via-models","text":"Once you've added database tables via project models, you're ready to read, write, and update them via Python code. Some examples of common use cases here are listed below. Official documentation is here: https://docs.sqlalchemy.org/en/14/orm/query.html#sqlalchemy.orm.Query . Import our application's database session: from fides.api.ops.db.session import get_db_session Instantiate the database interaction object: 1 2 SessionLocal = get_db_session(config) db = SessionLocal() Create a new row in a table: 1 2 3 4 5 6 7 8 9 db_obj = User( email=\"admin@fides.app\", full_name=\"Fides Admin\", is_superuser=True, is_active=True, ) db.add(db_obj) db.commit() db.refresh(db_obj) Fetch all objects in a table: users = db.query(User).all() Fetch all objects in a table that meet some criteria: active_users = db.query(User).filter(User.is_active == True) Get a specific row in a table: user = db.query(User).get(User.email == \"admin@fides.app\") Update a specific row in a table: 1 2 3 4 user.email = \"updated@fides.app\" db.add(user) db.commit() db.refresh()","title":"Using the database via models"},{"location":"development/contributing_details/#connecting-to-the-database","text":"When you run nox -s dev , the database will spin up in a Docker container with port 5432 exposed on localhost. You can connect to it using the credentials found in .fides.toml , e.g. Hostname: localhost Port: 5432 Username: see database.user in .fides.toml Password: see database.password in .fides.toml","title":"Connecting to the database"},{"location":"development/contributing_details/#alembic-migrations","text":"Some common Alembic commands are listed below. For a comprehensive guide see: https://alembic.sqlalchemy.org/en/latest/tutorial.html . The commands will need to be run inside a shell on your Docker containers, which can be opened with nox -s dev -- shell . In the /src/fides directory: Migrate your database to the latest state: alembic upgrade head Get revision id of previous migration: alembic current Automatically generate a new migration: alembic revision --autogenerate -m \"<a message describing your changes>\" Create a new migration file to manually fill out: alembic revision -m \"<a message describing your changes>\" Migrate your database to a specific state alembic upgrade <revision-id> or alembic downgrade <revision-id> , (or if you want to be smart alembic upgrade <revision-id> || alembic downgrade <revision-id> is handy when you don't know whether the target revision is an upgrade or downgrade) NB. You can find the revision-id inside each migration file in alembic/versions/ on line 3 next to Revision ID: ... When working on a PR with a migration, ensure that down_revision in the generated migration file correctly references the previous migration before submitting/merging the PR.","title":"Alembic migrations"},{"location":"development/contributing_details/#exception-handling","text":"Our preference for exception handling is by overriding the nearest sensible error, for example: 1 2 3 4 5 6 class SomeException(ValueError): \"a docstring\" def some_method(): raise SomeException(\"a message\")","title":"Exception Handling"},{"location":"development/contributing_details/#general-debugging-pdb","text":"The project uses pdb for debugging as a dev-requirement . You can set breakpoints with pdb in much the same way you'd set them using debugger in Javascript. Insert import pdb; pdb.set_trace() into the line where you want the breakpoint to set, then run your Python code.","title":"General debugging -- pdb"},{"location":"development/contributing_details/#docker","text":"Occasionally when developing you'll run into issues where it's beneficial to remove all existing Docker instances in order to recreate them based on some updated spec. Some commands to do this are below: Stop all running containers: docker-compose down Delete all local containers: docker rm -f $(docker ps -a -q) Delete all local Docker volumes: docker volume rm $(docker volume ls -q) Remove temp. files, installed dependencies, all local Docker containers and all local Docker volumes: nox -s clean Delete all stopped containers, all networks not used by a container, all dangling images, and all build cache: docker system prune Recreate the project: nox -s \"build(dev)\"","title":"Docker"},{"location":"development/database_migration/","text":"Database Migration Changes to Fides could require a change to the database model. This includes scenarios where you want to persist a new field or replace an existing field. Changes made to the Fides databases are done through alembic migration scripts. Migrations can be found in the following directory: src/fides/api/ctl/migrations/versions To create a new migration we use the alembic revision command: 1 2 cd src/fides/api/ctl alembic revision --autogenerate -m \"migration message\" The autogenerated script should be verified and could require some manual changes. Migrations will run on server startup.","title":"Database Migration"},{"location":"development/database_migration/#database-migration","text":"Changes to Fides could require a change to the database model. This includes scenarios where you want to persist a new field or replace an existing field. Changes made to the Fides databases are done through alembic migration scripts. Migrations can be found in the following directory: src/fides/api/ctl/migrations/versions To create a new migration we use the alembic revision command: 1 2 cd src/fides/api/ctl alembic revision --autogenerate -m \"migration message\" The autogenerated script should be verified and could require some manual changes. Migrations will run on server startup.","title":"Database Migration"},{"location":"development/documentation/","text":"Documentation Documentation is an incredibly important part of Fides, both for explaining its concepts to general audiences and describing its usage to developers. Concepts Fides includes a great deal of \"concept\" documentation, which covers features, tutorials, guides, and examples separately from the auto-generated API reference. To write concept docs, add Markdown files to the docs/fides/docs/ directory (or one of its subdirectories). To ensure that your page is displayed in the navigation, edit mkdocs.yml to include a reference to it. Semantics Capitalization Concepts that refer to proper nouns or are trademarked should always be capitalized. The exception for Fides is only when referencing any languages or tools, such as fideslang or fideslog. Other Fides terms, like \"Data Category\" or \"System\", should also be capitalized to be clear about the fact that a Fides resource is being referenced. When a System is applied, it is either created or updated through the Fides api. The System model requires a field called fides_key . Previewing docs locally Documentation (including both concepts and API references) is built and deployed with every merge to Fides's master branch. If you're using VS Code Dev Containers, the docs will automatically be available at localhost:8000 , otherwise you'll need to run the following command: 1 nox -s docs_serve You'll see a status update as the docs build, and then an announcement that they are available on http://127.0.0.1:8000 .","title":"Documentation"},{"location":"development/documentation/#documentation","text":"Documentation is an incredibly important part of Fides, both for explaining its concepts to general audiences and describing its usage to developers.","title":"Documentation"},{"location":"development/documentation/#concepts","text":"Fides includes a great deal of \"concept\" documentation, which covers features, tutorials, guides, and examples separately from the auto-generated API reference. To write concept docs, add Markdown files to the docs/fides/docs/ directory (or one of its subdirectories). To ensure that your page is displayed in the navigation, edit mkdocs.yml to include a reference to it.","title":"Concepts"},{"location":"development/documentation/#semantics","text":"","title":"Semantics"},{"location":"development/documentation/#capitalization","text":"Concepts that refer to proper nouns or are trademarked should always be capitalized. The exception for Fides is only when referencing any languages or tools, such as fideslang or fideslog. Other Fides terms, like \"Data Category\" or \"System\", should also be capitalized to be clear about the fact that a Fides resource is being referenced. When a System is applied, it is either created or updated through the Fides api. The System model requires a field called fides_key .","title":"Capitalization"},{"location":"development/documentation/#previewing-docs-locally","text":"Documentation (including both concepts and API references) is built and deployed with every merge to Fides's master branch. If you're using VS Code Dev Containers, the docs will automatically be available at localhost:8000 , otherwise you'll need to run the following command: 1 nox -s docs_serve You'll see a status update as the docs build, and then an announcement that they are available on http://127.0.0.1:8000 .","title":"Previewing docs locally"},{"location":"development/fideslog/","text":"Fideslog Analytics Fides includes an implementation of fideslog to provide Ethyca with an understanding of user interactions with fides tooling. All collected analytics are anonymized, and only used in either product roadmap determination, or as insight into product adoption. Information collected by fideslog is received via HTTPs request, stored in a secure database, and never shared with third parties unless required by law. More information on use, implementation, and configuration can be found in the fideslog repository . Collected Data Fideslog collects information on instances of Fides by recording internal events. Using Fides may result in sending any or all of the following analytics data to Ethyca: Parameter Description docker If fides is run in a docker container. event The type of analytics event - currently, either a server start or endpoint call . event_created The time of the event. endpoint The endpoint accessed. status_code The status result of the request. error Error information, if any. Disabling Fideslog To opt out of analytics, set either the following fides environment variable or .toml configuration variable to True . Variable Default Use analytics_opt_out False Include in your fides.toml file. FIDES__USER__ANALYTICS_OPT_OUT False Include in your environment variables.","title":"Fideslog Analytics"},{"location":"development/fideslog/#fideslog-analytics","text":"Fides includes an implementation of fideslog to provide Ethyca with an understanding of user interactions with fides tooling. All collected analytics are anonymized, and only used in either product roadmap determination, or as insight into product adoption. Information collected by fideslog is received via HTTPs request, stored in a secure database, and never shared with third parties unless required by law. More information on use, implementation, and configuration can be found in the fideslog repository .","title":"Fideslog Analytics"},{"location":"development/fideslog/#collected-data","text":"Fideslog collects information on instances of Fides by recording internal events. Using Fides may result in sending any or all of the following analytics data to Ethyca: Parameter Description docker If fides is run in a docker container. event The type of analytics event - currently, either a server start or endpoint call . event_created The time of the event. endpoint The endpoint accessed. status_code The status result of the request. error Error information, if any.","title":"Collected Data"},{"location":"development/fideslog/#disabling-fideslog","text":"To opt out of analytics, set either the following fides environment variable or .toml configuration variable to True . Variable Default Use analytics_opt_out False Include in your fides.toml file. FIDES__USER__ANALYTICS_OPT_OUT False Include in your environment variables.","title":"Disabling Fideslog"},{"location":"development/jetbrains_debugging/","text":"Debugging Fides in IntelliJ IDEA Ultimate This guide will show how to use the IntelliJ debugger with Fides running in Docker. The setup for PyCharm Professional should be very similar. Prerequisites Intellij IDEA Ultimate or PyCharm Professional Docker plugin Python plugin (this is needed for Intellij) Docker Desktop Setup Connect to Docker daemon This step will allow the IDE to connect to Docker Desktop. Go to: Settings/Preferences -> Docker -> + Select Docker for \"your operating system\" See the screenshot below: Configure Python Remote Interpreter Define a Docker-based remote interpreter. Go to: File -> Project Structure... -> Platform Settings -> SDKs -> + Set Server to Docker Set Configuration files to .docker-compose.yml Set Python interpreter path to python After clicking OK the Remote Python Docker Compose should be listed as an SDK. See screenshots below: Run/Debug Configuration Set up a Run/Debug Configuration so that breakpoints can be hit in the f sourcecode. Go to: Run/Debug Configurations -> + -> Python To debug Fides, debug the <path on your machine>/src/fides/main.py script Make sure to select Use specified interpreter set the Remote Python Docker Compose (created in the previous section) Add FIDES__CONFIG_PATH=/fides to Environment variables See screenshot below: Hit a Breakpoint Now the IDE is ready to debug the source code. Click the debug button for main (setup in the previous section) . Try firing a http request to Fides from Postman or Curl and hit a break point. There is a postman collection in this repo: docs/fides/docs/development/postman/Fides.postman_collection.json Screenshot of hit breakpoint below: Links The information is this guide is largely based on these docs https://www.jetbrains.com/help/pycharm/using-docker-as-a-remote-interpreter.html https://www.jetbrains.com/help/idea/configuring-local-python-interpreters.html","title":"Jetbrains Debugging"},{"location":"development/jetbrains_debugging/#debugging-fides-in-intellij-idea-ultimate","text":"This guide will show how to use the IntelliJ debugger with Fides running in Docker. The setup for PyCharm Professional should be very similar.","title":"Debugging Fides in IntelliJ IDEA Ultimate"},{"location":"development/jetbrains_debugging/#prerequisites","text":"Intellij IDEA Ultimate or PyCharm Professional Docker plugin Python plugin (this is needed for Intellij) Docker Desktop","title":"Prerequisites"},{"location":"development/jetbrains_debugging/#setup","text":"","title":"Setup"},{"location":"development/jetbrains_debugging/#connect-to-docker-daemon","text":"This step will allow the IDE to connect to Docker Desktop. Go to: Settings/Preferences -> Docker -> + Select Docker for \"your operating system\" See the screenshot below:","title":"Connect to Docker daemon"},{"location":"development/jetbrains_debugging/#configure-python-remote-interpreter","text":"Define a Docker-based remote interpreter. Go to: File -> Project Structure... -> Platform Settings -> SDKs -> + Set Server to Docker Set Configuration files to .docker-compose.yml Set Python interpreter path to python After clicking OK the Remote Python Docker Compose should be listed as an SDK. See screenshots below:","title":"Configure Python Remote Interpreter"},{"location":"development/jetbrains_debugging/#rundebug-configuration","text":"Set up a Run/Debug Configuration so that breakpoints can be hit in the f sourcecode. Go to: Run/Debug Configurations -> + -> Python To debug Fides, debug the <path on your machine>/src/fides/main.py script Make sure to select Use specified interpreter set the Remote Python Docker Compose (created in the previous section) Add FIDES__CONFIG_PATH=/fides to Environment variables See screenshot below:","title":"Run/Debug Configuration"},{"location":"development/jetbrains_debugging/#hit-a-breakpoint","text":"Now the IDE is ready to debug the source code. Click the debug button for main (setup in the previous section) . Try firing a http request to Fides from Postman or Curl and hit a break point. There is a postman collection in this repo: docs/fides/docs/development/postman/Fides.postman_collection.json Screenshot of hit breakpoint below:","title":"Hit a Breakpoint"},{"location":"development/jetbrains_debugging/#links","text":"The information is this guide is largely based on these docs https://www.jetbrains.com/help/pycharm/using-docker-as-a-remote-interpreter.html https://www.jetbrains.com/help/idea/configuring-local-python-interpreters.html","title":"Links"},{"location":"development/overview/","text":"Development Overview Thanks for contributing to Fides! This section of the docs is designed to help you become familiar with how we work, the standards we apply, and how to ensure your contribution is successful. If you're stuck, don't be shy about asking for help on GitHub . Getting Started The first step is to clone the Fides repo for development: 1 git clone https://github.com/ethyca/fides Once that's complete, there are a few different ways to spin up the project and get coding! Developer Workflows There are a few different ways to develop Fides, they are listed below in order of how strongly they are recommended! The recommended way to work on Fides is by utilizing the Noxfile commands: Make sure that you have docker , docker-compose and nox ( pip install nox ) installed. Run nox in the root directory to see a list of all of the possible Nox commands. This is helpful as a reference when trying to find new commands or remember old ones! Run nox -s dev -- shell to spin up the entire fides application as well as a shell within the fides webserver container. You can and should run all of your various development commands from within this shell, such as pytest , black , etc. While it is possible to install all application dependencies and develop on the project without Docker, this is neither recommended nor tested. Issues MSSQL: Known issues around connecting to MSSQL exist today for Apple M1 users. M1 users that wish to install pyodbc locally, please reference the workaround here . Package not found: When running nox -s dev , if you get a importlib.metadata.PackageNotFoundError: fides , do nox -s dev -- shell , and then run pip install -e . . Verify Fides is installed with pip list . Write your code We have no doubt you can write amazing code! However, we want to help you ensure your code plays nicely with the rest of the Fides ecosystem. Many projects describe code style and documentation as a suggestion; in Fides it's a CI-checked requirement. To learn how to style your code, see the style guide . To learn how to migrate the database schema, see the database migration guide . To learn how to document your code, see the docs guide . To learn how to test your code, see the tests guide . To learn what format your PR should follow, make sure to follow the pull request guidelines . Submit your code In order to submit code to Fides, please: Fork the Fides repository Create a new branch on your fork Open a Pull Request once your work is ready for review Once automated tests have passed, a maintainer will review your PR and provide feedback on any changes it requires to be approved. Once approved, your PR will be merged into Fides. Congratulations You're a Fides contributor - welcome to the team! \ud83c\udf89","title":"Overview"},{"location":"development/overview/#development-overview","text":"Thanks for contributing to Fides! This section of the docs is designed to help you become familiar with how we work, the standards we apply, and how to ensure your contribution is successful. If you're stuck, don't be shy about asking for help on GitHub .","title":"Development Overview"},{"location":"development/overview/#getting-started","text":"The first step is to clone the Fides repo for development: 1 git clone https://github.com/ethyca/fides Once that's complete, there are a few different ways to spin up the project and get coding!","title":"Getting Started"},{"location":"development/overview/#developer-workflows","text":"There are a few different ways to develop Fides, they are listed below in order of how strongly they are recommended! The recommended way to work on Fides is by utilizing the Noxfile commands: Make sure that you have docker , docker-compose and nox ( pip install nox ) installed. Run nox in the root directory to see a list of all of the possible Nox commands. This is helpful as a reference when trying to find new commands or remember old ones! Run nox -s dev -- shell to spin up the entire fides application as well as a shell within the fides webserver container. You can and should run all of your various development commands from within this shell, such as pytest , black , etc. While it is possible to install all application dependencies and develop on the project without Docker, this is neither recommended nor tested.","title":"Developer Workflows"},{"location":"development/overview/#issues","text":"MSSQL: Known issues around connecting to MSSQL exist today for Apple M1 users. M1 users that wish to install pyodbc locally, please reference the workaround here . Package not found: When running nox -s dev , if you get a importlib.metadata.PackageNotFoundError: fides , do nox -s dev -- shell , and then run pip install -e . . Verify Fides is installed with pip list .","title":"Issues"},{"location":"development/overview/#write-your-code","text":"We have no doubt you can write amazing code! However, we want to help you ensure your code plays nicely with the rest of the Fides ecosystem. Many projects describe code style and documentation as a suggestion; in Fides it's a CI-checked requirement. To learn how to style your code, see the style guide . To learn how to migrate the database schema, see the database migration guide . To learn how to document your code, see the docs guide . To learn how to test your code, see the tests guide . To learn what format your PR should follow, make sure to follow the pull request guidelines .","title":"Write your code"},{"location":"development/overview/#submit-your-code","text":"In order to submit code to Fides, please: Fork the Fides repository Create a new branch on your fork Open a Pull Request once your work is ready for review Once automated tests have passed, a maintainer will review your PR and provide feedback on any changes it requires to be approved. Once approved, your PR will be merged into Fides.","title":"Submit your code"},{"location":"development/overview/#congratulations","text":"You're a Fides contributor - welcome to the team! \ud83c\udf89","title":"Congratulations"},{"location":"development/pull_requests/","text":"Pull Requests Pull requests are the primary unit of work within the Fides project. All code changes are expected to be submitted via a PR with the following requirements: Completely fill out the provided pull request template. PRs should be in a draft state until they are ready for a final review + merge. A non-draft PR signals to the community that the author believes the PR is ready to ship! If you need early feedback on your PR, feel free to ask for it directly while your PR is in a draft state. Make sure that all checks are passing, and all boxes have been checked before taking the PR out of a draft state. PR reviews require other people to spend their time, so please be courteous and double check your work before passing it to a reviewer. If you're unsure about a potential feature implementation or there is anything else that needs discussing, feel free to ask for an early review/feedback in the comments of the draft PR. PRs should be focused, reflecting a single logical change or feature. Generally, it is better to have multiple smaller PRs than one big one. This reduces the merge risk and shortens review time.","title":"Pull Requests"},{"location":"development/pull_requests/#pull-requests","text":"Pull requests are the primary unit of work within the Fides project. All code changes are expected to be submitted via a PR with the following requirements: Completely fill out the provided pull request template. PRs should be in a draft state until they are ready for a final review + merge. A non-draft PR signals to the community that the author believes the PR is ready to ship! If you need early feedback on your PR, feel free to ask for it directly while your PR is in a draft state. Make sure that all checks are passing, and all boxes have been checked before taking the PR out of a draft state. PR reviews require other people to spend their time, so please be courteous and double check your work before passing it to a reviewer. If you're unsure about a potential feature implementation or there is anything else that needs discussing, feel free to ask for an early review/feedback in the comments of the draft PR. PRs should be focused, reflecting a single logical change or feature. Generally, it is better to have multiple smaller PRs than one big one. This reduces the merge risk and shortens review time.","title":"Pull Requests"},{"location":"development/releases/","text":"Releases Versioning Fides uses semantic versioning. Due to the rapid development of the project, some minor versions may also contain minor breaking changes. The best practice is to always pin versions, and carefully test before bumping to a new version. Patch versions will never cause breaking changes, and are only used to hotfix critical bugs. Release schedule Fides does not follow a set release schedule, and instead ships versions based on the addition of features and functionality. Each release, with the exception of hotfixes, will contain at least one substantial new feature. Planning For each release, a corresponding GitHub Project is created. Issues are added to projects as a way to organize what will be included in each release. Once a release project is complete and the core team signs off on the readiness of the release, a new version is cut using GitHub releases. You can see all Fides releases here . Each new release triggers a GitHub Action that pushes the new version to PyPI, and a clean version to DockerHub. The release project is then marked as closed . Hotfixes are an exception to this, and can be added and pushed as patch versions when needed. Branching Fides uses continuous delivery with a single main branch. All code changes are merged into this branch. When releasing, a new tag is created, and the release process proceeds automatically. In the case of patches, a branch is created from the relevant tag. Commits are then cherry-picked into this branch, and a new patch version tag is created. Release Steps We use GitHub\u2019s release feature to tag releases that then get automatically deployed to DockerHub and PyPi via GitHub Actions pipelines. We also use a CHANGELOG.md to make sure that our users are never surprised about an upcoming change and can plan upgrades accordingly. The release steps are as follows: Major and Minor Open a PR that is titled the version of the release (i.e. 1.6.0 ) Rename the Unreleased section of CHANGELOG.md to the new version number and put a date next to it Update the compare links for both the new version and for the new Unreleased section Once approved, merge the PR Create a new release, ensuring that the last PR to get merged is the aforementioned CHANGELOG.md update PR Add the new version as the tag (i.e. 1.6.0 ) Make the title the version with a v in front of it (i.e. v1.6.0 ) Add a link to the CHANGELOG.md Auto-populate the release notes Publish the release Patch It may be necessary for a patch release to contain only select commits to the main branch since the last major or minor release. To create a release with only the desired changes, follow the steps below: Checkout the most recent release's tag To fetch the most recent tag's name, run: 1 2 3 4 # fides on main git describe --abbrev = 0 --tags #=> 1.2.3 To checkout the most recent tag, run: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #fides on main git checkout 1 .2.3 #=> Note: switching to '1.2.3'. # # You are in 'detached HEAD' state. You can look around, make experimental # changes and commit them, and you can discard any commits you make in this # state without impacting any branches by switching back to a branch. # # If you want to create a new branch to retain commits you create, you may # do so (now or later) by using -c with the switch command. Example: # # git switch -c <new-branch-name> # # Or undo this operation with: # # git switch - # # Turn off this advice by setting config variable advice.detachedHead to false # # HEAD is now at 0123abcd Commit Message Tip This can be combined into a single command: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # fides on main git checkout $( git describe --abbrev = 0 --tags ) #=> Note: switching to '1.2.3'. # # You are in 'detached HEAD' state. You can look around, make experimental # changes and commit them, and you can discard any commits you make in this # state without impacting any branches by switching back to a branch. # # If you want to create a new branch to retain commits you create, you may # do so (now or later) by using -c with the switch command. Example: # # git switch -c <new-branch-name> # # Or undo this operation with: # # git switch - # # Turn off this advice by setting config variable advice.detachedHead to false # # HEAD is now at 0123abcd Commit Message Create a new branch from the HEAD commit of the most recent release's tag, called release-v<tag> 1 2 3 4 # fides on tags/1.2.3 git checkout -b release-v1.2.4 #=> Switched to a new branch 'release-v1.2.4' If the changes to be included in the patch release are contained in one or more unmerged pull requests, change the base branch of the pull request(s) to the release branch created in the previous step Once approved, merge the pull request(s) into the release branch Create a new branch off of the release branch by running: 1 2 3 4 # fides on release-v1.2.4 git checkout -b prepare-release-v1.2.4 #=> Switched to a new branch 'prepare-release-v1.2.4' Optional: Incorporate any additional specific changes required for the patch release by running: 1 2 # fides on prepare-release-v1.2.4 git cherry-pick <commit>... Copy the Unreleased section of CHANGELOG.md and paste above the release being patched Rename Unreleased to the new version number and put a date next to it Cut and paste the documented changes that are now included in the patch release to the correct section Commit these changes Open a pull request to incorporate any cherry-picked commits and the CHANGELOG.md changes into the release branch Set the base branch of this pull request to the release branch Once approved, merge the pull request into the release branch Create a new release from the release branch Add the new version as the tag (i.e. 1.2.4 ) Title the release with the version number, prefixed with a v (i.e. v1.2.4 ) Add a link to the CHANGELOG.md Auto-populate the release notes Publish the release Merge the new release tag into main Warning Pushing commits (including merge commits) to the main branch requires admin-level repository permissions. Checkout the main branch, and update the local repository: 1 2 3 4 git checkout main #=> Switched to branch 'main'... git pull Merge the new release tag into main : 1 git merge tags/1.2.4 1. Handle any merge conflicts, and push to the remote main branch","title":"Releases"},{"location":"development/releases/#releases","text":"","title":"Releases"},{"location":"development/releases/#versioning","text":"Fides uses semantic versioning. Due to the rapid development of the project, some minor versions may also contain minor breaking changes. The best practice is to always pin versions, and carefully test before bumping to a new version. Patch versions will never cause breaking changes, and are only used to hotfix critical bugs.","title":"Versioning"},{"location":"development/releases/#release-schedule","text":"Fides does not follow a set release schedule, and instead ships versions based on the addition of features and functionality. Each release, with the exception of hotfixes, will contain at least one substantial new feature.","title":"Release schedule"},{"location":"development/releases/#planning","text":"For each release, a corresponding GitHub Project is created. Issues are added to projects as a way to organize what will be included in each release. Once a release project is complete and the core team signs off on the readiness of the release, a new version is cut using GitHub releases. You can see all Fides releases here . Each new release triggers a GitHub Action that pushes the new version to PyPI, and a clean version to DockerHub. The release project is then marked as closed . Hotfixes are an exception to this, and can be added and pushed as patch versions when needed.","title":"Planning"},{"location":"development/releases/#branching","text":"Fides uses continuous delivery with a single main branch. All code changes are merged into this branch. When releasing, a new tag is created, and the release process proceeds automatically. In the case of patches, a branch is created from the relevant tag. Commits are then cherry-picked into this branch, and a new patch version tag is created.","title":"Branching"},{"location":"development/releases/#release-steps","text":"We use GitHub\u2019s release feature to tag releases that then get automatically deployed to DockerHub and PyPi via GitHub Actions pipelines. We also use a CHANGELOG.md to make sure that our users are never surprised about an upcoming change and can plan upgrades accordingly. The release steps are as follows:","title":"Release Steps"},{"location":"development/releases/#major-and-minor","text":"Open a PR that is titled the version of the release (i.e. 1.6.0 ) Rename the Unreleased section of CHANGELOG.md to the new version number and put a date next to it Update the compare links for both the new version and for the new Unreleased section Once approved, merge the PR Create a new release, ensuring that the last PR to get merged is the aforementioned CHANGELOG.md update PR Add the new version as the tag (i.e. 1.6.0 ) Make the title the version with a v in front of it (i.e. v1.6.0 ) Add a link to the CHANGELOG.md Auto-populate the release notes Publish the release","title":"Major and Minor"},{"location":"development/releases/#patch","text":"It may be necessary for a patch release to contain only select commits to the main branch since the last major or minor release. To create a release with only the desired changes, follow the steps below: Checkout the most recent release's tag To fetch the most recent tag's name, run: 1 2 3 4 # fides on main git describe --abbrev = 0 --tags #=> 1.2.3 To checkout the most recent tag, run: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #fides on main git checkout 1 .2.3 #=> Note: switching to '1.2.3'. # # You are in 'detached HEAD' state. You can look around, make experimental # changes and commit them, and you can discard any commits you make in this # state without impacting any branches by switching back to a branch. # # If you want to create a new branch to retain commits you create, you may # do so (now or later) by using -c with the switch command. Example: # # git switch -c <new-branch-name> # # Or undo this operation with: # # git switch - # # Turn off this advice by setting config variable advice.detachedHead to false # # HEAD is now at 0123abcd Commit Message Tip This can be combined into a single command: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # fides on main git checkout $( git describe --abbrev = 0 --tags ) #=> Note: switching to '1.2.3'. # # You are in 'detached HEAD' state. You can look around, make experimental # changes and commit them, and you can discard any commits you make in this # state without impacting any branches by switching back to a branch. # # If you want to create a new branch to retain commits you create, you may # do so (now or later) by using -c with the switch command. Example: # # git switch -c <new-branch-name> # # Or undo this operation with: # # git switch - # # Turn off this advice by setting config variable advice.detachedHead to false # # HEAD is now at 0123abcd Commit Message Create a new branch from the HEAD commit of the most recent release's tag, called release-v<tag> 1 2 3 4 # fides on tags/1.2.3 git checkout -b release-v1.2.4 #=> Switched to a new branch 'release-v1.2.4' If the changes to be included in the patch release are contained in one or more unmerged pull requests, change the base branch of the pull request(s) to the release branch created in the previous step Once approved, merge the pull request(s) into the release branch Create a new branch off of the release branch by running: 1 2 3 4 # fides on release-v1.2.4 git checkout -b prepare-release-v1.2.4 #=> Switched to a new branch 'prepare-release-v1.2.4' Optional: Incorporate any additional specific changes required for the patch release by running: 1 2 # fides on prepare-release-v1.2.4 git cherry-pick <commit>... Copy the Unreleased section of CHANGELOG.md and paste above the release being patched Rename Unreleased to the new version number and put a date next to it Cut and paste the documented changes that are now included in the patch release to the correct section Commit these changes Open a pull request to incorporate any cherry-picked commits and the CHANGELOG.md changes into the release branch Set the base branch of this pull request to the release branch Once approved, merge the pull request into the release branch Create a new release from the release branch Add the new version as the tag (i.e. 1.2.4 ) Title the release with the version number, prefixed with a v (i.e. v1.2.4 ) Add a link to the CHANGELOG.md Auto-populate the release notes Publish the release Merge the new release tag into main Warning Pushing commits (including merge commits) to the main branch requires admin-level repository permissions. Checkout the main branch, and update the local repository: 1 2 3 4 git checkout main #=> Switched to branch 'main'... git pull Merge the new release tag into main : 1 git merge tags/1.2.4 1. Handle any merge conflicts, and push to the remote main branch","title":"Patch"},{"location":"development/testing/","text":"Testing Fides loves tests! There are a few important reasons to write tests: Make sure your code works Tests ensure that your code does the thing you intend it to do. If you have a function that adds two numbers, you'll want to test that it does, in fact, return their sum. If behavior depends on a configuration setting, ensure that changing that setting changes the behavior. In short, if you wrote a line of code, you should test that line works as expected. Make sure your code doesn't not work It may seem silly, but another important reason to write tests is to ensure that your code behaves as expected even when it's broken . This is especially important for a project like Fides, which is focused on helping engineers when something unexpected happens to their code. For example, you could write tests about what you expect to happen if your function is called with incorrect (or no) arguments, or to ensure that any errors are properly trapped and handled. Tests are documentation Ultimately, your tests are the best documentation for your code. Another developer should be able to look at your tests and understand what your code does, how to invoke it, and what edge cases it contains. Therefore, try to write short, self-explanatory tests with descriptive titles. Help future developers As Fides grows, your code will be reused in more and more places, by developers who may not be familiar with the details of your implementation. Therefore, your tests are an opportunity to ensure that your code is used correctly in the future. For example, if your code needs to be used in a certain way, or expects a certain configuration, or is always expected to return a certain output, or has any other details that might impact its ability to be used in the framework, write a test for it! At minimum, you'll help a future developer understand that you consciously chose to design your code a certain way. Writing tests Fides' tests are stored in the tests directory. Tests should have descriptive names that make it clear what you're testing. If necessary, add a docstring or comment to explain why you're testing this specific thing. 1 2 3 4 5 6 7 # Good test name def test_dry_evaluate_system_fail ( server_url , resources_dict ): ... # Bad test name def test_dry_evaluate (): ... Fides has a few pytest fixtures available for testing; see conftest.py for details. Integration tests vs. mocked tests Generally, tests that include mocking are discouraged. Mocking can create a false sense of security and obfuscate possible errors in the code that only present themselves when integration tested. Running tests Fides uses pytest for unit testing. To run tests, invoke pytest from the /fides/ctl/ directory: 1 2 cd ctl pytest Running specific tests To run a subset of tests, provide a filename or directory; to match a specific test name, use the -k flag: 1 2 # run all tests in the tests/integration directory that contain the word \"api\" in their title pytest tests/integration/ -k api The --sw flag will exit pytest the first time it encounters an error; subsequent runs with the same flag will skip any tests that succeeded and run the failed test first. For more information on available Pytest invocation options, see the documentation here . Excluding external tests Integration tests also test integration with external services like Snowflake which require internet access and authentication. It is possible to skip these tests by excluding the external mark. 1 2 # run all tests except external ones pytest -m \"not external\" CI Workflows CI will run automatically against any PR you open. Please run your tests locally first to avoid \"debugging in CI\", as this takes up resources that could be used by other contributors and is generally an inefficient usage of your time!","title":"Testing"},{"location":"development/testing/#testing","text":"Fides loves tests! There are a few important reasons to write tests: Make sure your code works Tests ensure that your code does the thing you intend it to do. If you have a function that adds two numbers, you'll want to test that it does, in fact, return their sum. If behavior depends on a configuration setting, ensure that changing that setting changes the behavior. In short, if you wrote a line of code, you should test that line works as expected. Make sure your code doesn't not work It may seem silly, but another important reason to write tests is to ensure that your code behaves as expected even when it's broken . This is especially important for a project like Fides, which is focused on helping engineers when something unexpected happens to their code. For example, you could write tests about what you expect to happen if your function is called with incorrect (or no) arguments, or to ensure that any errors are properly trapped and handled. Tests are documentation Ultimately, your tests are the best documentation for your code. Another developer should be able to look at your tests and understand what your code does, how to invoke it, and what edge cases it contains. Therefore, try to write short, self-explanatory tests with descriptive titles. Help future developers As Fides grows, your code will be reused in more and more places, by developers who may not be familiar with the details of your implementation. Therefore, your tests are an opportunity to ensure that your code is used correctly in the future. For example, if your code needs to be used in a certain way, or expects a certain configuration, or is always expected to return a certain output, or has any other details that might impact its ability to be used in the framework, write a test for it! At minimum, you'll help a future developer understand that you consciously chose to design your code a certain way.","title":"Testing"},{"location":"development/testing/#writing-tests","text":"Fides' tests are stored in the tests directory. Tests should have descriptive names that make it clear what you're testing. If necessary, add a docstring or comment to explain why you're testing this specific thing. 1 2 3 4 5 6 7 # Good test name def test_dry_evaluate_system_fail ( server_url , resources_dict ): ... # Bad test name def test_dry_evaluate (): ... Fides has a few pytest fixtures available for testing; see conftest.py for details.","title":"Writing tests"},{"location":"development/testing/#integration-tests-vs-mocked-tests","text":"Generally, tests that include mocking are discouraged. Mocking can create a false sense of security and obfuscate possible errors in the code that only present themselves when integration tested.","title":"Integration tests vs. mocked tests"},{"location":"development/testing/#running-tests","text":"Fides uses pytest for unit testing. To run tests, invoke pytest from the /fides/ctl/ directory: 1 2 cd ctl pytest","title":"Running tests"},{"location":"development/testing/#running-specific-tests","text":"To run a subset of tests, provide a filename or directory; to match a specific test name, use the -k flag: 1 2 # run all tests in the tests/integration directory that contain the word \"api\" in their title pytest tests/integration/ -k api The --sw flag will exit pytest the first time it encounters an error; subsequent runs with the same flag will skip any tests that succeeded and run the failed test first. For more information on available Pytest invocation options, see the documentation here .","title":"Running specific tests"},{"location":"development/testing/#excluding-external-tests","text":"Integration tests also test integration with external services like Snowflake which require internet access and authentication. It is possible to skip these tests by excluding the external mark. 1 2 # run all tests except external ones pytest -m \"not external\"","title":"Excluding external tests"},{"location":"development/testing/#ci-workflows","text":"CI will run automatically against any PR you open. Please run your tests locally first to avoid \"debugging in CI\", as this takes up resources that could be used by other contributors and is generally an inefficient usage of your time!","title":"CI Workflows"},{"location":"development/ui/","text":"Local Development To test the UI locally, clone the FidesOps repository , and ensure you have Node.js installed to run the application. Creating the root user A root user can be created by adding a root_username and root_password to the security section of fidesops.toml file, or by setting FIDESOPS__SECURITY__ROOT_USERNAME and FIDESOPS__SECURITY__ROOT_PASSWORD environment variables. This will allow you to login in with a root user that can be used to access additional user endpoints . Accessing the Control Panel From the root fidesops directory, run the following: 1 2 3 cd clients/admin-ui npm install npm run dev This will navigate you to the admin-ui directory, and run the development environment. Visit http://localhost:3000/ in your browser, and provide your user credentials to log in. Authentication To enable stable authentication you must supply a NEXTAUTH_SECRET environment variable. The best way to do this is by creating a .env.local file, which Next will automatically pick up: 1 echo NEXTAUTH_SECRET = ` openssl rand -base64 32 ` >> .env.local Backend deployment Fidesops automatically serves a version of the UI when running nox -s dev . To deploy a full version of the UI from a backend, run the following from the root fidesops directory: 1 2 3 cd clients/admin-ui npm install npm run prod-export This will build and place the Admin UI files into a location accessible by backend fidesops deployments. To test the UI, run nox -s dev from the root directory, and visit http://0.0.0.0:8080/index.html .","title":"UI Development"},{"location":"development/ui/#local-development","text":"To test the UI locally, clone the FidesOps repository , and ensure you have Node.js installed to run the application.","title":"Local Development"},{"location":"development/ui/#creating-the-root-user","text":"A root user can be created by adding a root_username and root_password to the security section of fidesops.toml file, or by setting FIDESOPS__SECURITY__ROOT_USERNAME and FIDESOPS__SECURITY__ROOT_PASSWORD environment variables. This will allow you to login in with a root user that can be used to access additional user endpoints .","title":"Creating the root user"},{"location":"development/ui/#accessing-the-control-panel","text":"From the root fidesops directory, run the following: 1 2 3 cd clients/admin-ui npm install npm run dev This will navigate you to the admin-ui directory, and run the development environment. Visit http://localhost:3000/ in your browser, and provide your user credentials to log in.","title":"Accessing the Control Panel"},{"location":"development/ui/#authentication","text":"To enable stable authentication you must supply a NEXTAUTH_SECRET environment variable. The best way to do this is by creating a .env.local file, which Next will automatically pick up: 1 echo NEXTAUTH_SECRET = ` openssl rand -base64 32 ` >> .env.local","title":"Authentication"},{"location":"development/ui/#backend-deployment","text":"Fidesops automatically serves a version of the UI when running nox -s dev . To deploy a full version of the UI from a backend, run the following from the root fidesops directory: 1 2 3 cd clients/admin-ui npm install npm run prod-export This will build and place the Admin UI files into a location accessible by backend fidesops deployments. To test the UI, run nox -s dev from the root directory, and visit http://0.0.0.0:8080/index.html .","title":"Backend deployment"},{"location":"development/update_erd_diagram/","text":"Updating database diagram If you make updates to the Fides application database, you should update the DB Architecture diagram in the documentation. Connect DBeaver to our app DB container DBeaver > Database > New Database Connection > PostgreSQL Add configuration details Right-click on postgres connection > Create > Other Select ER Diagram, Click Next Drill down to Postgres > app > Schemas > public and click the checkbox. Add a name to your ER Diagram Click Finish Drag and drop tables so they are less messy. File > Save As (app_database.png) Replace img/app_database.png with the new file","title":"Updating the Database Diagram"},{"location":"development/update_erd_diagram/#updating-database-diagram","text":"If you make updates to the Fides application database, you should update the DB Architecture diagram in the documentation. Connect DBeaver to our app DB container DBeaver > Database > New Database Connection > PostgreSQL Add configuration details Right-click on postgres connection > Create > Other Select ER Diagram, Click Next Drill down to Postgres > app > Schemas > public and click the checkbox. Add a name to your ER Diagram Click Finish Drag and drop tables so they are less messy. File > Save As (app_database.png) Replace img/app_database.png with the new file","title":"Updating database diagram"},{"location":"development/postman/using_postman/","text":"Using the Fides postman collection A minimal Postman collection is included to assist in setting up your privacy request configurations, and in executing example access and erasure requests against mock external databases. Loading the collection Get Postman Postman > File > Import Upload the Fides collection found in docs/fides/docs/postman/Fides.postman_collection.json Click on the imported fidesops collection in the left pane, and then find Variables to edit the fidesops collection variables. Some variables are populated for you, and some will be added in this guide's next steps. Add your oauth_root_client_id and oauth_root_client_secret under CURRENT VALUE . fidesadmin and fidesadminsecret are default configurations for testing, found in your fides.toml . Add the appropriate values for your instance if they differ. Important: Click Save ! Bring up local servers and mock databases Run nox -s dev -- <datastore> in your terminal. This brings up the Fides server and the list of datastores specified, i.e. nox -s dev -- postgres mongodb . These mock datastores are pre-populated with test data to represent your datastores. The following list of requests is kept in the Minimum API calls to create an Access Privacy Request folder. Some of the returned data will need to be saved as additional variables for use in other steps. Saving Authentication variables Click on the Get Root Client Token request, and click Send to send a POST request to Fides to create a root token. Copy the access_token returned in the response body, and paste it as the Current Value of root_client_token in Fides' variables. Important: Click Save ! Similarly, click on Create Client , and click Send to send a POST request to Fides to create a new client. Copy the client_id and client_secret and paste into Current Value slots in Fides variables and click \"Save\". Finally, click on the Get Client Token request, and click Send to send another POST request to Fides. This will create a token for the client made in the previous step. If you click on Body , you can see that the client_id and client_secret have been added as form data for you. Save the returned token under client_token in the Fides variables. The client_token will be automatically passed into the rest of your requests as the Bearer Token. Building out remaining privacy request configuration Run through the remaining requests in the Minimum API calls to create an Access Privacy Request folder. Because variables are automatically being populated for you, you should be able to click on each request, clicking Send for each one. Inspect the Body of each request to see what is sent to Fides: Specify where your data is going: SEND Create/Update Storage - Local Storage Config - Sets up a local folder for uploading your privacy request results (local testing only) Configure what data you care about, and what to do with it: SEND Create/Update Policies - Creates a Policy to handle Privacy Requests SEND Create/Update Access Rule - Defines an access Rule on the previous Policy, which specifies results will be uploaded to the configured local storage SEND Create/Update Rule Targets - Specify a RuleTarget that says to will return data that has been marked as having a user data category Create ConnectionConfigs, and add connection secrets for the postgres_example and mongodb_example mock databases: SEND Create/Update Connection Configs: Postgres SEND Create/Update Connection Configs: Mongo SEND Update Connection Secrets: Postgres SEND Update Connection Secrets: Mongo Add annotations of the Postgres and Mongo datastores: SEND Create/Update Postgres Dataset SEND Create/Update Dataset Mongo API calls to additional supported datastores (MsSQL, MySQL) are in separate folders within the collection. Run a privacy request You have now completed the basic configuration required to create an Access Request. SEND Create Access Privacy Requests If \"succeeded\", note the \"id\" that is returned. Succeeded means the privacy request has been created and is pending, not that its execution is complete. Check your local fides_uploads folder, configured earlier, to see access request results. This is run asynchronously, so it may take a few moments to complete. This particular request should have retrieved data from both the postgres_example and mongodb_example databases with the user data_category Next steps Check out other requests in the collection! The Calls to create an Erasure Request folder walks you through configuring a separate erasure policy, and executing an erasure request. Note that these erasure requests will mask data in your connected datastores ( postgres_example and mongo_example here. If you connect your own live databases, data may be deleted. Happy experimenting!","title":"Using Postman"},{"location":"development/postman/using_postman/#using-the-fides-postman-collection","text":"A minimal Postman collection is included to assist in setting up your privacy request configurations, and in executing example access and erasure requests against mock external databases.","title":"Using the Fides postman collection"},{"location":"development/postman/using_postman/#loading-the-collection","text":"Get Postman Postman > File > Import Upload the Fides collection found in docs/fides/docs/postman/Fides.postman_collection.json Click on the imported fidesops collection in the left pane, and then find Variables to edit the fidesops collection variables. Some variables are populated for you, and some will be added in this guide's next steps. Add your oauth_root_client_id and oauth_root_client_secret under CURRENT VALUE . fidesadmin and fidesadminsecret are default configurations for testing, found in your fides.toml . Add the appropriate values for your instance if they differ. Important: Click Save !","title":"Loading the collection"},{"location":"development/postman/using_postman/#bring-up-local-servers-and-mock-databases","text":"Run nox -s dev -- <datastore> in your terminal. This brings up the Fides server and the list of datastores specified, i.e. nox -s dev -- postgres mongodb . These mock datastores are pre-populated with test data to represent your datastores. The following list of requests is kept in the Minimum API calls to create an Access Privacy Request folder. Some of the returned data will need to be saved as additional variables for use in other steps.","title":"Bring up local servers and mock databases"},{"location":"development/postman/using_postman/#saving-authentication-variables","text":"Click on the Get Root Client Token request, and click Send to send a POST request to Fides to create a root token. Copy the access_token returned in the response body, and paste it as the Current Value of root_client_token in Fides' variables. Important: Click Save ! Similarly, click on Create Client , and click Send to send a POST request to Fides to create a new client. Copy the client_id and client_secret and paste into Current Value slots in Fides variables and click \"Save\". Finally, click on the Get Client Token request, and click Send to send another POST request to Fides. This will create a token for the client made in the previous step. If you click on Body , you can see that the client_id and client_secret have been added as form data for you. Save the returned token under client_token in the Fides variables. The client_token will be automatically passed into the rest of your requests as the Bearer Token.","title":"Saving Authentication variables"},{"location":"development/postman/using_postman/#building-out-remaining-privacy-request-configuration","text":"Run through the remaining requests in the Minimum API calls to create an Access Privacy Request folder. Because variables are automatically being populated for you, you should be able to click on each request, clicking Send for each one. Inspect the Body of each request to see what is sent to Fides: Specify where your data is going: SEND Create/Update Storage - Local Storage Config - Sets up a local folder for uploading your privacy request results (local testing only) Configure what data you care about, and what to do with it: SEND Create/Update Policies - Creates a Policy to handle Privacy Requests SEND Create/Update Access Rule - Defines an access Rule on the previous Policy, which specifies results will be uploaded to the configured local storage SEND Create/Update Rule Targets - Specify a RuleTarget that says to will return data that has been marked as having a user data category Create ConnectionConfigs, and add connection secrets for the postgres_example and mongodb_example mock databases: SEND Create/Update Connection Configs: Postgres SEND Create/Update Connection Configs: Mongo SEND Update Connection Secrets: Postgres SEND Update Connection Secrets: Mongo Add annotations of the Postgres and Mongo datastores: SEND Create/Update Postgres Dataset SEND Create/Update Dataset Mongo API calls to additional supported datastores (MsSQL, MySQL) are in separate folders within the collection.","title":"Building out remaining privacy request configuration"},{"location":"development/postman/using_postman/#run-a-privacy-request","text":"You have now completed the basic configuration required to create an Access Request. SEND Create Access Privacy Requests If \"succeeded\", note the \"id\" that is returned. Succeeded means the privacy request has been created and is pending, not that its execution is complete. Check your local fides_uploads folder, configured earlier, to see access request results. This is run asynchronously, so it may take a few moments to complete. This particular request should have retrieved data from both the postgres_example and mongodb_example databases with the user data_category","title":"Run a privacy request"},{"location":"development/postman/using_postman/#next-steps","text":"Check out other requests in the collection! The Calls to create an Erasure Request folder walks you through configuring a separate erasure policy, and executing an erasure request. Note that these erasure requests will mask data in your connected datastores ( postgres_example and mongo_example here. If you connect your own live databases, data may be deleted. Happy experimenting!","title":"Next steps"},{"location":"getting-started/database_connectors/","text":"Connect to SQL and NoSQL Databases What is a Connection? A Connection links your owned databases and third-party applications to Fides, allowing Fides to execute privacy requests against your collections and fields. Fides currently supports connections to the following databases: PostgreSQL MongoDB MySQL MariaDB Microsoft SQLServer Amazon Redshift Snowflake Google BigQuery Other platforms will be added in future releases. How do Connections differ from Datasets? A Dataset is model of your database that describes the data contained within each field. A Connection stores the secrets to connect to the database. After Fides connects to your database, it dynamically generates queries to fulfil privacy requests by consulting the annotations in the Dataset. Create a new Connection The connection between Fides and your database is represented by a Connection . To create a new Connection, issue a request to the Connection endpoint, passing a payload that contains the properties listed below. Field Description name A human-readable name for your database. key A string token that uniquely identifies this Connection. If you don't supply a key , the name value, converted to snake-case, is used. connection-type Specifies the type of database. Valid values are postgres , mongodb , mysql , mariadb , mssql , redshift , snowflake , and bigquery . access The connection's permissions, either read (Fides may only read from your database) or write (Fides can read from and write to your database). disabled determines whether the Connection is active. If True , Fides will skip running queries for any collection associated with that Connection. description Optional. An extra field to add further details about your Connection. While the Connection contains meta information about the database, it does not identify the database itself. Examples All of the following are PATCH requests to api/v1/connection . PostgreSQL 1 2 3 4 5 6 7 8 [ { \"name\" : \"Application PostgreSQL DB\" , \"key\" : \"application_postgresql_db\" , \"connection_type\" : \"postgres\" , \"access\" : \"read\" } ] MongoDB 1 2 3 4 5 6 7 8 9 [ { \"name\" : \"My Mongo DB\" , \"key\" : \"my_mongo_db\" , \"connection_type\" : \"mongodb\" , \"access\" : \"write\" , \"disabled\" : false } ] MySQL 1 2 3 4 5 6 7 8 9 [ { \"name\" : \"My MySQL DB\" , \"key\" : \"my_mysql_db\" , \"connection_type\" : \"mysql\" , \"access\" : \"write\" , \"disabled\" : false } ] MariaDB 1 2 3 4 5 6 7 8 9 [ { \"name\" : \"My Maria DB\" , \"key\" : \"my_maria_db\" , \"connection_type\" : \"mariadb\" , \"access\" : \"write\" , \"disabled\" : false } ] MsSQL 1 2 3 4 5 6 7 8 9 [ { \"name\" : \"My MsSQL DB\" , \"key\" : \"my_mssql_db\" , \"connection_type\" : \"mssql\" , \"access\" : \"write\" , \"disabled\" : false } ] Manual Connections 1 2 3 4 5 6 7 8 9 10 [ { \"name\" : \"Manual connector\" , \"key\" : \"manual_connector\" , \"connection_type\" : \"manual\" , \"access\" : \"read\" , \"disabled\" : false , \"description\" : \"Connector describing manual actions\" } ] Set the Connection secrets After creating a new Connection, you explain how to connect to it by setting its \"secrets\": the host, port, user, and password. These values are specific to each database, and should reference the user and password you would like Fides to use when accessing your database. Call the Connection Secrets endpoint. You can set the Connection attributes separately, or supply a single url string that encodes them all. Fides encrypts all Connection secrets values before they're stored. Set the secrets separately This example sets the database secrets through separate properties and then tests the connection. PUT /api/v1/connection/application-postgresql-db/secret?verify=true 1 2 3 4 5 6 7 { \"host\" : \"host.docker.internal\" , \"port\" : 5432 , \"dbname\" : \"postgres_example\" , \"username\" : \"postgres\" , \"password\" : \"postgres\" } Set the secrets as a URL This example sets the database secrets as a single url property, and skips the connection test. PUT api/v1/connection/my_mongo_db/secret?verify=false 1 2 3 { \"url\" : \"mongodb://mongo_user:mongo_pass@mongodb_example/mongo_test\" } Examples Amazon Redshift PUT api/v1/connection/my_redshift_db/secret 1 2 3 4 { \"url\" : \"redshift+psycopg2://username@host.amazonaws.com:5439/database\" , \"db_schema\" : \"my_test_schema\" } This Amazon Redshift example sets the database secrets using a url property and a db_schema property. Redshift databases have one or more schemas, with the default being named public . If you need to use a different schema, specify a db_schema when setting your secrets, and it will be set as the search_path for querying. Google BigQuery PUT api/v1/connection/my_bigquery_db/secret 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"dataset\" : \"some-dataset\" , \"keyfile_creds\" : { \"type\" : \"service_account\" , \"project_id\" : \"project-12345\" , \"private_key_id\" : \"qo28cy4nlwu\" , \"private_key\" : \"-----BEGIN PRIVATE KEY-----\\nqi2unhflhncflkjas\\nkqiu34c\\n-----END PRIVATE KEY-----\\n\" , \"client_email\" : \"something@project-12345.iam.gserviceaccount.com\" , \"client_id\" : \"287345028734538\" , \"auth_uri\" : \"https://accounts.google.com/o/oauth2/auth\" , \"token_uri\" : \"https://oauth2.googleapis.com/token\" , \"auth_provider_x509_cert_url\" : \"https://www.googleapis.com/oauth2/v1/certs\" , \"client_x509_cert_url\" : \"https://www.googleapis.com/robot/v1/metadata/x509/something%40project-12345.iam.gserviceaccount.com\" } } Google BigQuery requires two parameters: dataset - The name of your dataset. BigQuery datasets are top-level containers (within a project) that are used to organize and control access to your tables and views. keyfile_creds - The credentials from your service account JSON keyfile, accessible for download from the GCP console. Test your connection When setting your Connection secrets, setting the verify query parameter to true allows you to test the Connection by issuing a trivial request to the database. The test_status response property announces the test result as succeeded or failed . If the attempt has failed, the failure_reason property gives further details about the failure. To skip the connection test, set verify to false . You can verify that a Connection's secrets are valid at any time by calling the Test a Connection's Secrets endpoint: GET 1 /api/v1/connection/application-postgresql-db/test Test failures can be resolved by calling the Set a Connection's Secrets endpoint, and resetting the secret values. Success 1 2 3 4 5 { \"msg\" : \"Test completed for ConnectionConfig with key: app_postgres_db.\" , \"test_status\" : \"succeeded\" , \"failure_reason\" : null } Failure 1 2 3 4 5 { \"msg\" : \"Secrets updated for ConnectionConfig with key: app_mongo_db.\" , \"test_status\" : \"failed\" , \"failure_reason\" : \"Operation Failure connecting to MongoDB.\" } Associate a Dataset Once you have a working Connection, it must be associated to an existing dataset . This enables Fides to map and access the contents of your database. Call the /dataset endpoint with a JSON version of your dataset as the request body: PATCH /api/v1/connection/my_connection_key/dataset 1 2 3 4 5 6 [{ \"fides_key\" : \"example_test_dataset\" , \"name\" : \"Example Test Dataset\" , \"description\" : \"Example of a dataset containing a variety of related tables like customers, products, addresses, etc.\" , \"collections\" : [ ... ] }] Filtering your Connections Fides can filter and return matching Connections based on the connection_type , the testing_status , the system_status , and whether the connection is disabled . Connection type filter Including multiple connection_type query parameters and values will result in a query that looks for any connections with that type: GET api/v1//connection/?connection_type=mariadb&connection_type=postgres 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 { \"items\" : [ { \"name\" : \"Application Maria DB\" , \"key\" : \"app_mariadb_db\" , \"description\" : null , \"connection_type\" : \"mariadb\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:21:02.353226+00:00\" , \"updated_at\" : \"2022-06-16T22:21:02.353226+00:00\" , \"disabled\" : false , \"last_test_timestamp\" : null , \"last_test_succeeded\" : null }, { \"name\" : \"Application PostgreSQL DB\" , \"key\" : \"app_postgres_db\" , \"description\" : \"postgres backup\" , \"connection_type\" : \"postgres\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:20:24.972539+00:00\" , \"updated_at\" : \"2022-06-16T22:20:24.972539+00:00\" , \"disabled\" : false , \"last_test_timestamp\" : null , \"last_test_succeeded\" : null } ], \"total\" : 2 , \"page\" : 1 , \"size\" : 50 } Disabled filter The disabled filter will return datastores are skipped as part of privacy request execution: GET api/v1/connection/?disabled=true 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"items\" : [ { \"name\" : \"My Mongo DB\" , \"key\" : \"app_mongo_db\" , \"description\" : \"Primary Mongo DB\" , \"connection_type\" : \"mongodb\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"updated_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"disabled\" : true , \"last_test_timestamp\" : null , \"last_test_succeeded\" : null } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } Test_Status filter The test_status filter queries on the status of the last successful test: GET api/v1/connection/?test_status=false 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"items\" : [ { \"name\" : \"My Mongo DB\" , \"key\" : \"app_mongo_db\" , \"description\" : \"Primary Mongo DB\" , \"connection_type\" : \"mongodb\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"updated_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"disabled\" : true , \"last_test_timestamp\" : 2022-06-16 T 22 : 20 : 34.122212+00 : 00 , \"last_test_succeeded\" : false } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } System_Status filter The system_status filter surfaces either database or saas -type connectors: GET api/v1/connection/?system_type=database 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"items\" : [ { \"name\" : \"My Mongo DB\" , \"key\" : \"app_mongo_db\" , \"description\" : \"Primary Mongo DB\" , \"connection_type\" : \"mongodb\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"updated_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"disabled\" : true , \"last_test_timestamp\" : 2022-06-16 T 22 : 20 : 34.122212+00 : 00 , \"last_test_succeeded\" : false } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } Search your Connections You can search the name , key , and description fields of your Connections with the search query parameter. GET /api/v1/connection/?search=application mysql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"items\" : [ { \"name\" : \"Application MySQL DB\" , \"key\" : \"app_mysql_db\" , \"description\" : \"My Backup MySQL DB\" , \"connection_type\" : \"mysql\" , \"access\" : \"read\" , \"created_at\" : \"2022-06-13T18:03:28.404091+00:00\" , \"updated_at\" : \"2022-06-13T18:03:28.404091+00:00\" , \"last_test_timestamp\" : null , \"last_test_succeeded\" : null } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } View available connection types To view a list of all available connection types, visit GET /api/v1/connection_type . This endpoint can be filtered with a search query parameter, and is subject to change. Both database options and third party API services are included. GET /api/v1/connection_type 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 { \"items\" : [ { \"identifier\" : \"bigquery\" , \"type\" : \"database\" }, { \"identifier\" : \"mariadb\" , \"type\" : \"database\" }, { \"identifier\" : \"mongodb\" , \"type\" : \"database\" }, { \"identifier\" : \"mssql\" , \"type\" : \"database\" }, { \"identifier\" : \"mysql\" , \"type\" : \"database\" }, { \"identifier\" : \"postgres\" , \"type\" : \"database\" }, { \"identifier\" : \"redshift\" , \"type\" : \"database\" }, { \"identifier\" : \"snowflake\" , \"type\" : \"database\" }, { \"identifier\" : \"adobe_campaign\" , \"type\" : \"saas\" }, { \"identifier\" : \"auth0\" , \"type\" : \"saas\" }, { \"identifier\" : \"datadog\" , \"type\" : \"saas\" }, { \"identifier\" : \"hubspot\" , \"type\" : \"saas\" }, { \"identifier\" : \"logi_id\" , \"type\" : \"saas\" }, { \"identifier\" : \"mailchimp\" , \"type\" : \"saas\" }, { \"identifier\" : \"outreach\" , \"type\" : \"saas\" }, { \"identifier\" : \"salesforce\" , \"type\" : \"saas\" }, { \"identifier\" : \"segment\" , \"type\" : \"saas\" }, { \"identifier\" : \"sendgrid\" , \"type\" : \"saas\" }, { \"identifier\" : \"sentry\" , \"type\" : \"saas\" }, { \"identifier\" : \"stripe\" , \"type\" : \"saas\" }, { \"identifier\" : \"zendesk\" , \"type\" : \"saas\" } ], \"total\" : 21 , \"page\" : 1 , \"size\" : 50 } View required connection secrets To view the secrets needed to authenticate with a given connection, visit GET /api/v1/connection_type/<connection_type>/secret . GET /api/v1/connection_type/sentry/secret 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"title\" : \"sentry_schema\" , \"description\" : \"Sentry secrets schema\" , \"type\" : \"object\" , \"properties\" : { \"access_token\" : { \"title\" : \"Access Token\" , \"type\" : \"string\" }, \"domain\" : { \"title\" : \"Domain\" , \"default\" : \"sentry.io\" , \"type\" : \"string\" } }, \"required\" : [ \"access_token\" ], \"additionalProperties\" : false }","title":"Connect to Databases"},{"location":"getting-started/database_connectors/#connect-to-sql-and-nosql-databases","text":"","title":"Connect to SQL and NoSQL Databases"},{"location":"getting-started/database_connectors/#what-is-a-connection","text":"A Connection links your owned databases and third-party applications to Fides, allowing Fides to execute privacy requests against your collections and fields. Fides currently supports connections to the following databases: PostgreSQL MongoDB MySQL MariaDB Microsoft SQLServer Amazon Redshift Snowflake Google BigQuery Other platforms will be added in future releases.","title":"What is a Connection?"},{"location":"getting-started/database_connectors/#how-do-connections-differ-from-datasets","text":"A Dataset is model of your database that describes the data contained within each field. A Connection stores the secrets to connect to the database. After Fides connects to your database, it dynamically generates queries to fulfil privacy requests by consulting the annotations in the Dataset.","title":"How do Connections differ from Datasets?"},{"location":"getting-started/database_connectors/#create-a-new-connection","text":"The connection between Fides and your database is represented by a Connection . To create a new Connection, issue a request to the Connection endpoint, passing a payload that contains the properties listed below. Field Description name A human-readable name for your database. key A string token that uniquely identifies this Connection. If you don't supply a key , the name value, converted to snake-case, is used. connection-type Specifies the type of database. Valid values are postgres , mongodb , mysql , mariadb , mssql , redshift , snowflake , and bigquery . access The connection's permissions, either read (Fides may only read from your database) or write (Fides can read from and write to your database). disabled determines whether the Connection is active. If True , Fides will skip running queries for any collection associated with that Connection. description Optional. An extra field to add further details about your Connection. While the Connection contains meta information about the database, it does not identify the database itself.","title":"Create a new Connection"},{"location":"getting-started/database_connectors/#examples","text":"All of the following are PATCH requests to api/v1/connection . PostgreSQL 1 2 3 4 5 6 7 8 [ { \"name\" : \"Application PostgreSQL DB\" , \"key\" : \"application_postgresql_db\" , \"connection_type\" : \"postgres\" , \"access\" : \"read\" } ] MongoDB 1 2 3 4 5 6 7 8 9 [ { \"name\" : \"My Mongo DB\" , \"key\" : \"my_mongo_db\" , \"connection_type\" : \"mongodb\" , \"access\" : \"write\" , \"disabled\" : false } ] MySQL 1 2 3 4 5 6 7 8 9 [ { \"name\" : \"My MySQL DB\" , \"key\" : \"my_mysql_db\" , \"connection_type\" : \"mysql\" , \"access\" : \"write\" , \"disabled\" : false } ] MariaDB 1 2 3 4 5 6 7 8 9 [ { \"name\" : \"My Maria DB\" , \"key\" : \"my_maria_db\" , \"connection_type\" : \"mariadb\" , \"access\" : \"write\" , \"disabled\" : false } ] MsSQL 1 2 3 4 5 6 7 8 9 [ { \"name\" : \"My MsSQL DB\" , \"key\" : \"my_mssql_db\" , \"connection_type\" : \"mssql\" , \"access\" : \"write\" , \"disabled\" : false } ] Manual Connections 1 2 3 4 5 6 7 8 9 10 [ { \"name\" : \"Manual connector\" , \"key\" : \"manual_connector\" , \"connection_type\" : \"manual\" , \"access\" : \"read\" , \"disabled\" : false , \"description\" : \"Connector describing manual actions\" } ]","title":"Examples"},{"location":"getting-started/database_connectors/#set-the-connection-secrets","text":"After creating a new Connection, you explain how to connect to it by setting its \"secrets\": the host, port, user, and password. These values are specific to each database, and should reference the user and password you would like Fides to use when accessing your database. Call the Connection Secrets endpoint. You can set the Connection attributes separately, or supply a single url string that encodes them all. Fides encrypts all Connection secrets values before they're stored.","title":"Set the Connection secrets"},{"location":"getting-started/database_connectors/#set-the-secrets-separately","text":"This example sets the database secrets through separate properties and then tests the connection. PUT /api/v1/connection/application-postgresql-db/secret?verify=true 1 2 3 4 5 6 7 { \"host\" : \"host.docker.internal\" , \"port\" : 5432 , \"dbname\" : \"postgres_example\" , \"username\" : \"postgres\" , \"password\" : \"postgres\" }","title":"Set the secrets separately"},{"location":"getting-started/database_connectors/#set-the-secrets-as-a-url","text":"This example sets the database secrets as a single url property, and skips the connection test. PUT api/v1/connection/my_mongo_db/secret?verify=false 1 2 3 { \"url\" : \"mongodb://mongo_user:mongo_pass@mongodb_example/mongo_test\" }","title":"Set the secrets as a URL"},{"location":"getting-started/database_connectors/#examples_1","text":"Amazon Redshift PUT api/v1/connection/my_redshift_db/secret 1 2 3 4 { \"url\" : \"redshift+psycopg2://username@host.amazonaws.com:5439/database\" , \"db_schema\" : \"my_test_schema\" } This Amazon Redshift example sets the database secrets using a url property and a db_schema property. Redshift databases have one or more schemas, with the default being named public . If you need to use a different schema, specify a db_schema when setting your secrets, and it will be set as the search_path for querying. Google BigQuery PUT api/v1/connection/my_bigquery_db/secret 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"dataset\" : \"some-dataset\" , \"keyfile_creds\" : { \"type\" : \"service_account\" , \"project_id\" : \"project-12345\" , \"private_key_id\" : \"qo28cy4nlwu\" , \"private_key\" : \"-----BEGIN PRIVATE KEY-----\\nqi2unhflhncflkjas\\nkqiu34c\\n-----END PRIVATE KEY-----\\n\" , \"client_email\" : \"something@project-12345.iam.gserviceaccount.com\" , \"client_id\" : \"287345028734538\" , \"auth_uri\" : \"https://accounts.google.com/o/oauth2/auth\" , \"token_uri\" : \"https://oauth2.googleapis.com/token\" , \"auth_provider_x509_cert_url\" : \"https://www.googleapis.com/oauth2/v1/certs\" , \"client_x509_cert_url\" : \"https://www.googleapis.com/robot/v1/metadata/x509/something%40project-12345.iam.gserviceaccount.com\" } } Google BigQuery requires two parameters: dataset - The name of your dataset. BigQuery datasets are top-level containers (within a project) that are used to organize and control access to your tables and views. keyfile_creds - The credentials from your service account JSON keyfile, accessible for download from the GCP console.","title":"Examples"},{"location":"getting-started/database_connectors/#test-your-connection","text":"When setting your Connection secrets, setting the verify query parameter to true allows you to test the Connection by issuing a trivial request to the database. The test_status response property announces the test result as succeeded or failed . If the attempt has failed, the failure_reason property gives further details about the failure. To skip the connection test, set verify to false . You can verify that a Connection's secrets are valid at any time by calling the Test a Connection's Secrets endpoint: GET 1 /api/v1/connection/application-postgresql-db/test Test failures can be resolved by calling the Set a Connection's Secrets endpoint, and resetting the secret values. Success 1 2 3 4 5 { \"msg\" : \"Test completed for ConnectionConfig with key: app_postgres_db.\" , \"test_status\" : \"succeeded\" , \"failure_reason\" : null } Failure 1 2 3 4 5 { \"msg\" : \"Secrets updated for ConnectionConfig with key: app_mongo_db.\" , \"test_status\" : \"failed\" , \"failure_reason\" : \"Operation Failure connecting to MongoDB.\" }","title":"Test your connection"},{"location":"getting-started/database_connectors/#associate-a-dataset","text":"Once you have a working Connection, it must be associated to an existing dataset . This enables Fides to map and access the contents of your database. Call the /dataset endpoint with a JSON version of your dataset as the request body: PATCH /api/v1/connection/my_connection_key/dataset 1 2 3 4 5 6 [{ \"fides_key\" : \"example_test_dataset\" , \"name\" : \"Example Test Dataset\" , \"description\" : \"Example of a dataset containing a variety of related tables like customers, products, addresses, etc.\" , \"collections\" : [ ... ] }]","title":"Associate a Dataset"},{"location":"getting-started/database_connectors/#filtering-your-connections","text":"Fides can filter and return matching Connections based on the connection_type , the testing_status , the system_status , and whether the connection is disabled .","title":"Filtering your Connections"},{"location":"getting-started/database_connectors/#connection-type-filter","text":"Including multiple connection_type query parameters and values will result in a query that looks for any connections with that type: GET api/v1//connection/?connection_type=mariadb&connection_type=postgres 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 { \"items\" : [ { \"name\" : \"Application Maria DB\" , \"key\" : \"app_mariadb_db\" , \"description\" : null , \"connection_type\" : \"mariadb\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:21:02.353226+00:00\" , \"updated_at\" : \"2022-06-16T22:21:02.353226+00:00\" , \"disabled\" : false , \"last_test_timestamp\" : null , \"last_test_succeeded\" : null }, { \"name\" : \"Application PostgreSQL DB\" , \"key\" : \"app_postgres_db\" , \"description\" : \"postgres backup\" , \"connection_type\" : \"postgres\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:20:24.972539+00:00\" , \"updated_at\" : \"2022-06-16T22:20:24.972539+00:00\" , \"disabled\" : false , \"last_test_timestamp\" : null , \"last_test_succeeded\" : null } ], \"total\" : 2 , \"page\" : 1 , \"size\" : 50 }","title":"Connection type filter"},{"location":"getting-started/database_connectors/#disabled-filter","text":"The disabled filter will return datastores are skipped as part of privacy request execution: GET api/v1/connection/?disabled=true 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"items\" : [ { \"name\" : \"My Mongo DB\" , \"key\" : \"app_mongo_db\" , \"description\" : \"Primary Mongo DB\" , \"connection_type\" : \"mongodb\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"updated_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"disabled\" : true , \"last_test_timestamp\" : null , \"last_test_succeeded\" : null } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"Disabled filter"},{"location":"getting-started/database_connectors/#test_status-filter","text":"The test_status filter queries on the status of the last successful test: GET api/v1/connection/?test_status=false 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"items\" : [ { \"name\" : \"My Mongo DB\" , \"key\" : \"app_mongo_db\" , \"description\" : \"Primary Mongo DB\" , \"connection_type\" : \"mongodb\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"updated_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"disabled\" : true , \"last_test_timestamp\" : 2022-06-16 T 22 : 20 : 34.122212+00 : 00 , \"last_test_succeeded\" : false } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"Test_Status filter"},{"location":"getting-started/database_connectors/#system_status-filter","text":"The system_status filter surfaces either database or saas -type connectors: GET api/v1/connection/?system_type=database 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"items\" : [ { \"name\" : \"My Mongo DB\" , \"key\" : \"app_mongo_db\" , \"description\" : \"Primary Mongo DB\" , \"connection_type\" : \"mongodb\" , \"access\" : \"write\" , \"created_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"updated_at\" : \"2022-06-16T22:20:34.122212+00:00\" , \"disabled\" : true , \"last_test_timestamp\" : 2022-06-16 T 22 : 20 : 34.122212+00 : 00 , \"last_test_succeeded\" : false } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"System_Status filter"},{"location":"getting-started/database_connectors/#search-your-connections","text":"You can search the name , key , and description fields of your Connections with the search query parameter. GET /api/v1/connection/?search=application mysql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"items\" : [ { \"name\" : \"Application MySQL DB\" , \"key\" : \"app_mysql_db\" , \"description\" : \"My Backup MySQL DB\" , \"connection_type\" : \"mysql\" , \"access\" : \"read\" , \"created_at\" : \"2022-06-13T18:03:28.404091+00:00\" , \"updated_at\" : \"2022-06-13T18:03:28.404091+00:00\" , \"last_test_timestamp\" : null , \"last_test_succeeded\" : null } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"Search your Connections"},{"location":"getting-started/database_connectors/#view-available-connection-types","text":"To view a list of all available connection types, visit GET /api/v1/connection_type . This endpoint can be filtered with a search query parameter, and is subject to change. Both database options and third party API services are included. GET /api/v1/connection_type 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 { \"items\" : [ { \"identifier\" : \"bigquery\" , \"type\" : \"database\" }, { \"identifier\" : \"mariadb\" , \"type\" : \"database\" }, { \"identifier\" : \"mongodb\" , \"type\" : \"database\" }, { \"identifier\" : \"mssql\" , \"type\" : \"database\" }, { \"identifier\" : \"mysql\" , \"type\" : \"database\" }, { \"identifier\" : \"postgres\" , \"type\" : \"database\" }, { \"identifier\" : \"redshift\" , \"type\" : \"database\" }, { \"identifier\" : \"snowflake\" , \"type\" : \"database\" }, { \"identifier\" : \"adobe_campaign\" , \"type\" : \"saas\" }, { \"identifier\" : \"auth0\" , \"type\" : \"saas\" }, { \"identifier\" : \"datadog\" , \"type\" : \"saas\" }, { \"identifier\" : \"hubspot\" , \"type\" : \"saas\" }, { \"identifier\" : \"logi_id\" , \"type\" : \"saas\" }, { \"identifier\" : \"mailchimp\" , \"type\" : \"saas\" }, { \"identifier\" : \"outreach\" , \"type\" : \"saas\" }, { \"identifier\" : \"salesforce\" , \"type\" : \"saas\" }, { \"identifier\" : \"segment\" , \"type\" : \"saas\" }, { \"identifier\" : \"sendgrid\" , \"type\" : \"saas\" }, { \"identifier\" : \"sentry\" , \"type\" : \"saas\" }, { \"identifier\" : \"stripe\" , \"type\" : \"saas\" }, { \"identifier\" : \"zendesk\" , \"type\" : \"saas\" } ], \"total\" : 21 , \"page\" : 1 , \"size\" : 50 }","title":"View available connection types"},{"location":"getting-started/database_connectors/#view-required-connection-secrets","text":"To view the secrets needed to authenticate with a given connection, visit GET /api/v1/connection_type/<connection_type>/secret . GET /api/v1/connection_type/sentry/secret 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"title\" : \"sentry_schema\" , \"description\" : \"Sentry secrets schema\" , \"type\" : \"object\" , \"properties\" : { \"access_token\" : { \"title\" : \"Access Token\" , \"type\" : \"string\" }, \"domain\" : { \"title\" : \"Domain\" , \"default\" : \"sentry.io\" , \"type\" : \"string\" } }, \"required\" : [ \"access_token\" ], \"additionalProperties\" : false }","title":"View required connection secrets"},{"location":"getting-started/datasets/","text":"Create Datasets What is a Dataset? A Dataset is the configuration you provide for a database or other queryable datastore. Fides Datasets are applicable to a wide variety of datastores beyond traditional databases. Within Datasets, the term collection is used to describe an SQL table, mongo database collection, or any other single coherent set values. Configure a Dataset Fides uses a YAML manifest file to represent your datastores, and requires information beyond table names and fields to fully configure a Dataset. Datastores connected in this way will be automatically traversed when Fides executes a privacy request, and will either return or update the requested data according to the associated execution policy . Ensure you have created a Connection for the datastore you would like to map. The Dataset defined by the following process should be associated to the Connection . Describe a datastore The following is a sample database of customers and addresses. It includes a customer table that has a foreign key of address_id to an address table: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE CUSTOMER ( id INT PRIMARY KEY , name VARCHAR , email VARCHAR , address_id int REFERENCES ADDRESS ( id ) ); CREATE TABLE ADDRESS ( id INT PRIMARY KEY , street VARCHAR , city VARCHAR , state VARCHAR , zip VARCHAR ); A Fides Dataset contains a map of the database's fields, and metadata describing how those fields are related. Fides uses this relationship information to navigate between different collections and fulfill privacy requests. The Dataset declaration for the above schema looks like: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : address fields : - name : id data_categories : [ system.operations ] fidesops_meta : primary_key : True - name : street data_categories : [ user.contact.address.street ] fidesops_meta : data_type : string - name : city data_categories : [ user.contact.address.city ] fidesops_meta : data_type : string - name : state data_categories : [ user.contact.address.state ] fidesops_meta : data_type : string - name : zip data_categories : [ user.contact.address.postal_code ] fidesops_meta : data_type : string - name : customer after : mydatabase.address fields : - name : address_id data_categories : [ system.operations ] fidesops_meta : references : - dataset : mydatabase field : address.id direction : to - name : created data_categories : [ system.operations ] - name : email data_categories : [ user.contact.email ] fidesops_meta : identity : email data_type : string - name : id data_categories : [ user.unique_id ] fidesops_meta : primary_key : True - name : name data_categories : [ user.name ] fidesops_meta : data_type : string Dataset members Name Description fides_key A unique identifier name for the Dataset. collections A list of addressable collections. after An optional list of Datasets that must be fully traversed before this Dataset is queried. Collection members Name Description name This collection name must correspond to the name used for it in your datastore. It will be used to dynamically generate query and update statements. fields A list of addressable fields in the collection. Specifying the fields in the collection tells Fides what data to address in the collection. after Optional. A list of collections (in the form [dataset name].[collection name] ) that must be fully traversed before this collection is queried. Field members Name Description name The name of the field will be used to generate query and update statements. Fides does not do automated schema discovery, and is only aware of the fields you declare. data_categories Annotating data_categories connects fields to execution policy rules, and determines which actions apply to each field. For more information see execution policies . fidesops_meta The fidesops_meta section specifies additional fields that control how Fides manages your data. references A declaration of relationships between collections. Where the customer configuration declares a reference to mydatabase:address:id , Fides will use the values from mydatabase.address.id to search for related values in customer . References require both the Dataset and collection name to allow for multiple Dataset-collection configurations. references.field The linked field, using the syntax [dataset name].[collection name ].[field name] . references.identity Signifies that this field is an identity value that can be used as the root for a traversal. For more information, see graph traversals . references.direction Optional. Accepted values are from or to . This determines how fidesops uses the relationships to discover data. If the direction is to , fidesops will only use data in the source collection to discover data in the referenced collection. If the direction is from , fidesops will only use data in the referenced collection to discover data in the source collection. If the direction is omitted, fidesops will traverse the relation in whatever direction works to discover all related data. references.primary_key Optional. A boolean value. Fides will treat this field as a unique row identifier for generating update statements. If no primary key is specified for any field on a collection, no updates will be generated against that collection. If multiple fields are marked as primary keys, the combination of their values will be treated as a combined key. references.data_type Optional. An indication of the type of data held by this field. Data types are used to convert values to the appropriate type when those values are used in queries. This is especially necessary when using data of one type to help locate data of another type. Data types are also used to generate the appropriate masked value when running erasures, since fidesops needs to know the type of data expected by the field in order to generate an appropriate masked value. Available data types are string , integer , float , boolean , and object_id . object types are also supported for MongoDB. references.length Optional. An indicator of field length. references.return_all_elements Optional. For array entrypoint fields, specify whether the query should return/mask all fields, or just matching fields. By default, we just return/mask matching fields. Setting return_all_elements=true will return/mask the entire array. Generate a Dataset The Fides CLI allows you to both connect to and generate a blank Dataset for your datastores. This blank Dataset does not include any annotations (e.g., Fides data descriptions) or fidesops_meta information, but can be used to initially map your databases. For more information, see generating resources . Configure a manual Dataset Not all data can be automatically retrieved. When services have no external API, or when user data is held in a physical location, you can define a Dataset to describe the types of manual fields you plan to upload, as well as any dependencies between these manual collections and other collections. When a manual Dataset is defined, an in-progress access request will pause until the data is added manually, and then resume execution. For more information, see resuming a paused request . Describe a manual datastore In the following example, the manual Dataset is a physical location, which contains one storage_unit collection. email is defined as the unit's identity , which will then be used to retrieve the box_id in the storage unit. To add a Manual Dataset, first create a Manual Connection . The following Manual Dataset can then be added to the new ConnectionConfig: PATCH {{host}}/connection/ /dataset 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 dataset : - fides_key : manual_input name : Manual Dataset description : Example of a Dataset whose data must be manually retrieved collections : - name : storage_unit fields : - name : box_id data_categories : [ user ] fidesops_meta : primary_key : true - name : email data_categories : [ user.contact.email ] fidesops_meta : identity : email data_type : string Resume a paused access privacy request A privacy request will pause execution when it reaches a manual collection in an access request. An administrator should manually retrieve the data and send it in a POST request. The fields should match the fields on the paused collection. Erasure requests with manual collections will also need data manually added as well. POST {{host}}/privacy-request/{{privacy_request_id}}/manual_input 1 2 3 4 [{ \"box_id\" : 5 , \"email\" : \"customer-1@example.com\" }] If no manual data can be found, pass in an empty list to resume the privacy request: 1 [] Resume a paused erasure privacy request A privacy request will pause execution when it reaches a manual collection in an erasure request. An administrator should manually mask the records in question, and send confirmation of the rows affected in a POST request. POST {{host}}/privacy-request/{{privacy_request_id}}/erasure_confirm 1 { \"row_count\" : 2 } If no manual data was destroyed, pass in a count of 0 to resume the privacy request: 1 { \"row_count\" : 0 }","title":"Create Datasets"},{"location":"getting-started/datasets/#create-datasets","text":"","title":"Create Datasets"},{"location":"getting-started/datasets/#what-is-a-dataset","text":"A Dataset is the configuration you provide for a database or other queryable datastore. Fides Datasets are applicable to a wide variety of datastores beyond traditional databases. Within Datasets, the term collection is used to describe an SQL table, mongo database collection, or any other single coherent set values.","title":"What is a Dataset?"},{"location":"getting-started/datasets/#configure-a-dataset","text":"Fides uses a YAML manifest file to represent your datastores, and requires information beyond table names and fields to fully configure a Dataset. Datastores connected in this way will be automatically traversed when Fides executes a privacy request, and will either return or update the requested data according to the associated execution policy . Ensure you have created a Connection for the datastore you would like to map. The Dataset defined by the following process should be associated to the Connection .","title":"Configure a Dataset"},{"location":"getting-started/datasets/#describe-a-datastore","text":"The following is a sample database of customers and addresses. It includes a customer table that has a foreign key of address_id to an address table: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE CUSTOMER ( id INT PRIMARY KEY , name VARCHAR , email VARCHAR , address_id int REFERENCES ADDRESS ( id ) ); CREATE TABLE ADDRESS ( id INT PRIMARY KEY , street VARCHAR , city VARCHAR , state VARCHAR , zip VARCHAR ); A Fides Dataset contains a map of the database's fields, and metadata describing how those fields are related. Fides uses this relationship information to navigate between different collections and fulfill privacy requests. The Dataset declaration for the above schema looks like: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : address fields : - name : id data_categories : [ system.operations ] fidesops_meta : primary_key : True - name : street data_categories : [ user.contact.address.street ] fidesops_meta : data_type : string - name : city data_categories : [ user.contact.address.city ] fidesops_meta : data_type : string - name : state data_categories : [ user.contact.address.state ] fidesops_meta : data_type : string - name : zip data_categories : [ user.contact.address.postal_code ] fidesops_meta : data_type : string - name : customer after : mydatabase.address fields : - name : address_id data_categories : [ system.operations ] fidesops_meta : references : - dataset : mydatabase field : address.id direction : to - name : created data_categories : [ system.operations ] - name : email data_categories : [ user.contact.email ] fidesops_meta : identity : email data_type : string - name : id data_categories : [ user.unique_id ] fidesops_meta : primary_key : True - name : name data_categories : [ user.name ] fidesops_meta : data_type : string","title":"Describe a datastore"},{"location":"getting-started/datasets/#dataset-members","text":"Name Description fides_key A unique identifier name for the Dataset. collections A list of addressable collections. after An optional list of Datasets that must be fully traversed before this Dataset is queried.","title":"Dataset members"},{"location":"getting-started/datasets/#collection-members","text":"Name Description name This collection name must correspond to the name used for it in your datastore. It will be used to dynamically generate query and update statements. fields A list of addressable fields in the collection. Specifying the fields in the collection tells Fides what data to address in the collection. after Optional. A list of collections (in the form [dataset name].[collection name] ) that must be fully traversed before this collection is queried.","title":"Collection members"},{"location":"getting-started/datasets/#field-members","text":"Name Description name The name of the field will be used to generate query and update statements. Fides does not do automated schema discovery, and is only aware of the fields you declare. data_categories Annotating data_categories connects fields to execution policy rules, and determines which actions apply to each field. For more information see execution policies . fidesops_meta The fidesops_meta section specifies additional fields that control how Fides manages your data. references A declaration of relationships between collections. Where the customer configuration declares a reference to mydatabase:address:id , Fides will use the values from mydatabase.address.id to search for related values in customer . References require both the Dataset and collection name to allow for multiple Dataset-collection configurations. references.field The linked field, using the syntax [dataset name].[collection name ].[field name] . references.identity Signifies that this field is an identity value that can be used as the root for a traversal. For more information, see graph traversals . references.direction Optional. Accepted values are from or to . This determines how fidesops uses the relationships to discover data. If the direction is to , fidesops will only use data in the source collection to discover data in the referenced collection. If the direction is from , fidesops will only use data in the referenced collection to discover data in the source collection. If the direction is omitted, fidesops will traverse the relation in whatever direction works to discover all related data. references.primary_key Optional. A boolean value. Fides will treat this field as a unique row identifier for generating update statements. If no primary key is specified for any field on a collection, no updates will be generated against that collection. If multiple fields are marked as primary keys, the combination of their values will be treated as a combined key. references.data_type Optional. An indication of the type of data held by this field. Data types are used to convert values to the appropriate type when those values are used in queries. This is especially necessary when using data of one type to help locate data of another type. Data types are also used to generate the appropriate masked value when running erasures, since fidesops needs to know the type of data expected by the field in order to generate an appropriate masked value. Available data types are string , integer , float , boolean , and object_id . object types are also supported for MongoDB. references.length Optional. An indicator of field length. references.return_all_elements Optional. For array entrypoint fields, specify whether the query should return/mask all fields, or just matching fields. By default, we just return/mask matching fields. Setting return_all_elements=true will return/mask the entire array.","title":"Field members"},{"location":"getting-started/datasets/#generate-a-dataset","text":"The Fides CLI allows you to both connect to and generate a blank Dataset for your datastores. This blank Dataset does not include any annotations (e.g., Fides data descriptions) or fidesops_meta information, but can be used to initially map your databases. For more information, see generating resources .","title":"Generate a Dataset"},{"location":"getting-started/datasets/#configure-a-manual-dataset","text":"Not all data can be automatically retrieved. When services have no external API, or when user data is held in a physical location, you can define a Dataset to describe the types of manual fields you plan to upload, as well as any dependencies between these manual collections and other collections. When a manual Dataset is defined, an in-progress access request will pause until the data is added manually, and then resume execution. For more information, see resuming a paused request .","title":"Configure a manual Dataset"},{"location":"getting-started/datasets/#describe-a-manual-datastore","text":"In the following example, the manual Dataset is a physical location, which contains one storage_unit collection. email is defined as the unit's identity , which will then be used to retrieve the box_id in the storage unit. To add a Manual Dataset, first create a Manual Connection . The following Manual Dataset can then be added to the new ConnectionConfig: PATCH {{host}}/connection/ /dataset 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 dataset : - fides_key : manual_input name : Manual Dataset description : Example of a Dataset whose data must be manually retrieved collections : - name : storage_unit fields : - name : box_id data_categories : [ user ] fidesops_meta : primary_key : true - name : email data_categories : [ user.contact.email ] fidesops_meta : identity : email data_type : string","title":"Describe a manual datastore"},{"location":"getting-started/datasets/#resume-a-paused-access-privacy-request","text":"A privacy request will pause execution when it reaches a manual collection in an access request. An administrator should manually retrieve the data and send it in a POST request. The fields should match the fields on the paused collection. Erasure requests with manual collections will also need data manually added as well. POST {{host}}/privacy-request/{{privacy_request_id}}/manual_input 1 2 3 4 [{ \"box_id\" : 5 , \"email\" : \"customer-1@example.com\" }] If no manual data can be found, pass in an empty list to resume the privacy request: 1 []","title":"Resume a paused access privacy request"},{"location":"getting-started/datasets/#resume-a-paused-erasure-privacy-request","text":"A privacy request will pause execution when it reaches a manual collection in an erasure request. An administrator should manually mask the records in question, and send confirmation of the rows affected in a POST request. POST {{host}}/privacy-request/{{privacy_request_id}}/erasure_confirm 1 { \"row_count\" : 2 } If no manual data was destroyed, pass in a count of 0 to resume the privacy request: 1 { \"row_count\" : 0 }","title":"Resume a paused erasure privacy request"},{"location":"getting-started/execution_policies/","text":"Configure Policies What is an execution policy? An execution policy (separate from a Policy , used to enforce compliance) is a set of instructions, or Rules, that are executed when a user submits a request to retrieve or delete their data. It describes how to access, mask, or erase data that matches specific data categories in submitted privacy requests. Each endpoint takes an array of objects to create multiple policies, rules, or targets at one time. Regarding PATCH endpoints PATCH requests perform the equivalent of a create_or_update operation. This means that any existing objects sent to this endpoint will: be updated, any non-existing objects will be created, AND any objects existing that are not specified in the request will not be deleted. Create a Policy To create a new execution policy, it must first be defined: PATCH /api/v1/policy 1 2 3 4 5 6 7 [ { \"name\" : \"User Email Address\" , \"key\" : \"user_email_address_policy\" , \"drp_action\" : \"access\" // optional } ] Policy attributes Attribute Description name User-friendly name for your Policy. key Unique key by which to reference the Policy. drp_action Optional. A Data Rights Protocol action to associate to this policy. Accepted values are access (must be used with an access Rule ) or deletion (must be used with an erasure Rule ). Add a Rule The policy creation operation returns an execution policy key. This key can be used to add a Rule to the execution policy. Rules represent a series of information and actions to take when a privacy request of the corresponding action_type is submitted. The following is an example of an access Rule: PATCH /api/v1/policy/{policy_key}/rule 1 2 3 4 5 6 7 8 [ { \"name\" : \"Access User Email Address\" , \"key\" : \"access_user_email_address_rule\" , \"action_type\" : \"access\" , \"storage_destination_key\" : \"storage_key\" } ] Rule attributes Attribute Description name A user-friendly name for the rule. action_type Which action is this Rule handling? action_type.access A data subject access request. Matching data will be returned. action_type.erasure A data subject erasure request (or Right to be Forgotten). Matching data will be erased or masked . storage_destination Where Fides will upload the returned data for an access action. See storage . masking_strategy How to erase data that applies to this Rule . See Configuring Masking Strategies The storage_key must identify an existing Storage object. Add a Rule Target A Rule also specifies one or more Data Categories , or \"Targets\", to which the rule applies. Creating a Rule will return a key, which can be used to assign it one or more targets: PATCH /api/v1/policy/{policy_key}/rule/{rule_key}/target 1 2 3 4 5 6 7 [ { \"name\" : \"Access User Email Address Target\" , \"key\" : \"access_user_email_address_target\" , \"data_category\" : \"user.contact.email\" , } ] Attribute Description name A user-friendly name for the target. key A unique key to identify the target. data_category The data categories to which the associated rule applies. For example, email addresses under user.contact.email . Add an erasure Rule Access rules will always run before erasure rules. The access execution policy created above will pull all data of category user.contact.email . In the event of an erasure request, we might also want to mask this information. A new erasure rule can be added to the same execution policy: PATCH /api/v1/policy/{policy_key}/rule 1 2 3 4 5 6 7 8 9 10 11 12 13 [ { \"name\" : \"Mask Provided Emails\" , \"key\" : \"mask_provided_emails\" , \"action_type\" : \"erasure\" , \"masking_strategy\" : { \"strategy\" : \"hash\" , \"configuration\" : { \"algorithm\" : \"SHA-512\" }, }, }, ] This will create a Rule to hash an unspecified value with a SHA-512 hash. To add a value to hash, create a new Target for this Rule: PATCH api/v1/policy/{policy_key}/rule/{rule_key} 1 2 3 4 5 [ { \"data_category\" : \"user.contact.email\" , }, ] This execution policy, user_email_address_policy , will now do the following: - Return all data with a data category that matches (or is nested under) user.contact . - Mask all data with data category that matches user.contact.email with a the SHA-512 hashing function. Erasing data When an execution policy Rule erases data, it erases the entire branch given by the Target. For example, a user.contact Rule, will erase all of the information within the contact node, including user.contact.email . It's illegal to erase the same data twice within an execution policy. For example, erasing user.contact and user.contact.email is not allowed. Default execution policies These auto-generated execution policies are intended for use in a test environment. In production deployments, configure separate execution policies and storage destinations that target and process the appropriate fields. Fides ships with two default execution policies: download (for access requests) and delete (for erasure requests). The download execution policy is configured to retrieve user data and upload to a local storage location. The delete execution policy is set up to mask user data with the string \" MASKED \".","title":"Create Execution Policies"},{"location":"getting-started/execution_policies/#configure-policies","text":"","title":"Configure Policies"},{"location":"getting-started/execution_policies/#what-is-an-execution-policy","text":"An execution policy (separate from a Policy , used to enforce compliance) is a set of instructions, or Rules, that are executed when a user submits a request to retrieve or delete their data. It describes how to access, mask, or erase data that matches specific data categories in submitted privacy requests. Each endpoint takes an array of objects to create multiple policies, rules, or targets at one time. Regarding PATCH endpoints PATCH requests perform the equivalent of a create_or_update operation. This means that any existing objects sent to this endpoint will: be updated, any non-existing objects will be created, AND any objects existing that are not specified in the request will not be deleted.","title":"What is an execution policy?"},{"location":"getting-started/execution_policies/#create-a-policy","text":"To create a new execution policy, it must first be defined: PATCH /api/v1/policy 1 2 3 4 5 6 7 [ { \"name\" : \"User Email Address\" , \"key\" : \"user_email_address_policy\" , \"drp_action\" : \"access\" // optional } ]","title":"Create a Policy"},{"location":"getting-started/execution_policies/#policy-attributes","text":"Attribute Description name User-friendly name for your Policy. key Unique key by which to reference the Policy. drp_action Optional. A Data Rights Protocol action to associate to this policy. Accepted values are access (must be used with an access Rule ) or deletion (must be used with an erasure Rule ).","title":"Policy attributes"},{"location":"getting-started/execution_policies/#add-a-rule","text":"The policy creation operation returns an execution policy key. This key can be used to add a Rule to the execution policy. Rules represent a series of information and actions to take when a privacy request of the corresponding action_type is submitted. The following is an example of an access Rule: PATCH /api/v1/policy/{policy_key}/rule 1 2 3 4 5 6 7 8 [ { \"name\" : \"Access User Email Address\" , \"key\" : \"access_user_email_address_rule\" , \"action_type\" : \"access\" , \"storage_destination_key\" : \"storage_key\" } ]","title":"Add a Rule"},{"location":"getting-started/execution_policies/#rule-attributes","text":"Attribute Description name A user-friendly name for the rule. action_type Which action is this Rule handling? action_type.access A data subject access request. Matching data will be returned. action_type.erasure A data subject erasure request (or Right to be Forgotten). Matching data will be erased or masked . storage_destination Where Fides will upload the returned data for an access action. See storage . masking_strategy How to erase data that applies to this Rule . See Configuring Masking Strategies The storage_key must identify an existing Storage object.","title":"Rule attributes"},{"location":"getting-started/execution_policies/#add-a-rule-target","text":"A Rule also specifies one or more Data Categories , or \"Targets\", to which the rule applies. Creating a Rule will return a key, which can be used to assign it one or more targets: PATCH /api/v1/policy/{policy_key}/rule/{rule_key}/target 1 2 3 4 5 6 7 [ { \"name\" : \"Access User Email Address Target\" , \"key\" : \"access_user_email_address_target\" , \"data_category\" : \"user.contact.email\" , } ] Attribute Description name A user-friendly name for the target. key A unique key to identify the target. data_category The data categories to which the associated rule applies. For example, email addresses under user.contact.email .","title":"Add a Rule Target"},{"location":"getting-started/execution_policies/#add-an-erasure-rule","text":"Access rules will always run before erasure rules. The access execution policy created above will pull all data of category user.contact.email . In the event of an erasure request, we might also want to mask this information. A new erasure rule can be added to the same execution policy: PATCH /api/v1/policy/{policy_key}/rule 1 2 3 4 5 6 7 8 9 10 11 12 13 [ { \"name\" : \"Mask Provided Emails\" , \"key\" : \"mask_provided_emails\" , \"action_type\" : \"erasure\" , \"masking_strategy\" : { \"strategy\" : \"hash\" , \"configuration\" : { \"algorithm\" : \"SHA-512\" }, }, }, ] This will create a Rule to hash an unspecified value with a SHA-512 hash. To add a value to hash, create a new Target for this Rule: PATCH api/v1/policy/{policy_key}/rule/{rule_key} 1 2 3 4 5 [ { \"data_category\" : \"user.contact.email\" , }, ] This execution policy, user_email_address_policy , will now do the following: - Return all data with a data category that matches (or is nested under) user.contact . - Mask all data with data category that matches user.contact.email with a the SHA-512 hashing function.","title":"Add an erasure Rule"},{"location":"getting-started/execution_policies/#erasing-data","text":"When an execution policy Rule erases data, it erases the entire branch given by the Target. For example, a user.contact Rule, will erase all of the information within the contact node, including user.contact.email . It's illegal to erase the same data twice within an execution policy. For example, erasing user.contact and user.contact.email is not allowed.","title":"Erasing data"},{"location":"getting-started/execution_policies/#default-execution-policies","text":"These auto-generated execution policies are intended for use in a test environment. In production deployments, configure separate execution policies and storage destinations that target and process the appropriate fields. Fides ships with two default execution policies: download (for access requests) and delete (for erasure requests). The download execution policy is configured to retrieve user data and upload to a local storage location. The delete execution policy is set up to mask user data with the string \" MASKED \".","title":"Default execution policies"},{"location":"getting-started/generate_resources/","text":"Generate and Maintain Resources What is a resource? A resource is a Fides representation of a system, database, policy, or organization. Resources are maintained in YAML manifest files written in fideslang . Generating resources creates a template of your databases, services, or applications for further annotation and use in privacy requests or data maps . The Fides CLI provides a generate command to connect to a database, and automatically generate a resource YAML file based on the database schema. The scan command is available to compare your existing resources against what is defined in your Fides server, or against your resource manifest files. The scan and generate commands work best when used in tandem, as they follow an expected resource format. The Fides format must be followed in order to be able to track coverage. Providing Credentials Database credentials are provided as part of the connection string supplied. The connection string can be supplied as a command option or the fides config. Command Options A connection string can be supplied using the connection-string option: 1 2 3 ... --connection-string <my_connection_string> ... The appropriate connection-string format for your database connector can be found in the SQLAlchemy Documentation . Fides Config A connection string can also be defined within your Fides configuration under the credentials section. 1 2 [ credentials ] my_database_credentials = { connection_string = \"<my_connection_string>\" } Your command can then reference the key defined in your config: 1 2 3 ... --credentials-id \"my_database_credentials\" ... It is possible to use an environment variable to set credentials config values if persisting your connection string to a file is problematic. To set a connection string you can set the environment variable with a prefix of FIDES__CREDENTIALS__ and __ as the nested key delimiter: 1 export FIDES__CREDENTIALS__MY_DATABASE_CREDENTIALS__CONNECTION_STRING = \"<my_database_credentials>\" Generating a Dataset Given a database schema with a single users table as follows: 1 2 3 4 5 6 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) We can invoke the generate command by providing a connection url for this database: 1 2 3 ./venv/bin/fides generate dataset db \\ fides_resources/flaskr_postgres_dataset.yml \\ --connection-string postgresql://postgres:postgres@localhost:5432/flaskr The result is a resource file with a dataset with collections and fields to represent our schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 dataset : - fides_key : public organization_fides_key : default_organization name : public description : 'Fides Generated Description for Schema: public' meta : null data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified collections : - name : public.users description : 'Fides Generated Description for Table: public.users' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : created_at description : 'Fides Generated Description for Column: created_at' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : email description : 'Fides Generated Description for Column: email' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : first_name description : 'Fides Generated Description for Column: first_name' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : id description : 'Fides Generated Description for Column: id' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : last_name description : 'Fides Generated Description for Column: last_name' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : password description : 'Fides Generated Description for Column: password' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified The resulting file still requires annotating the dataset with data categories to represent what is stored. To use this Dataset in a Privacy Request, you must add required meta information . Scanning the Dataset The scan command can then connect to your database and compare its schema to your defined Datasets. 1 2 3 ./venv/bin/fides scan dataset db \\ fides_resources/flaskr_postgres_dataset.yml \\ --connection-string postgresql://postgres:postgres@localhost:5432/flaskr The command output confirms our database resource is covered fully: 1 2 3 4 5 6 Loading resource manifests from: dataset.yml Taxonomy successfully created. Successfully scanned the following datasets: public Annotation coverage: 100 % Working With an AWS Account The generate command can connect to an AWS account and automatically generate resource YAML file based on tracked resources. Generated resources can be used as System declarations for generating Data Maps . Providing Credentials AWS credentials can be provided through command options, environment variables or the fides config. Command Options Credentials can be directly supplied in your command using the access_key_id , secret_access_key , and region options. 1 2 3 4 5 ... --access_key_id \"<my_access_key_id>\" --secret_access_key \"<my_secret_access_key>\" --region \"us-east-1\" ... Environment Variables The simplest way to authenticate through environment variables is to set an SECRET_ACCESS_KEY and ACCESS_KEY_ID , as defined by boto3 : 1 2 3 export AWS_ACCESS_KEY_ID = \"<my_access_key_id>\" export AWS_SECRET_ACCESS_KEY = \"<my_access_key>\" export AWS_DEFAULT_REGION = \"us-east-1\" It is also possible to reference a profile: 1 2 export AWS_PROFILE = \"my_profile_1\" export AWS_DEFAULT_REGION = \"us-east-1\" Fides Config Credentials can be defined within your Fides config under the credentials section. 1 2 [ credentials ] my_aws_credentials = { aws_access_key_id = \"<my_aws_access_key_id>\" , aws_secret_access_key = \"<my_aws_secret_access_key>\" , region_name = \"us-east-1\" } Your command can then reference the key defined in your config. 1 2 3 ... --credentials-id \"my_aws_credentials\" ... It is possible to use an environment variable to set credentials config values if persisting your keys to a config file is problematic. To set a secret access key and id, you can set the environment variable with a prefix of FIDES__CREDENTIALS__ and __ as the nested key delimiter: 1 2 export FIDES__CREDENTIALS__MY_AWS_CREDENTIALS__AWS_ACCESS_KEY_ID = \"<my_aws_access_key_id>\" export FIDES__CREDENTIALS__MY_AWS_CREDENTIALS__AWS_SECRET_ACCESS_KEY = \"<my_aws_secret_access_key>\" Required Permissions The identity which is authenticated must be allowed to invoke the following actions: redshift:DescribeClusters rds:DescribeDBInstances rds:DescribeDBClusters Sample IAM Policy These permissions can be supplied in an IAM policy: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"redshift:DescribeClusters\" , \"rds:DescribeDBInstances\" , \"rds:DescribeDBClusters\" , \"tag:GetResources\" , ], \"Resource\" : \"*\" } ] } Filtering AWS Resources It is possible to filter resources at the organization level by adding a resource filter within fidesctl_meta . The ignore_resource_arn filter can exclude any resources with an exact matching Amazon Resource Name (ARN) and also supports wildcards in individual ARN fields. An empty ARN field in the filter pattern works as a wildcard. The filter can be added to the organization model within your manifest file: 1 2 3 4 5 6 7 organization : - fides_key : default_organization name : default_organization fidesctl_meta : resource_filters : - type : ignore_resource_arn value : 'arn:aws:rds:us-east-1:910934740016:db:database-2' In the above example we explicitly ignore a single rds database but if we wanted to ignore all rds databases we could remove the partition, account id, region and database name ARN fields: 1 2 3 resource_filters : - type : ignore_resource_arn value : 'arn::rds:::db:' Any ARN field can be wildcarded by leaving it empty. Generating Systems Once credentials have been configured we can invoke the generate system aws command: 1 2 ./venv/bin/fides generate system aws \\ fides_resources/aws_systems.yml The result is a resource file with a system that represents a redshift cluster defined in our account: 1 2 3 4 5 6 7 8 9 10 11 system : - fides_key : my_redshift_cluster organization_fides_key : default_organization name : my_redshift_cluster description : 'Fides Generated Description for Cluster: my_redshift_cluster' fidesctl_meta : endpoint_address : my_redshift_cluster.us-east-1.redshift.amazonaws.com endpoint_port : '5439' resource_id : arn:aws:redshift:us-east-1:910934740016:namespace:057d5b0e-7eaa-4012-909c-3957c7149176 system_type : redshift_cluster privacy_declarations : [] Scanning the Systems The scan command can then connect to your AWS account and compare its resources to your already defined systems: 1 2 ./venv/bin/fides scan system aws \\ fides_resources/aws_systems.yml The command output confirms our resources are covered fully: 1 2 3 4 Loading resource manifests from: manifest.yml Taxonomy successfully created. Scanned 1 resource and all were found in taxonomy. Resource coverage: 100 % Working With an Okta Account The generate command can connect to an Okta admin account and automatically generate resource YAML file based on applications your organization integrates with. Generated resources can be used as System declarations for generating Data Maps . Providing Credentials Okta credentials can be provided through command options, environment variables or the Fides config. Command Options Credentials can be directly supplied in your command using the org-url and token options. 1 2 3 4 ... --token \"<my_okta_client_token>\" --org-url \"<my_okta_org_url>\" ... Environment Variables The simplest way to authenticate is by using a client token, defined by the Okta Python SDK : 1 export OKTA_CLIENT_TOKEN = \"<my_okta_client_token>\" It is also possible to authenticate using OAuth 2.0: 1 2 3 4 export OKTA_CLIENT_AUTHORIZATIONMODE = \"PrivateKey\" export OKTA_CLIENT_CLIENTID = \"<my_client_id>\" export OKTA_CLIENT_SCOPES = \"<my_scope_1,my_scope_2>\" export OKTA_CLIENT_PRIVATEKEY = \"<my_private_jwk>\" Fides Configuration Credentials can be defined within your Fides config under the credentials section. 1 2 [ credentials ] my_okta_credentials = { orgUrl = \"<my_okta_org_url>\" token = \"<my_okta_client_token>\" } Your command can then reference the key defined in your config. 1 2 3 ... --credentials-id \"my_okta_credentials\" ... It is possible to use an environment variable to set credentials config values if persisting your token to a file is problematic. To set a token, you can set the environment variable with a prefix of FIDES__CREDENTIALS__ and __ as the nested key delimiter: 1 export FIDES__CREDENTIALS__MY_OKTA_CREDENTIALS__TOKEN = \"<my_okta_client_token>\" Generating Systems Once credentials have been configured we can invoke the generate system okta command: 1 2 ./venv/bin/fides generate system okta fides_resources/okta_systems.yml The result is a resource file with systems that represent our application integrations: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 system : - fides_key : 0oa4jejqcp74R9MpJ5d7 organization_fides_key : default_organization name : salesforce description : 'Fides Generated Description for Okta Application: Salesforce.com' fidesctl_meta : resource_id : 0oa4jejqcp74R9MpJ5d7 privacy_declarations : [] - fides_key : 0oa4jekd00tpvn5hN5d7 organization_fides_key : default_organization name : google description : 'Fides Generated Description for Okta Application: Google Workspace' fidesctl_meta : resource_id : 0oa4jekd00tpvn5hN5d7 privacy_declarations : [] Scanning the Systems The scan command can then connect to your Okta account and compare its applications to your already defined systems: 1 2 ./venv/bin/fides scan system okta \\ fides_resources/okta_systems.yml The command output confirms our resources are covered fully: 1 2 3 4 5 6 7 8 9 10 Loading resource manifests from: manifest.yml Taxonomy successfully created. Successfully scanned the following systems: saasure ( id = 0oa4h45lj1tcpqU6W5d7 ) okta_enduser ( id = 0oa4h45ln0xLKJnAw5d7 ) okta_browser_plugin ( id = 0oa4h45lnodX7MHJB5d7 ) salesforce ( id = 0oa4jejqcp74R9MpJ5d7 ) google ( id = 0oa4jekd00tpvn5hN5d7 ) Resource coverage: 100 % Working With a GCP Account The generate command can connect to a GCP account and automatically generate resource YAML files based on tracked resources. Currently, generating datasets from BigQuery is supported. Providing Credentials GCP credentials can be generated via a service account keyfile which can be passed as a command option or the fides config. You will need to set project specific credentials for access rights, but datasets can be passed explicitly at runtime. Command Options The path to the keyfile can be directly supplied in your command using the keyfile_path option. 1 2 3 ... --keyfile-path \"/path/to/keyfile.json\" ... Fides Config Credentials can be defined within your fides config under the credentials section. 1 2 3 4 5 6 7 8 9 10 11 [credentials.bigquery_1] type = \"service_account\" project_id = \"<my_project_id>\" private_key_id = \"<my_private_key_id>\" private_key = \"<my_private_key>\" client_email = \"<my_client_email>\" client_id = \"<my_client_id>\" auth_uri = \"https://accounts.google.com/o/oauth2/auth\" token_uri = \"https://oauth2.googleapis.com/token\" auth_provider_x509_cert_url = \"https://www.googleapis.com/oauth2/v1/certs\" client_x509_cert_url = \"<my_cert_url>\" Your command can then reference the key defined in your config. 1 2 3 ... --credentials-id \"my_gcp_credentials\" ... It is possible to use an environment variable to set credentials config values if persisting your keys to a config file is problematic. To set a secret access key and id, you can set the environment variable with a prefix of FIDES__CREDENTIALS__ and __ as the nested key delimiter: 1 2 export FIDES__CREDENTIALS__BIGQUERY_1__PRIVATE_KEY = \"<my_private_key>\" export FIDES__CREDENTIALS__BIGQUERY_1__CLIENT_ID = \"<my_client_id>\" Generating a Dataset Once credentials have been configured, the generate dataset gcp bigquery command can take both a configuration option and a dataset name to create the resource file. 1 2 3 ./venv/bin/fides generate dataset gcp bigquery \\ <dataset_name> --keyfile-path \".fides/creds/bigquery.json\" \\ <output_file_name> The result is a resource file with a dataset that represents the bigquery dataset defined in your account. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 dataset : - fides_key : my_bigquery_dataset organization_fides_key : default_organization name : bigquery dataset description : 'Fides Generated Description for Schema: BigQuery' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified retention : No retention or erasure policy collections : - name : table description : 'Fides Generated Description for Table: table' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : column description : 'Fides Generated Description for Column: column' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified ...","title":"Generate Resources"},{"location":"getting-started/generate_resources/#generate-and-maintain-resources","text":"","title":"Generate and Maintain Resources"},{"location":"getting-started/generate_resources/#what-is-a-resource","text":"A resource is a Fides representation of a system, database, policy, or organization. Resources are maintained in YAML manifest files written in fideslang . Generating resources creates a template of your databases, services, or applications for further annotation and use in privacy requests or data maps . The Fides CLI provides a generate command to connect to a database, and automatically generate a resource YAML file based on the database schema. The scan command is available to compare your existing resources against what is defined in your Fides server, or against your resource manifest files. The scan and generate commands work best when used in tandem, as they follow an expected resource format. The Fides format must be followed in order to be able to track coverage.","title":"What is a resource?"},{"location":"getting-started/generate_resources/#providing-credentials","text":"Database credentials are provided as part of the connection string supplied. The connection string can be supplied as a command option or the fides config.","title":"Providing Credentials"},{"location":"getting-started/generate_resources/#command-options","text":"A connection string can be supplied using the connection-string option: 1 2 3 ... --connection-string <my_connection_string> ... The appropriate connection-string format for your database connector can be found in the SQLAlchemy Documentation .","title":"Command Options"},{"location":"getting-started/generate_resources/#fides-config","text":"A connection string can also be defined within your Fides configuration under the credentials section. 1 2 [ credentials ] my_database_credentials = { connection_string = \"<my_connection_string>\" } Your command can then reference the key defined in your config: 1 2 3 ... --credentials-id \"my_database_credentials\" ... It is possible to use an environment variable to set credentials config values if persisting your connection string to a file is problematic. To set a connection string you can set the environment variable with a prefix of FIDES__CREDENTIALS__ and __ as the nested key delimiter: 1 export FIDES__CREDENTIALS__MY_DATABASE_CREDENTIALS__CONNECTION_STRING = \"<my_database_credentials>\"","title":"Fides Config"},{"location":"getting-started/generate_resources/#generating-a-dataset","text":"Given a database schema with a single users table as follows: 1 2 3 4 5 6 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) We can invoke the generate command by providing a connection url for this database: 1 2 3 ./venv/bin/fides generate dataset db \\ fides_resources/flaskr_postgres_dataset.yml \\ --connection-string postgresql://postgres:postgres@localhost:5432/flaskr The result is a resource file with a dataset with collections and fields to represent our schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 dataset : - fides_key : public organization_fides_key : default_organization name : public description : 'Fides Generated Description for Schema: public' meta : null data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified collections : - name : public.users description : 'Fides Generated Description for Table: public.users' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : created_at description : 'Fides Generated Description for Column: created_at' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : email description : 'Fides Generated Description for Column: email' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : first_name description : 'Fides Generated Description for Column: first_name' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : id description : 'Fides Generated Description for Column: id' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : last_name description : 'Fides Generated Description for Column: last_name' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : password description : 'Fides Generated Description for Column: password' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified The resulting file still requires annotating the dataset with data categories to represent what is stored. To use this Dataset in a Privacy Request, you must add required meta information .","title":"Generating a Dataset"},{"location":"getting-started/generate_resources/#scanning-the-dataset","text":"The scan command can then connect to your database and compare its schema to your defined Datasets. 1 2 3 ./venv/bin/fides scan dataset db \\ fides_resources/flaskr_postgres_dataset.yml \\ --connection-string postgresql://postgres:postgres@localhost:5432/flaskr The command output confirms our database resource is covered fully: 1 2 3 4 5 6 Loading resource manifests from: dataset.yml Taxonomy successfully created. Successfully scanned the following datasets: public Annotation coverage: 100 %","title":"Scanning the Dataset"},{"location":"getting-started/generate_resources/#working-with-an-aws-account","text":"The generate command can connect to an AWS account and automatically generate resource YAML file based on tracked resources. Generated resources can be used as System declarations for generating Data Maps .","title":"Working With an AWS Account"},{"location":"getting-started/generate_resources/#providing-credentials_1","text":"AWS credentials can be provided through command options, environment variables or the fides config.","title":"Providing Credentials"},{"location":"getting-started/generate_resources/#command-options_1","text":"Credentials can be directly supplied in your command using the access_key_id , secret_access_key , and region options. 1 2 3 4 5 ... --access_key_id \"<my_access_key_id>\" --secret_access_key \"<my_secret_access_key>\" --region \"us-east-1\" ...","title":"Command Options"},{"location":"getting-started/generate_resources/#environment-variables","text":"The simplest way to authenticate through environment variables is to set an SECRET_ACCESS_KEY and ACCESS_KEY_ID , as defined by boto3 : 1 2 3 export AWS_ACCESS_KEY_ID = \"<my_access_key_id>\" export AWS_SECRET_ACCESS_KEY = \"<my_access_key>\" export AWS_DEFAULT_REGION = \"us-east-1\" It is also possible to reference a profile: 1 2 export AWS_PROFILE = \"my_profile_1\" export AWS_DEFAULT_REGION = \"us-east-1\"","title":"Environment Variables"},{"location":"getting-started/generate_resources/#fides-config_1","text":"Credentials can be defined within your Fides config under the credentials section. 1 2 [ credentials ] my_aws_credentials = { aws_access_key_id = \"<my_aws_access_key_id>\" , aws_secret_access_key = \"<my_aws_secret_access_key>\" , region_name = \"us-east-1\" } Your command can then reference the key defined in your config. 1 2 3 ... --credentials-id \"my_aws_credentials\" ... It is possible to use an environment variable to set credentials config values if persisting your keys to a config file is problematic. To set a secret access key and id, you can set the environment variable with a prefix of FIDES__CREDENTIALS__ and __ as the nested key delimiter: 1 2 export FIDES__CREDENTIALS__MY_AWS_CREDENTIALS__AWS_ACCESS_KEY_ID = \"<my_aws_access_key_id>\" export FIDES__CREDENTIALS__MY_AWS_CREDENTIALS__AWS_SECRET_ACCESS_KEY = \"<my_aws_secret_access_key>\"","title":"Fides Config"},{"location":"getting-started/generate_resources/#required-permissions","text":"The identity which is authenticated must be allowed to invoke the following actions: redshift:DescribeClusters rds:DescribeDBInstances rds:DescribeDBClusters","title":"Required Permissions"},{"location":"getting-started/generate_resources/#sample-iam-policy","text":"These permissions can be supplied in an IAM policy: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"redshift:DescribeClusters\" , \"rds:DescribeDBInstances\" , \"rds:DescribeDBClusters\" , \"tag:GetResources\" , ], \"Resource\" : \"*\" } ] }","title":"Sample IAM Policy"},{"location":"getting-started/generate_resources/#filtering-aws-resources","text":"It is possible to filter resources at the organization level by adding a resource filter within fidesctl_meta . The ignore_resource_arn filter can exclude any resources with an exact matching Amazon Resource Name (ARN) and also supports wildcards in individual ARN fields. An empty ARN field in the filter pattern works as a wildcard. The filter can be added to the organization model within your manifest file: 1 2 3 4 5 6 7 organization : - fides_key : default_organization name : default_organization fidesctl_meta : resource_filters : - type : ignore_resource_arn value : 'arn:aws:rds:us-east-1:910934740016:db:database-2' In the above example we explicitly ignore a single rds database but if we wanted to ignore all rds databases we could remove the partition, account id, region and database name ARN fields: 1 2 3 resource_filters : - type : ignore_resource_arn value : 'arn::rds:::db:' Any ARN field can be wildcarded by leaving it empty.","title":"Filtering AWS Resources"},{"location":"getting-started/generate_resources/#generating-systems","text":"Once credentials have been configured we can invoke the generate system aws command: 1 2 ./venv/bin/fides generate system aws \\ fides_resources/aws_systems.yml The result is a resource file with a system that represents a redshift cluster defined in our account: 1 2 3 4 5 6 7 8 9 10 11 system : - fides_key : my_redshift_cluster organization_fides_key : default_organization name : my_redshift_cluster description : 'Fides Generated Description for Cluster: my_redshift_cluster' fidesctl_meta : endpoint_address : my_redshift_cluster.us-east-1.redshift.amazonaws.com endpoint_port : '5439' resource_id : arn:aws:redshift:us-east-1:910934740016:namespace:057d5b0e-7eaa-4012-909c-3957c7149176 system_type : redshift_cluster privacy_declarations : []","title":"Generating Systems"},{"location":"getting-started/generate_resources/#scanning-the-systems","text":"The scan command can then connect to your AWS account and compare its resources to your already defined systems: 1 2 ./venv/bin/fides scan system aws \\ fides_resources/aws_systems.yml The command output confirms our resources are covered fully: 1 2 3 4 Loading resource manifests from: manifest.yml Taxonomy successfully created. Scanned 1 resource and all were found in taxonomy. Resource coverage: 100 %","title":"Scanning the Systems"},{"location":"getting-started/generate_resources/#working-with-an-okta-account","text":"The generate command can connect to an Okta admin account and automatically generate resource YAML file based on applications your organization integrates with. Generated resources can be used as System declarations for generating Data Maps .","title":"Working With an Okta Account"},{"location":"getting-started/generate_resources/#providing-credentials_2","text":"Okta credentials can be provided through command options, environment variables or the Fides config.","title":"Providing Credentials"},{"location":"getting-started/generate_resources/#command-options_2","text":"Credentials can be directly supplied in your command using the org-url and token options. 1 2 3 4 ... --token \"<my_okta_client_token>\" --org-url \"<my_okta_org_url>\" ...","title":"Command Options"},{"location":"getting-started/generate_resources/#environment-variables_1","text":"The simplest way to authenticate is by using a client token, defined by the Okta Python SDK : 1 export OKTA_CLIENT_TOKEN = \"<my_okta_client_token>\" It is also possible to authenticate using OAuth 2.0: 1 2 3 4 export OKTA_CLIENT_AUTHORIZATIONMODE = \"PrivateKey\" export OKTA_CLIENT_CLIENTID = \"<my_client_id>\" export OKTA_CLIENT_SCOPES = \"<my_scope_1,my_scope_2>\" export OKTA_CLIENT_PRIVATEKEY = \"<my_private_jwk>\"","title":"Environment Variables"},{"location":"getting-started/generate_resources/#fides-configuration","text":"Credentials can be defined within your Fides config under the credentials section. 1 2 [ credentials ] my_okta_credentials = { orgUrl = \"<my_okta_org_url>\" token = \"<my_okta_client_token>\" } Your command can then reference the key defined in your config. 1 2 3 ... --credentials-id \"my_okta_credentials\" ... It is possible to use an environment variable to set credentials config values if persisting your token to a file is problematic. To set a token, you can set the environment variable with a prefix of FIDES__CREDENTIALS__ and __ as the nested key delimiter: 1 export FIDES__CREDENTIALS__MY_OKTA_CREDENTIALS__TOKEN = \"<my_okta_client_token>\"","title":"Fides Configuration"},{"location":"getting-started/generate_resources/#generating-systems_1","text":"Once credentials have been configured we can invoke the generate system okta command: 1 2 ./venv/bin/fides generate system okta fides_resources/okta_systems.yml The result is a resource file with systems that represent our application integrations: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 system : - fides_key : 0oa4jejqcp74R9MpJ5d7 organization_fides_key : default_organization name : salesforce description : 'Fides Generated Description for Okta Application: Salesforce.com' fidesctl_meta : resource_id : 0oa4jejqcp74R9MpJ5d7 privacy_declarations : [] - fides_key : 0oa4jekd00tpvn5hN5d7 organization_fides_key : default_organization name : google description : 'Fides Generated Description for Okta Application: Google Workspace' fidesctl_meta : resource_id : 0oa4jekd00tpvn5hN5d7 privacy_declarations : []","title":"Generating Systems"},{"location":"getting-started/generate_resources/#scanning-the-systems_1","text":"The scan command can then connect to your Okta account and compare its applications to your already defined systems: 1 2 ./venv/bin/fides scan system okta \\ fides_resources/okta_systems.yml The command output confirms our resources are covered fully: 1 2 3 4 5 6 7 8 9 10 Loading resource manifests from: manifest.yml Taxonomy successfully created. Successfully scanned the following systems: saasure ( id = 0oa4h45lj1tcpqU6W5d7 ) okta_enduser ( id = 0oa4h45ln0xLKJnAw5d7 ) okta_browser_plugin ( id = 0oa4h45lnodX7MHJB5d7 ) salesforce ( id = 0oa4jejqcp74R9MpJ5d7 ) google ( id = 0oa4jekd00tpvn5hN5d7 ) Resource coverage: 100 %","title":"Scanning the Systems"},{"location":"getting-started/generate_resources/#working-with-a-gcp-account","text":"The generate command can connect to a GCP account and automatically generate resource YAML files based on tracked resources. Currently, generating datasets from BigQuery is supported.","title":"Working With a GCP Account"},{"location":"getting-started/generate_resources/#providing-credentials_3","text":"GCP credentials can be generated via a service account keyfile which can be passed as a command option or the fides config. You will need to set project specific credentials for access rights, but datasets can be passed explicitly at runtime.","title":"Providing Credentials"},{"location":"getting-started/generate_resources/#command-options_3","text":"The path to the keyfile can be directly supplied in your command using the keyfile_path option. 1 2 3 ... --keyfile-path \"/path/to/keyfile.json\" ...","title":"Command Options"},{"location":"getting-started/generate_resources/#fides-config_2","text":"Credentials can be defined within your fides config under the credentials section. 1 2 3 4 5 6 7 8 9 10 11 [credentials.bigquery_1] type = \"service_account\" project_id = \"<my_project_id>\" private_key_id = \"<my_private_key_id>\" private_key = \"<my_private_key>\" client_email = \"<my_client_email>\" client_id = \"<my_client_id>\" auth_uri = \"https://accounts.google.com/o/oauth2/auth\" token_uri = \"https://oauth2.googleapis.com/token\" auth_provider_x509_cert_url = \"https://www.googleapis.com/oauth2/v1/certs\" client_x509_cert_url = \"<my_cert_url>\" Your command can then reference the key defined in your config. 1 2 3 ... --credentials-id \"my_gcp_credentials\" ... It is possible to use an environment variable to set credentials config values if persisting your keys to a config file is problematic. To set a secret access key and id, you can set the environment variable with a prefix of FIDES__CREDENTIALS__ and __ as the nested key delimiter: 1 2 export FIDES__CREDENTIALS__BIGQUERY_1__PRIVATE_KEY = \"<my_private_key>\" export FIDES__CREDENTIALS__BIGQUERY_1__CLIENT_ID = \"<my_client_id>\"","title":"Fides Config"},{"location":"getting-started/generate_resources/#generating-a-dataset_1","text":"Once credentials have been configured, the generate dataset gcp bigquery command can take both a configuration option and a dataset name to create the resource file. 1 2 3 ./venv/bin/fides generate dataset gcp bigquery \\ <dataset_name> --keyfile-path \".fides/creds/bigquery.json\" \\ <output_file_name> The result is a resource file with a dataset that represents the bigquery dataset defined in your account. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 dataset : - fides_key : my_bigquery_dataset organization_fides_key : default_organization name : bigquery dataset description : 'Fides Generated Description for Schema: BigQuery' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified retention : No retention or erasure policy collections : - name : table description : 'Fides Generated Description for Table: table' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : column description : 'Fides Generated Description for Column: column' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified ...","title":"Generating a Dataset"},{"location":"getting-started/privacy_requests/","text":"Execute Privacy Requests What is a Privacy Request? A privacy request represents an ask from a user to perform an action on their identity data. The request itself identifies the user by email address, phone number, social security number, or other identifiable information. The data that will be affected, and how it's affected, is described in an execution policy associated with the request. For more information on policies, see the execution policies guide. Submit a privacy request Privacy Requests are executed immediately by default. This setting may be changed in your fides.toml configuration file. Privacy requests are submitted by calling the Privacy Request endpoint: POST /api/v1/privacy-request 1 2 3 4 5 6 7 8 9 10 11 [ { \"external_id\" : \"a-user-defined-id\" , \"requested_at\" : \"2021-10-31T16:00:00.000Z\" , \"policy_key\" : \"a-demo-policy\" , \"identity\" : { \"email\" : \"identity@example.com\" , \"phone_number\" : \"+1 (123) 456 7891\" } } ] The above request will apply the a-demo-policy execution policy to all target data that can be generated from the email address identity@example.com , and the phone number +1 (123) 456 7891 . Attribute Description external_id Optional. An identifier that lets you track the privacy request. See Report on Privacy Requests for more information. requested_at Optional. An ISO8601 timestamp that specifies the moment that the request was submitted. Defaults to the created_at time if not specified. policy_key Identifies the execution policy applied to this request. identities An array of objects. These objects identify any users whose data will be affected by the execution policy. Each object identifies a single user. A full list of attributes available to set on a privacy request can be found in the API documentation . Enable subject identity verification Verifying user identity prior to processing their privacy request requires the following: Set the subject_identity_verification_required variable in your fides.toml to TRUE . Configure Emails that lets Fides send automated emails to your users. With identify verification enabled, a user will be emailed a six-digit code when they submit a privacy request. They must supply that verification code to Fides to continue privacy request execution. Until the Privacy Request identity is verified, it will have a status of identity_unverified : POST api/v1/privacy-request/ /verify 1 { \"code\" : \"<verification code here>\" } Privacy request actions Approve and deny privacy requests Fides processes privacy requests immediately by default. To review privacy requests before they are executed, the require_manual_request_approval variable in your fides.toml must be set to TRUE . To process pending privacy requests, a list of privacy request IDs must be sent to the approve or deny endpoints. Both endpoints support processing requests in bulk. PATCH api/v1/privacy-request/administrate/approve 1 2 3 4 5 6 { \"request_ids\" :[ \"pri_2d181f15-486d-4bcf-a871-f50ed9f95673\" , \"pri_2d181f15-486d-4bcf-a871-f50ed9f95673\" ] } An optional denial reason can be provided when denying a privacy request: PATCH api/v1/privacy-request/administrate/deny 1 2 3 4 5 6 7 { \"request_ids\" :[ \"pri_2d181f15-486d-4bcf-a871-f50ed9f95673\" , \"pri_2d181f15-486d-4bcf-a871-f50ed9f95673\" ], \"reason\" : \"Requests denied because they're duplicates\" } Monitor ongoing requests Privacy requests can be monitored at any time throughout their execution by calling either of the following endpoints: 1 GET api/v1/privacy-request?request_id=<privacy_request_id> 1 GET api/v1/privacy-request?external_id=<external_id> For more detailed examples and further privacy request filtering, see Reporting on Privacy Requests . Restart failed requests To restart a failed privacy request, call the following endpoint with an empty request body: 1 POST /api/v1/privacy-request/<privacy_request_id>/retry Encrypt your requests Access request results can be optionally encrypted by supplying an encryption_key string in the request body. Fides uses the supplied encryption_key to encrypt the contents of your JSON and CSV results using an AES-256 algorithm in GCM mode. When converted to bytes, your encryption_key must be 16 bytes long. The data returned will have the nonce concatenated to the encrypted data. POST /privacy-request 1 2 3 4 5 6 7 8 [ { \"requested_at\" : \"2021-08-30T16:09:37.359Z\" , \"identity\" : { \"email\" : \"customer-1@example.com\" }, \"policy_key\" : \"my_access_policy\" , \"encryption_key\" : \"test--encryption\" } ] Decrypt your results If you specified an encryption key, Fides encrypted the result data using your key and an internally-generated nonce with an AES 256 algorithm in GCM mode. The return value is a 12-byte nonce plus the encrypted data that is b64 encoded together. 1 2 3 +------------------+-------------------+ | nonce (12 bytes) | message (N bytes) | +------------------+-------------------+ For example, if you specified an encryption key of test--encryption , and resulting data was uploaded to S3 in a JSON file GPUiK9tq5k/HfBnSN+J+OvLXZ+GCisapdI2KGP7A1WK+dz1XHef+hWb/SjszdqdNVGvziyY6GF5KIrvrXgxjZuaAvgU=' , you would need to implement something similar to the snippet below to decrypt the result: Sample decryption 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import json import base64 from cryptography.hazmat.primitives.ciphers.aead import AESGCM encrypted : str = \"GPUiK9tq5k/HfBnSN+J+OvLXZ+GCisapdI2KGP7A1WK+dz1XHef+hWb/SjszdqdNVGvziyY6GF5KIrvrXgxjZuaAvgU=\" encryption_key : str = \"test--encryption\" . encode ( \"utf-8\" ) # Only you know this encrypted_combined : bytes = base64 . b64decode ( encrypted ) nonce : bytes = encrypted_combined [ 0 : 12 ] encrypted_message : bytes = encrypted_combined [ 12 :] gcm = AESGCM ( encryption_key ) decrypted_bytes : bytes = gcm . decrypt ( nonce , encrypted_message , nonce ) decrypted_str : str = decrypted_bytes . decode ( \"utf-8\" ) json . loads ( decrypted_str ) Sample result 1 >>> { \"street\" : \"test street\" , \"state\" : \"NY\" } If CSV data was uploaded, each CSV in the zipfile was encrypted using a different nonce, so you'll need to follow a similar process for each CSV file. Privacy request integrations Generic API interoperability : Third party services can be authorized by creating additional OAuth clients. Tokens obtained from OAuth clients can be managed and revoked at any time. See authenticating with OAuth for more information. OneTrust : Fides can be configured to act as (or as part of) the fulfillment layer in OneTrust's Data Subject Request automation flow. See the OneTrust integration guide for more information.","title":"Execute Privacy Requests"},{"location":"getting-started/privacy_requests/#execute-privacy-requests","text":"","title":"Execute Privacy Requests"},{"location":"getting-started/privacy_requests/#what-is-a-privacy-request","text":"A privacy request represents an ask from a user to perform an action on their identity data. The request itself identifies the user by email address, phone number, social security number, or other identifiable information. The data that will be affected, and how it's affected, is described in an execution policy associated with the request. For more information on policies, see the execution policies guide.","title":"What is a Privacy Request?"},{"location":"getting-started/privacy_requests/#submit-a-privacy-request","text":"Privacy Requests are executed immediately by default. This setting may be changed in your fides.toml configuration file. Privacy requests are submitted by calling the Privacy Request endpoint: POST /api/v1/privacy-request 1 2 3 4 5 6 7 8 9 10 11 [ { \"external_id\" : \"a-user-defined-id\" , \"requested_at\" : \"2021-10-31T16:00:00.000Z\" , \"policy_key\" : \"a-demo-policy\" , \"identity\" : { \"email\" : \"identity@example.com\" , \"phone_number\" : \"+1 (123) 456 7891\" } } ] The above request will apply the a-demo-policy execution policy to all target data that can be generated from the email address identity@example.com , and the phone number +1 (123) 456 7891 . Attribute Description external_id Optional. An identifier that lets you track the privacy request. See Report on Privacy Requests for more information. requested_at Optional. An ISO8601 timestamp that specifies the moment that the request was submitted. Defaults to the created_at time if not specified. policy_key Identifies the execution policy applied to this request. identities An array of objects. These objects identify any users whose data will be affected by the execution policy. Each object identifies a single user. A full list of attributes available to set on a privacy request can be found in the API documentation .","title":"Submit a privacy request"},{"location":"getting-started/privacy_requests/#enable-subject-identity-verification","text":"Verifying user identity prior to processing their privacy request requires the following: Set the subject_identity_verification_required variable in your fides.toml to TRUE . Configure Emails that lets Fides send automated emails to your users. With identify verification enabled, a user will be emailed a six-digit code when they submit a privacy request. They must supply that verification code to Fides to continue privacy request execution. Until the Privacy Request identity is verified, it will have a status of identity_unverified : POST api/v1/privacy-request/ /verify 1 { \"code\" : \"<verification code here>\" }","title":"Enable subject identity verification"},{"location":"getting-started/privacy_requests/#privacy-request-actions","text":"","title":"Privacy request actions"},{"location":"getting-started/privacy_requests/#approve-and-deny-privacy-requests","text":"Fides processes privacy requests immediately by default. To review privacy requests before they are executed, the require_manual_request_approval variable in your fides.toml must be set to TRUE . To process pending privacy requests, a list of privacy request IDs must be sent to the approve or deny endpoints. Both endpoints support processing requests in bulk. PATCH api/v1/privacy-request/administrate/approve 1 2 3 4 5 6 { \"request_ids\" :[ \"pri_2d181f15-486d-4bcf-a871-f50ed9f95673\" , \"pri_2d181f15-486d-4bcf-a871-f50ed9f95673\" ] } An optional denial reason can be provided when denying a privacy request: PATCH api/v1/privacy-request/administrate/deny 1 2 3 4 5 6 7 { \"request_ids\" :[ \"pri_2d181f15-486d-4bcf-a871-f50ed9f95673\" , \"pri_2d181f15-486d-4bcf-a871-f50ed9f95673\" ], \"reason\" : \"Requests denied because they're duplicates\" }","title":"Approve and deny privacy requests"},{"location":"getting-started/privacy_requests/#monitor-ongoing-requests","text":"Privacy requests can be monitored at any time throughout their execution by calling either of the following endpoints: 1 GET api/v1/privacy-request?request_id=<privacy_request_id> 1 GET api/v1/privacy-request?external_id=<external_id> For more detailed examples and further privacy request filtering, see Reporting on Privacy Requests .","title":"Monitor ongoing requests"},{"location":"getting-started/privacy_requests/#restart-failed-requests","text":"To restart a failed privacy request, call the following endpoint with an empty request body: 1 POST /api/v1/privacy-request/<privacy_request_id>/retry","title":"Restart failed requests"},{"location":"getting-started/privacy_requests/#encrypt-your-requests","text":"Access request results can be optionally encrypted by supplying an encryption_key string in the request body. Fides uses the supplied encryption_key to encrypt the contents of your JSON and CSV results using an AES-256 algorithm in GCM mode. When converted to bytes, your encryption_key must be 16 bytes long. The data returned will have the nonce concatenated to the encrypted data. POST /privacy-request 1 2 3 4 5 6 7 8 [ { \"requested_at\" : \"2021-08-30T16:09:37.359Z\" , \"identity\" : { \"email\" : \"customer-1@example.com\" }, \"policy_key\" : \"my_access_policy\" , \"encryption_key\" : \"test--encryption\" } ]","title":"Encrypt your requests"},{"location":"getting-started/privacy_requests/#decrypt-your-results","text":"If you specified an encryption key, Fides encrypted the result data using your key and an internally-generated nonce with an AES 256 algorithm in GCM mode. The return value is a 12-byte nonce plus the encrypted data that is b64 encoded together. 1 2 3 +------------------+-------------------+ | nonce (12 bytes) | message (N bytes) | +------------------+-------------------+ For example, if you specified an encryption key of test--encryption , and resulting data was uploaded to S3 in a JSON file GPUiK9tq5k/HfBnSN+J+OvLXZ+GCisapdI2KGP7A1WK+dz1XHef+hWb/SjszdqdNVGvziyY6GF5KIrvrXgxjZuaAvgU=' , you would need to implement something similar to the snippet below to decrypt the result: Sample decryption 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import json import base64 from cryptography.hazmat.primitives.ciphers.aead import AESGCM encrypted : str = \"GPUiK9tq5k/HfBnSN+J+OvLXZ+GCisapdI2KGP7A1WK+dz1XHef+hWb/SjszdqdNVGvziyY6GF5KIrvrXgxjZuaAvgU=\" encryption_key : str = \"test--encryption\" . encode ( \"utf-8\" ) # Only you know this encrypted_combined : bytes = base64 . b64decode ( encrypted ) nonce : bytes = encrypted_combined [ 0 : 12 ] encrypted_message : bytes = encrypted_combined [ 12 :] gcm = AESGCM ( encryption_key ) decrypted_bytes : bytes = gcm . decrypt ( nonce , encrypted_message , nonce ) decrypted_str : str = decrypted_bytes . decode ( \"utf-8\" ) json . loads ( decrypted_str ) Sample result 1 >>> { \"street\" : \"test street\" , \"state\" : \"NY\" } If CSV data was uploaded, each CSV in the zipfile was encrypted using a different nonce, so you'll need to follow a similar process for each CSV file.","title":"Decrypt your results"},{"location":"getting-started/privacy_requests/#privacy-request-integrations","text":"Generic API interoperability : Third party services can be authorized by creating additional OAuth clients. Tokens obtained from OAuth clients can be managed and revoked at any time. See authenticating with OAuth for more information. OneTrust : Fides can be configured to act as (or as part of) the fulfillment layer in OneTrust's Data Subject Request automation flow. See the OneTrust integration guide for more information.","title":"Privacy request integrations"},{"location":"getting-started/storage/","text":"Configure Storage Destinations What is a storage destination? Access requests produce a package of returned data upon completion. This data will need to be uploaded to a storage destination (e.g. an S3 bucket) in order to be returned to the user. Fides never stores privacy request results locally. At least one storage destination must be configured if you wish to process access requests. Storage destinations are associated to execution policies in their Rules , allowing multiple storage destinations to be configured per execution policy. Create a storage destination Configure your storage method To configure a Storage destination, first choose a method to store your results. Fides currently supports the following methods of storage: local - This saves upload packages locally, generating a fides_uploads directory at the root of your project. This destination type should only be used for testing purposes, and not to process real-world access requests. S3 - Files are uploaded to an S3 bucket of your choosing upon completion of an access request. Use S3 if you need a place to store those files. OneTrust - A OneTrust storage destination should be configured for Fides to process requests from an existing OneTrust integration. Read more about how the OneTrust integration here . Create your storage destination Storage destinations are created and managed via the API. To create a new Storage destination, use the following endpoint: PATCH {host}/api/v1/storage/config 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"destinations\" : [ { \"name\" : s tr , \"key\" : FidesKey (op t io nal ) , \"type\" : s tr , \"format\" : s tr \"details\" : { # s 3 \"auth_method\" : s tr , \"bucket\" : s tr , \"naming\" : s tr , # o netrust \"service_name\" : s tr , \"onetrust_polling_hr\" : i nt , \"onetrust_polling_day_of_week\" : i nt } } ] } Destination attributes Attribute Description name A unique user-friendly name for your storage destination. key A unique key used to manage your storage destination. This is auto-generated from name if left blank. Accepted values are alphanumeric, _ , and . . type Type of storage destination. Supported types include s3 , onetrust , and local . You may configure multiple destinations of the same type. format The format of uploaded data. Supported formats include json and csv . For OneTrust and local destination types, use json . Additional attributes for s3 buckets Attribute Description auth_method The authentication method for creating a session with S3. Either automatic or secret_keys . bucket The name of the bucket in S3. naming This defines how the uploaded files will be named. Currently, Fides only supports upload file naming by request_id . Use this value for all your storage destinations. Additional attributes for OneTrust Attribute Description service_name The name of your service or company. This informs OneTrust from where the data obtained from a given access request originated. onetrust_polling_hr The hour, in UTC timezone, at which to poll OneTrust for new requests. Accepts an integer from 0-23, where 0 is midnight. E.g. 7 is 7am UTC. onetrust_polling_day_of_week The day on which to poll OneTrust for new requests. Accepts an int from 0-6 where 0 is Sunday. E.g. 1 is Monday. Additional attributes for local storage Attribute Description naming This defines how the uploaded files will be named. Currently, Fides supports upload file naming by request_id . Use this value for all your storage destinations. On success, the response from the above endpoint will include a storage_key for each destination, which can be used when defining execution policy Rules . Example response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"items\" : [ { \"id\" : \"sto_fe4e4dc0-b5d3-4ac1-bfcd-86e60e9891b9\" , \"name\" : \"s3 storage 2\" , \"type\" : \"s3\" , \"details\" : { \"auth_method\" : \"secret_keys\" , \"bucket\" : \"my-bucket\" , \"naming\" : \"request_id\" , \"object_name\" : \"requests\" }, \"key\" : \"s3_storage_2\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 1 } Authenticate with your destination Fides requires authenticated access to update and erase/mask data in your storage destination. Use storage_key returned during your storage creation to provide access credentials: PUT {host}/api/v1/storage/config/{storage_key}/secret 1 2 3 4 5 6 7 8 9 { # s 3 \"aws_access_key_id\" : s tr , \"aws_secret_access_key\" : s tr # o netrust \"onetrust_hostname\" : s tr \"onetrust_client_id\" : s tr \"onetrust_client_secret\" : s tr } Additional attributes for S3 buckets Fides supports automatically creating a session for S3. If your auth_method is set to automatic , no secrets need to be provided. Boto3 will look for credentials on the server. Attribute Description aws_access_key_id AWS access key id, obtained from AWS console. aws_secret_access_key AWS secret access key, obtained from AWS console. Additional attributes for OneTrust Attribute Description onetrust_hostname Your unique OneTrust hostname, used to call OneTrust REST APIs, e.g. my-company.onetrust . onetrust_client_id OneTrust client ID, obtained from your OneTrust portal. onetrust_client_secret OneTrust client UD, obtained from your OneTrust portal. Secrets are not saved if credentials fail authentication with the given storage destination. Test your storage connection OneTrust destinations need to be tested end-to-end. Use the OneTrust interface to approve a test privacy request. To test that your storage destination works correctly, you can call the upload endpoint directly. Specify a request_id in the path with an arbitrary string: PUT {host}/api/v1/storage/{request_id} 1 2 3 4 5 6 { \"storage_key\" : { s t orage_key }, \"data\" : { #da ta here } } Attribute Description storage_key The key associated with the storage destination. data A dictionary of arbitrary data you wish to upload to storage destination. Extensibility Fides can be extended to support additional storage destinations by: Adding destination-specific enums in src/fides/ops/schemas/storage/storage.py Implementing an authenticator in src/fides/ops/service/storage/storage_authenticator_service.py Implementing the uploader in src/fides/ops/service/storage/storage_uploader_service.py","title":"Configure Storage Destinations"},{"location":"getting-started/storage/#configure-storage-destinations","text":"","title":"Configure Storage Destinations"},{"location":"getting-started/storage/#what-is-a-storage-destination","text":"Access requests produce a package of returned data upon completion. This data will need to be uploaded to a storage destination (e.g. an S3 bucket) in order to be returned to the user. Fides never stores privacy request results locally. At least one storage destination must be configured if you wish to process access requests. Storage destinations are associated to execution policies in their Rules , allowing multiple storage destinations to be configured per execution policy.","title":"What is a storage destination?"},{"location":"getting-started/storage/#create-a-storage-destination","text":"","title":"Create a storage destination"},{"location":"getting-started/storage/#configure-your-storage-method","text":"To configure a Storage destination, first choose a method to store your results. Fides currently supports the following methods of storage: local - This saves upload packages locally, generating a fides_uploads directory at the root of your project. This destination type should only be used for testing purposes, and not to process real-world access requests. S3 - Files are uploaded to an S3 bucket of your choosing upon completion of an access request. Use S3 if you need a place to store those files. OneTrust - A OneTrust storage destination should be configured for Fides to process requests from an existing OneTrust integration. Read more about how the OneTrust integration here .","title":"Configure your storage method"},{"location":"getting-started/storage/#create-your-storage-destination","text":"Storage destinations are created and managed via the API. To create a new Storage destination, use the following endpoint: PATCH {host}/api/v1/storage/config 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"destinations\" : [ { \"name\" : s tr , \"key\" : FidesKey (op t io nal ) , \"type\" : s tr , \"format\" : s tr \"details\" : { # s 3 \"auth_method\" : s tr , \"bucket\" : s tr , \"naming\" : s tr , # o netrust \"service_name\" : s tr , \"onetrust_polling_hr\" : i nt , \"onetrust_polling_day_of_week\" : i nt } } ] }","title":"Create your storage destination"},{"location":"getting-started/storage/#destination-attributes","text":"Attribute Description name A unique user-friendly name for your storage destination. key A unique key used to manage your storage destination. This is auto-generated from name if left blank. Accepted values are alphanumeric, _ , and . . type Type of storage destination. Supported types include s3 , onetrust , and local . You may configure multiple destinations of the same type. format The format of uploaded data. Supported formats include json and csv . For OneTrust and local destination types, use json .","title":"Destination attributes"},{"location":"getting-started/storage/#additional-attributes-for-s3-buckets","text":"Attribute Description auth_method The authentication method for creating a session with S3. Either automatic or secret_keys . bucket The name of the bucket in S3. naming This defines how the uploaded files will be named. Currently, Fides only supports upload file naming by request_id . Use this value for all your storage destinations.","title":"Additional attributes for s3 buckets"},{"location":"getting-started/storage/#additional-attributes-for-onetrust","text":"Attribute Description service_name The name of your service or company. This informs OneTrust from where the data obtained from a given access request originated. onetrust_polling_hr The hour, in UTC timezone, at which to poll OneTrust for new requests. Accepts an integer from 0-23, where 0 is midnight. E.g. 7 is 7am UTC. onetrust_polling_day_of_week The day on which to poll OneTrust for new requests. Accepts an int from 0-6 where 0 is Sunday. E.g. 1 is Monday.","title":"Additional attributes for OneTrust"},{"location":"getting-started/storage/#additional-attributes-for-local-storage","text":"Attribute Description naming This defines how the uploaded files will be named. Currently, Fides supports upload file naming by request_id . Use this value for all your storage destinations. On success, the response from the above endpoint will include a storage_key for each destination, which can be used when defining execution policy Rules . Example response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"items\" : [ { \"id\" : \"sto_fe4e4dc0-b5d3-4ac1-bfcd-86e60e9891b9\" , \"name\" : \"s3 storage 2\" , \"type\" : \"s3\" , \"details\" : { \"auth_method\" : \"secret_keys\" , \"bucket\" : \"my-bucket\" , \"naming\" : \"request_id\" , \"object_name\" : \"requests\" }, \"key\" : \"s3_storage_2\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 1 }","title":"Additional attributes for local storage"},{"location":"getting-started/storage/#authenticate-with-your-destination","text":"Fides requires authenticated access to update and erase/mask data in your storage destination. Use storage_key returned during your storage creation to provide access credentials: PUT {host}/api/v1/storage/config/{storage_key}/secret 1 2 3 4 5 6 7 8 9 { # s 3 \"aws_access_key_id\" : s tr , \"aws_secret_access_key\" : s tr # o netrust \"onetrust_hostname\" : s tr \"onetrust_client_id\" : s tr \"onetrust_client_secret\" : s tr }","title":"Authenticate with your destination"},{"location":"getting-started/storage/#additional-attributes-for-s3-buckets_1","text":"Fides supports automatically creating a session for S3. If your auth_method is set to automatic , no secrets need to be provided. Boto3 will look for credentials on the server. Attribute Description aws_access_key_id AWS access key id, obtained from AWS console. aws_secret_access_key AWS secret access key, obtained from AWS console.","title":"Additional attributes for S3 buckets"},{"location":"getting-started/storage/#additional-attributes-for-onetrust_1","text":"Attribute Description onetrust_hostname Your unique OneTrust hostname, used to call OneTrust REST APIs, e.g. my-company.onetrust . onetrust_client_id OneTrust client ID, obtained from your OneTrust portal. onetrust_client_secret OneTrust client UD, obtained from your OneTrust portal. Secrets are not saved if credentials fail authentication with the given storage destination.","title":"Additional attributes for OneTrust"},{"location":"getting-started/storage/#test-your-storage-connection","text":"OneTrust destinations need to be tested end-to-end. Use the OneTrust interface to approve a test privacy request. To test that your storage destination works correctly, you can call the upload endpoint directly. Specify a request_id in the path with an arbitrary string: PUT {host}/api/v1/storage/{request_id} 1 2 3 4 5 6 { \"storage_key\" : { s t orage_key }, \"data\" : { #da ta here } } Attribute Description storage_key The key associated with the storage destination. data A dictionary of arbitrary data you wish to upload to storage destination.","title":"Test your storage connection"},{"location":"getting-started/storage/#extensibility","text":"Fides can be extended to support additional storage destinations by: Adding destination-specific enums in src/fides/ops/schemas/storage/storage.py Implementing an authenticator in src/fides/ops/service/storage/storage_authenticator_service.py Implementing the uploader in src/fides/ops/service/storage/storage_uploader_service.py","title":"Extensibility"},{"location":"guides/complex_fields/","text":"Annotate Complex Fields Fides can retrieve and mask data from complex objects and arrays in MongoDB. This involves annotating your dataset files to let Fides know about your complex data. Declare an object field To declare an object field, define nested fields underneath that field. In the example below, workplace_info is an object field with two nested fields: employer and position . Data categories cannot be specified at the object level due to potential conflicts with nested fields. Instead, annotate the scalar fields within the object field. Here, the workplace_info.position field has data_category: user.job_title . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 dataset : - fides_key : mongo_nested_object_example name : Mongo Example with Nested Objects description : Example of a Mongo dataset that contains 'details' about customers defined in the 'postgres_example_test_dataset' collections : - name : customer_details fields : - ... - name : workplace_info fidesops_meta : data_type : object fields : - name : employer fidesops_meta : data_type : string - name : position data_categories : [ user.job_title ] fidesops_meta : data_type : string - name : id Reference a nested field To define a relationship between a field on one collection and a nested field on another collection, use dot notation in the fidesops_meta references for as many levels are necessary. In the example below, this field is denoted by <collection_name>.<field_name>.<sub_field> name, or customer_details.workplace_info.id . This relationship could also be defined on the customer_details.workplace_info.id field itself, with a direction of from , with field mydatabase.customer.workplace_id , and dataset mydatabase . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - name : workplace_id data_categories : [ system.operations ] fidesops_meta : references : - dataset : mongo_nested_object_example field : customer_details.workplace_info.id direction : to ... Declare an array field There is no official array type. Instead, an array is represented by a [] flag on a field. Declare an array of scalar values In this example, the mydatabase:customer collection has a travel_identifiers field that is an string array, described by data_type: string[] . An array of integers would be described by data_type: integer[] . 1 2 3 4 5 6 7 8 9 10 11 12 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - ... - name : travel_identifiers fidesops_meta : data_type : string[] data_categories : [ system.operations ] Declare a nested array In this example, the mydatabase:customer collection has a nested workplace_info.direct_reports string array. We define direct_reports as a subfield under workplace_info , as well as add the data_type string[] to direct_reports . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - name : workplace_info fidesops_meta : data_type : object fields : - name : employer fidesops_meta : data_type : string - name : position data_categories : [ user.job_title ] fidesops_meta : data_type : string - name : direct_reports data_categories : [ user.name ] fidesops_meta : data_type : string[] Declare an array of objects In this example, the mydatabase:customer collection has an emergency_contacts object array field, or embedded documents, denoted by data_type: object[] . Each object in the emergency_contacts array can contain a name , relationship , and phone field. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - name : emergency_contacts fidesops_meta : data_type : object[] fields : - name : name data_categories : [ user.name ] fidesops_meta : data_type : string - name : relationship fidesops_meta : data_type : string - name : phone data_categories : [ user.contact.phone_number ] fidesops_meta : data_type : string Reference an array Reference an array field as if it is any other field. You cannot currently reference a specific index in an array field, but Fides will search an array field for matches. In this example, mydatabase:flights.plane is an integer field that will be used to lookup records that match an integer in the mydatabase:aircraft.planes array. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : flights fields : - ... - name : passenger_information fields : - name : passenger_ids fidesops_meta : data_type : string[] - name : plane data_categories : [ system.operations ] fidesops_meta : data_type : integer - name : aircraft fields : - name : _id data_categories : [ system.operations ] fidesops_meta : primary_key : True data_type : object_id - name : planes data_categories : [ system.operations ] fidesops_meta : data_type : integer[] references : - dataset : mydatabase field : flights.plane direction : from - name : model data_categories : [ system.operations ] fidesops_meta : data_type : string In this more complicated example, a field in an array of objects is used to look up a different field in an array of objects in another collection. Potentially multiple values from mydatabase:customer.comments.comment_id can be used to query for corresponding values in mydatabase:conversations.thread.comment . Because this field is in an array of objects, multiple matches may be found. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - name : comments fidesops_meta : data_type : object[] fields : - name : comment_id fidesops_meta : data_type : string references : - dataset : mydatabase field : conversations.thread.comment direction : to - name : conversations fidesops_meta : data_type : object[] fields : - name : thread fields : - name : comment fidesops_meta : data_type : string - name : message fidesops_meta : data_type : string - name : chat_name data_categories : [ user.name ] fidesops_meta : data_type : string Query an array There are some assumptions made with array querying that may or may not fit with how your data is structured. If an array is an entrypoint into a collection (i.e., one collection references its array field), there is ambiguity around how the queries should be built. (e.g., AND versus OR, and whether only the matched indices or matched embedded documents within arrays should be considered). Assumptions If an array is the entry point into a node, Fides will search for corresponding matches across the entire array. You cannot specify a certain index. Fides operates on \"OR\" queries. Data returned from multiple array fields will be flattened before being passed into the next collection. For example, Collection A returned values [1, 2, 3], and Collection B returned values [4, 5, 6]. Collection C has an array field that depends on both Collection A and Collection B. Fides will search Collection C's array field to return any record that contains one of the values [1, 2, 3, 4, 5, 6] in the array. By default, if an array field is an entry point to a node, only matching indices in that array are considered, both for access and erasures, as well as for subsequent queries on dependent collections where applicable. For example, a query on Collection A only matched indices 0 and 1 in an array. Only the data located at indices 0 and 1 will be returned, and used to query data on dependent collection C. This can be overridden by specifying return_all_elements: true on an entrypoint array field, in which case, the query will return the entire array and/or mask the entire array. Individual array elements are masked, not the entire array, e.g. [\"MASKED\", \"MASKED\", \"MASKED\"] Example query traversal This is an example traversal created from the test postgres_example and mongo_test datasets. Multiple collections point to or from complex objects and arrays. See the mongo_example_test_dataset.yml for more information.","title":"Annotate Complex Fields"},{"location":"guides/complex_fields/#annotate-complex-fields","text":"Fides can retrieve and mask data from complex objects and arrays in MongoDB. This involves annotating your dataset files to let Fides know about your complex data.","title":"Annotate Complex Fields"},{"location":"guides/complex_fields/#declare-an-object-field","text":"To declare an object field, define nested fields underneath that field. In the example below, workplace_info is an object field with two nested fields: employer and position . Data categories cannot be specified at the object level due to potential conflicts with nested fields. Instead, annotate the scalar fields within the object field. Here, the workplace_info.position field has data_category: user.job_title . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 dataset : - fides_key : mongo_nested_object_example name : Mongo Example with Nested Objects description : Example of a Mongo dataset that contains 'details' about customers defined in the 'postgres_example_test_dataset' collections : - name : customer_details fields : - ... - name : workplace_info fidesops_meta : data_type : object fields : - name : employer fidesops_meta : data_type : string - name : position data_categories : [ user.job_title ] fidesops_meta : data_type : string - name : id","title":"Declare an object field"},{"location":"guides/complex_fields/#reference-a-nested-field","text":"To define a relationship between a field on one collection and a nested field on another collection, use dot notation in the fidesops_meta references for as many levels are necessary. In the example below, this field is denoted by <collection_name>.<field_name>.<sub_field> name, or customer_details.workplace_info.id . This relationship could also be defined on the customer_details.workplace_info.id field itself, with a direction of from , with field mydatabase.customer.workplace_id , and dataset mydatabase . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - name : workplace_id data_categories : [ system.operations ] fidesops_meta : references : - dataset : mongo_nested_object_example field : customer_details.workplace_info.id direction : to ...","title":"Reference a nested field"},{"location":"guides/complex_fields/#declare-an-array-field","text":"There is no official array type. Instead, an array is represented by a [] flag on a field.","title":"Declare an array field"},{"location":"guides/complex_fields/#declare-an-array-of-scalar-values","text":"In this example, the mydatabase:customer collection has a travel_identifiers field that is an string array, described by data_type: string[] . An array of integers would be described by data_type: integer[] . 1 2 3 4 5 6 7 8 9 10 11 12 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - ... - name : travel_identifiers fidesops_meta : data_type : string[] data_categories : [ system.operations ]","title":"Declare an array of scalar values"},{"location":"guides/complex_fields/#declare-a-nested-array","text":"In this example, the mydatabase:customer collection has a nested workplace_info.direct_reports string array. We define direct_reports as a subfield under workplace_info , as well as add the data_type string[] to direct_reports . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - name : workplace_info fidesops_meta : data_type : object fields : - name : employer fidesops_meta : data_type : string - name : position data_categories : [ user.job_title ] fidesops_meta : data_type : string - name : direct_reports data_categories : [ user.name ] fidesops_meta : data_type : string[]","title":"Declare a nested array"},{"location":"guides/complex_fields/#declare-an-array-of-objects","text":"In this example, the mydatabase:customer collection has an emergency_contacts object array field, or embedded documents, denoted by data_type: object[] . Each object in the emergency_contacts array can contain a name , relationship , and phone field. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - name : emergency_contacts fidesops_meta : data_type : object[] fields : - name : name data_categories : [ user.name ] fidesops_meta : data_type : string - name : relationship fidesops_meta : data_type : string - name : phone data_categories : [ user.contact.phone_number ] fidesops_meta : data_type : string","title":"Declare an array of objects"},{"location":"guides/complex_fields/#reference-an-array","text":"Reference an array field as if it is any other field. You cannot currently reference a specific index in an array field, but Fides will search an array field for matches. In this example, mydatabase:flights.plane is an integer field that will be used to lookup records that match an integer in the mydatabase:aircraft.planes array. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : flights fields : - ... - name : passenger_information fields : - name : passenger_ids fidesops_meta : data_type : string[] - name : plane data_categories : [ system.operations ] fidesops_meta : data_type : integer - name : aircraft fields : - name : _id data_categories : [ system.operations ] fidesops_meta : primary_key : True data_type : object_id - name : planes data_categories : [ system.operations ] fidesops_meta : data_type : integer[] references : - dataset : mydatabase field : flights.plane direction : from - name : model data_categories : [ system.operations ] fidesops_meta : data_type : string In this more complicated example, a field in an array of objects is used to look up a different field in an array of objects in another collection. Potentially multiple values from mydatabase:customer.comments.comment_id can be used to query for corresponding values in mydatabase:conversations.thread.comment . Because this field is in an array of objects, multiple matches may be found. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : customer fields : - name : comments fidesops_meta : data_type : object[] fields : - name : comment_id fidesops_meta : data_type : string references : - dataset : mydatabase field : conversations.thread.comment direction : to - name : conversations fidesops_meta : data_type : object[] fields : - name : thread fields : - name : comment fidesops_meta : data_type : string - name : message fidesops_meta : data_type : string - name : chat_name data_categories : [ user.name ] fidesops_meta : data_type : string","title":"Reference an array"},{"location":"guides/complex_fields/#query-an-array","text":"There are some assumptions made with array querying that may or may not fit with how your data is structured. If an array is an entrypoint into a collection (i.e., one collection references its array field), there is ambiguity around how the queries should be built. (e.g., AND versus OR, and whether only the matched indices or matched embedded documents within arrays should be considered).","title":"Query an array"},{"location":"guides/complex_fields/#assumptions","text":"If an array is the entry point into a node, Fides will search for corresponding matches across the entire array. You cannot specify a certain index. Fides operates on \"OR\" queries. Data returned from multiple array fields will be flattened before being passed into the next collection. For example, Collection A returned values [1, 2, 3], and Collection B returned values [4, 5, 6]. Collection C has an array field that depends on both Collection A and Collection B. Fides will search Collection C's array field to return any record that contains one of the values [1, 2, 3, 4, 5, 6] in the array. By default, if an array field is an entry point to a node, only matching indices in that array are considered, both for access and erasures, as well as for subsequent queries on dependent collections where applicable. For example, a query on Collection A only matched indices 0 and 1 in an array. Only the data located at indices 0 and 1 will be returned, and used to query data on dependent collection C. This can be overridden by specifying return_all_elements: true on an entrypoint array field, in which case, the query will return the entire array and/or mask the entire array. Individual array elements are masked, not the entire array, e.g. [\"MASKED\", \"MASKED\", \"MASKED\"]","title":"Assumptions"},{"location":"guides/complex_fields/#example-query-traversal","text":"This is an example traversal created from the test postgres_example and mongo_test datasets. Multiple collections point to or from complex objects and arrays. See the mongo_example_test_dataset.yml for more information.","title":"Example query traversal"},{"location":"guides/connection_types/","text":"Connection Types Available Connection Types To view a list of all available connection types, visit GET /api/v1/connection_type . This endpoint can be filtered with a search query param or a system_type query param and is subject to change. We include database options and third party API services with which fidesops can communicate. GET /api/v1/connection_type 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 { \"items\" : [ { \"identifier\" : \"bigquery\" , \"type\" : \"database\" , \"human_readable\" : \"BigQuery\" }, { \"identifier\" : \"mariadb\" , \"type\" : \"database\" , \"human_readable\" : \"MariaDB\" }, { \"identifier\" : \"mongodb\" , \"type\" : \"database\" , \"human_readable\" : \"MongoDB\" }, { \"identifier\" : \"mssql\" , \"type\" : \"database\" , \"human_readable\" : \"Microsoft SQL Server\" }, { \"identifier\" : \"mysql\" , \"type\" : \"database\" , \"human_readable\" : \"MySQL\" }, { \"identifier\" : \"postgres\" , \"type\" : \"database\" , \"human_readable\" : \"PostgreSQL\" }, { \"identifier\" : \"redshift\" , \"type\" : \"database\" , \"human_readable\" : \"Amazon Redshift\" }, { \"identifier\" : \"snowflake\" , \"type\" : \"database\" , \"human_readable\" : \"Snowflake\" }, { \"identifier\" : \"adobe_campaign\" , \"type\" : \"saas\" , \"human_readable\" : \"Adobe Campaign\" }, { \"identifier\" : \"auth0\" , \"type\" : \"saas\" , \"human_readable\" : \"Auth0\" }, { \"identifier\" : \"datadog\" , \"type\" : \"saas\" , \"human_readable\" : \"Datadog\" }, { \"identifier\" : \"hubspot\" , \"type\" : \"saas\" , \"human_readable\" : \"HubSpot\" }, { \"identifier\" : \"mailchimp\" , \"type\" : \"saas\" , \"human_readable\" : \"Mailchimp\" }, { \"identifier\" : \"outreach\" , \"type\" : \"saas\" , \"human_readable\" : \"Outreach\" }, { \"identifier\" : \"salesforce\" , \"type\" : \"saas\" , \"human_readable\" : \"Salesforce\" }, { \"identifier\" : \"segment\" , \"type\" : \"saas\" , \"human_readable\" : \"Segment\" }, { \"identifier\" : \"sendgrid\" , \"type\" : \"saas\" , \"human_readable\" : \"SendGrid\" }, { \"identifier\" : \"sentry\" , \"type\" : \"saas\" , \"human_readable\" : \"Sentry\" }, { \"identifier\" : \"shopify\" , \"type\" : \"saas\" , \"human_readable\" : \"Shopify\" }, { \"identifier\" : \"stripe\" , \"type\" : \"saas\" , \"human_readable\" : \"Stripe\" }, { \"identifier\" : \"zendesk\" , \"type\" : \"saas\" , \"human_readable\" : \"Zendesk\" }, { \"identifier\" : \"manual_webhook\" , \"type\" : \"manual\" , \"human_readable\" : \"Manual Webhook\" } ], \"total\" : 23 , \"page\" : 1 , \"size\" : 50 } Required Connection Secrets To view the secrets needed to authenticate with a given connection, visit GET /api/v1/connection_type/<connection_type>/secret . Example GET /api/v1/connection_type/sentry/secret 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"title\" : \"sentry_schema\" , \"description\" : \"Sentry secrets schema\" , \"type\" : \"object\" , \"properties\" : { \"access_token\" : { \"title\" : \"Access Token\" , \"type\" : \"string\" }, \"domain\" : { \"title\" : \"Domain\" , \"default\" : \"sentry.io\" , \"type\" : \"string\" } }, \"required\" : [ \"access_token\" ], \"additionalProperties\" : false } Setting up a SaaS Connector from a Template To create all the resources necessary to set up a SaaS Connector in one request, you can create a connector from a template. This creates a saas ConnectionConfig for you with your supplied name and description, with your supplied secrets . In the example below, we're creating a mailchimp saas connector, so you should supply the relevant mailchimp secrets . Your instance_key will become the identifier for the related DatasetConfig resource. By default, the saas connection config is enabled, with write access. POST /connection/instantiate/mailchimp 1 2 3 4 5 6 7 8 9 10 { \"name\" : \"My Mailchimp connector\" , \"description\" : \"Production Mailchimp Instance\" , \"secrets\" : { \"domain\" : \"{{mailchimp_domain}}\" , \"api_key\" : \"{{mailchimp_api_key}}\" , \"username\" : \"{{mailchimp_username}}\" }, \"instance_key\" : \"primary_mailchimp\" , }","title":"View Available Connection Types"},{"location":"guides/connection_types/#connection-types","text":"","title":"Connection Types"},{"location":"guides/connection_types/#available-connection-types","text":"To view a list of all available connection types, visit GET /api/v1/connection_type . This endpoint can be filtered with a search query param or a system_type query param and is subject to change. We include database options and third party API services with which fidesops can communicate. GET /api/v1/connection_type 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 { \"items\" : [ { \"identifier\" : \"bigquery\" , \"type\" : \"database\" , \"human_readable\" : \"BigQuery\" }, { \"identifier\" : \"mariadb\" , \"type\" : \"database\" , \"human_readable\" : \"MariaDB\" }, { \"identifier\" : \"mongodb\" , \"type\" : \"database\" , \"human_readable\" : \"MongoDB\" }, { \"identifier\" : \"mssql\" , \"type\" : \"database\" , \"human_readable\" : \"Microsoft SQL Server\" }, { \"identifier\" : \"mysql\" , \"type\" : \"database\" , \"human_readable\" : \"MySQL\" }, { \"identifier\" : \"postgres\" , \"type\" : \"database\" , \"human_readable\" : \"PostgreSQL\" }, { \"identifier\" : \"redshift\" , \"type\" : \"database\" , \"human_readable\" : \"Amazon Redshift\" }, { \"identifier\" : \"snowflake\" , \"type\" : \"database\" , \"human_readable\" : \"Snowflake\" }, { \"identifier\" : \"adobe_campaign\" , \"type\" : \"saas\" , \"human_readable\" : \"Adobe Campaign\" }, { \"identifier\" : \"auth0\" , \"type\" : \"saas\" , \"human_readable\" : \"Auth0\" }, { \"identifier\" : \"datadog\" , \"type\" : \"saas\" , \"human_readable\" : \"Datadog\" }, { \"identifier\" : \"hubspot\" , \"type\" : \"saas\" , \"human_readable\" : \"HubSpot\" }, { \"identifier\" : \"mailchimp\" , \"type\" : \"saas\" , \"human_readable\" : \"Mailchimp\" }, { \"identifier\" : \"outreach\" , \"type\" : \"saas\" , \"human_readable\" : \"Outreach\" }, { \"identifier\" : \"salesforce\" , \"type\" : \"saas\" , \"human_readable\" : \"Salesforce\" }, { \"identifier\" : \"segment\" , \"type\" : \"saas\" , \"human_readable\" : \"Segment\" }, { \"identifier\" : \"sendgrid\" , \"type\" : \"saas\" , \"human_readable\" : \"SendGrid\" }, { \"identifier\" : \"sentry\" , \"type\" : \"saas\" , \"human_readable\" : \"Sentry\" }, { \"identifier\" : \"shopify\" , \"type\" : \"saas\" , \"human_readable\" : \"Shopify\" }, { \"identifier\" : \"stripe\" , \"type\" : \"saas\" , \"human_readable\" : \"Stripe\" }, { \"identifier\" : \"zendesk\" , \"type\" : \"saas\" , \"human_readable\" : \"Zendesk\" }, { \"identifier\" : \"manual_webhook\" , \"type\" : \"manual\" , \"human_readable\" : \"Manual Webhook\" } ], \"total\" : 23 , \"page\" : 1 , \"size\" : 50 }","title":"Available Connection Types"},{"location":"guides/connection_types/#required-connection-secrets","text":"To view the secrets needed to authenticate with a given connection, visit GET /api/v1/connection_type/<connection_type>/secret .","title":"Required Connection Secrets"},{"location":"guides/connection_types/#example","text":"GET /api/v1/connection_type/sentry/secret 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"title\" : \"sentry_schema\" , \"description\" : \"Sentry secrets schema\" , \"type\" : \"object\" , \"properties\" : { \"access_token\" : { \"title\" : \"Access Token\" , \"type\" : \"string\" }, \"domain\" : { \"title\" : \"Domain\" , \"default\" : \"sentry.io\" , \"type\" : \"string\" } }, \"required\" : [ \"access_token\" ], \"additionalProperties\" : false }","title":"Example"},{"location":"guides/connection_types/#setting-up-a-saas-connector-from-a-template","text":"To create all the resources necessary to set up a SaaS Connector in one request, you can create a connector from a template. This creates a saas ConnectionConfig for you with your supplied name and description, with your supplied secrets . In the example below, we're creating a mailchimp saas connector, so you should supply the relevant mailchimp secrets . Your instance_key will become the identifier for the related DatasetConfig resource. By default, the saas connection config is enabled, with write access. POST /connection/instantiate/mailchimp 1 2 3 4 5 6 7 8 9 10 { \"name\" : \"My Mailchimp connector\" , \"description\" : \"Production Mailchimp Instance\" , \"secrets\" : { \"domain\" : \"{{mailchimp_domain}}\" , \"api_key\" : \"{{mailchimp_api_key}}\" , \"username\" : \"{{mailchimp_username}}\" }, \"instance_key\" : \"primary_mailchimp\" , }","title":"Setting up a SaaS Connector from a Template"},{"location":"guides/data_rights_protocol/","text":"Data Rights Protocol The Data Rights Protocol (DRP) is a technical standard for exchanging data rights requests under regulations like the California Consumer Privacy Act (CCPA). As a Privacy Infrastructure Provider (PIP), Fides conforms to the DRP standards to receive and process Data Rights Requests. The following endpoints and actions are available in Fides for working within the DRP specifications. DRP Actions A DRP action may be defined when creating or editing a policy . These actions associate a Fides execution policy with a DRP-standardized protocol for receiving and processing Data Rights Requests. A given action may only be associated to a single policy: PATCH /api/v1/policy 1 2 3 4 5 6 7 [ { \"name\" : \"User Email Address\" , \"key\" : \"user_email_address_policy\" , \"drp_action\" : \"access\" } ] Available actions The following actions may be associated to a policy via the drp_action attribute, which correspond to the DRP's set of supported rights . Action Use sale:opt_out Right to opt out of data sale sale:opt_in Reconsent, or opt-in to data sale deletion Right to Delete access Right to Know access:categories Right to Know access:specific Right to Know Endpoints Once a policy is associated with an action, the following DRP-standardized endpoints are available. Exercise The /exercise endpoint creates a new DRP privacy request. Fides will execute this request based on the policy associated to the DRP action specified in exercise . All identity information should be encapsulated in the provided identity field using RFC7515-encoded JSON Web Tokens . More about identity ecapsulation can be found in the DRP standard . POST /api/v1/drp/exercise 1 2 3 4 5 6 7 8 9 { \"meta\" : { \"version\" : \"0.5\" }, \"exercise\" : [ \"sale:opt-out\" ], \"identity\" : \"jwt\" , } Response 1 2 3 4 5 6 { \"request_id\" : \"c789ff35-7644-4ceb-9981-4b35c264aac3\" , \"received_at\" : \"20210902T152725.403-0700\" , \"expected_by\" : \"20211015T152725.403-0700\" , \"status\" : \"open\" , } Status The current status of an existing privacy request may be returned via the /status endpoint, which must be queried using a privacy request ID. GET /api/v1/drp/status?request_id={privacy_request_id} 1 2 3 4 { \"request_id\" : \"c789ff35-7644-4ceb-9981-4b35c264aac3\" , \"status\" : \"open\" , } Data Rights All data rights associated with existing policies may be returned via the /data-rights endpoint. Note that the v1 in the below URL does not correspond to DRP version, but instead corresponds to Fides version. GET /api/v1/drp/data-rights 1 2 3 4 5 6 7 8 { \"version\" : \"0.5\" , \"api_base\" : null , \"actions\" : [ \"access\" ], \"user_relationships\" : null } Revoke You can revoke a pending privacy request via the /revoke endpoint. GET /api/v1/drp/revoke 1 2 3 4 { \"request_id\" : \"c789ff35-7644-4ceb-9981-4b35c264aac3\" , \"reason\" : \"Accidentally submitted\" }","title":"Data Rights Protocol"},{"location":"guides/data_rights_protocol/#data-rights-protocol","text":"The Data Rights Protocol (DRP) is a technical standard for exchanging data rights requests under regulations like the California Consumer Privacy Act (CCPA). As a Privacy Infrastructure Provider (PIP), Fides conforms to the DRP standards to receive and process Data Rights Requests. The following endpoints and actions are available in Fides for working within the DRP specifications.","title":"Data Rights Protocol"},{"location":"guides/data_rights_protocol/#drp-actions","text":"A DRP action may be defined when creating or editing a policy . These actions associate a Fides execution policy with a DRP-standardized protocol for receiving and processing Data Rights Requests. A given action may only be associated to a single policy: PATCH /api/v1/policy 1 2 3 4 5 6 7 [ { \"name\" : \"User Email Address\" , \"key\" : \"user_email_address_policy\" , \"drp_action\" : \"access\" } ]","title":"DRP Actions"},{"location":"guides/data_rights_protocol/#available-actions","text":"The following actions may be associated to a policy via the drp_action attribute, which correspond to the DRP's set of supported rights . Action Use sale:opt_out Right to opt out of data sale sale:opt_in Reconsent, or opt-in to data sale deletion Right to Delete access Right to Know access:categories Right to Know access:specific Right to Know","title":"Available actions"},{"location":"guides/data_rights_protocol/#endpoints","text":"Once a policy is associated with an action, the following DRP-standardized endpoints are available.","title":"Endpoints"},{"location":"guides/data_rights_protocol/#exercise","text":"The /exercise endpoint creates a new DRP privacy request. Fides will execute this request based on the policy associated to the DRP action specified in exercise . All identity information should be encapsulated in the provided identity field using RFC7515-encoded JSON Web Tokens . More about identity ecapsulation can be found in the DRP standard . POST /api/v1/drp/exercise 1 2 3 4 5 6 7 8 9 { \"meta\" : { \"version\" : \"0.5\" }, \"exercise\" : [ \"sale:opt-out\" ], \"identity\" : \"jwt\" , } Response 1 2 3 4 5 6 { \"request_id\" : \"c789ff35-7644-4ceb-9981-4b35c264aac3\" , \"received_at\" : \"20210902T152725.403-0700\" , \"expected_by\" : \"20211015T152725.403-0700\" , \"status\" : \"open\" , }","title":"Exercise"},{"location":"guides/data_rights_protocol/#status","text":"The current status of an existing privacy request may be returned via the /status endpoint, which must be queried using a privacy request ID. GET /api/v1/drp/status?request_id={privacy_request_id} 1 2 3 4 { \"request_id\" : \"c789ff35-7644-4ceb-9981-4b35c264aac3\" , \"status\" : \"open\" , }","title":"Status"},{"location":"guides/data_rights_protocol/#data-rights","text":"All data rights associated with existing policies may be returned via the /data-rights endpoint. Note that the v1 in the below URL does not correspond to DRP version, but instead corresponds to Fides version. GET /api/v1/drp/data-rights 1 2 3 4 5 6 7 8 { \"version\" : \"0.5\" , \"api_base\" : null , \"actions\" : [ \"access\" ], \"user_relationships\" : null }","title":"Data Rights"},{"location":"guides/data_rights_protocol/#revoke","text":"You can revoke a pending privacy request via the /revoke endpoint. GET /api/v1/drp/revoke 1 2 3 4 { \"request_id\" : \"c789ff35-7644-4ceb-9981-4b35c264aac3\" , \"reason\" : \"Accidentally submitted\" }","title":"Revoke"},{"location":"guides/email_communications/","text":"Configure Email Communications What is email used for? Fides supports email server configurations for sending processing notices to privacy request subjects. Future updates will support outbound email communications with data processors. Supported modes of use: Subject Identity Verification - for more information on identity verification in subject requests, see the Privacy Requests guide. Prerequisites Fides currently supports Mailgun for email integrations. Ensure you register or use an existing Mailgun account in order to get up and running with email communications. Generate a Mailgun Domain Sending Key Follow the Mailgun documentation to create a new Domain Sending Key for Fides. Note Mailgun automatically generates a primary account API key when you sign up for an account. This key allows you to perform all CRUD operations via Mailgun's API endpoints, and for any of your sending domains. For security purposes, using a new domain sending key is recommended over your primary API key. Configuration Create the email configuration POST api/v1/email/config 1 2 3 4 5 6 7 8 { \"key\" : \"{{email_config_key}}\" , \"name\" : \"mailgun\" , \"service_type\" : \"mailgun\" , \"details\" : { \"domain\" : \"your.mailgun.domain\" } } Field Description key Optional. A unique key used to manage your email config. This is auto-generated from name if left blank. Accepted values are alphanumeric, _ , and . . name A unique user-friendly name for your email config. service_type The email service to configure. Currently, Fides supports mailgun . details A dict of key/val config vars specific to Mailgun. domain Your unique Mailgun domain. is_eu_domain Optional. A boolean that denotes whether your Mailgun domain was created in the EU region. Defaults to False . api_version Optional. A string that denotes the API version. Defaults to v3 . Add the email configuration secrets POST api/v1/email/config/{{email_config_key}}/secret 1 2 3 { \"mailgun_api_key\" : \"nc123849ycnpq98fnu\" } Field Description mailgun_api_key Your Mailgun Domain Sending Key.","title":"Configure Email Communications"},{"location":"guides/email_communications/#configure-email-communications","text":"","title":"Configure Email Communications"},{"location":"guides/email_communications/#what-is-email-used-for","text":"Fides supports email server configurations for sending processing notices to privacy request subjects. Future updates will support outbound email communications with data processors. Supported modes of use: Subject Identity Verification - for more information on identity verification in subject requests, see the Privacy Requests guide.","title":"What is email used for?"},{"location":"guides/email_communications/#prerequisites","text":"Fides currently supports Mailgun for email integrations. Ensure you register or use an existing Mailgun account in order to get up and running with email communications. Generate a Mailgun Domain Sending Key Follow the Mailgun documentation to create a new Domain Sending Key for Fides. Note Mailgun automatically generates a primary account API key when you sign up for an account. This key allows you to perform all CRUD operations via Mailgun's API endpoints, and for any of your sending domains. For security purposes, using a new domain sending key is recommended over your primary API key.","title":"Prerequisites"},{"location":"guides/email_communications/#configuration","text":"","title":"Configuration"},{"location":"guides/email_communications/#create-the-email-configuration","text":"POST api/v1/email/config 1 2 3 4 5 6 7 8 { \"key\" : \"{{email_config_key}}\" , \"name\" : \"mailgun\" , \"service_type\" : \"mailgun\" , \"details\" : { \"domain\" : \"your.mailgun.domain\" } } Field Description key Optional. A unique key used to manage your email config. This is auto-generated from name if left blank. Accepted values are alphanumeric, _ , and . . name A unique user-friendly name for your email config. service_type The email service to configure. Currently, Fides supports mailgun . details A dict of key/val config vars specific to Mailgun. domain Your unique Mailgun domain. is_eu_domain Optional. A boolean that denotes whether your Mailgun domain was created in the EU region. Defaults to False . api_version Optional. A string that denotes the API version. Defaults to v3 .","title":"Create the email configuration"},{"location":"guides/email_communications/#add-the-email-configuration-secrets","text":"POST api/v1/email/config/{{email_config_key}}/secret 1 2 3 { \"mailgun_api_key\" : \"nc123849ycnpq98fnu\" } Field Description mailgun_api_key Your Mailgun Domain Sending Key.","title":"Add the email configuration secrets"},{"location":"guides/extend_taxonomy/","text":"Extending the Default Taxonomy Fides' default taxonomy can be extended to ensure interoperability inside and outside your organization. Extending the existing categories allows the use of attribution when exporting data from Fides, and when adding context or clarity for legal teams. If you have suggestions for core categories that should ship with the taxonomy, requests can be submitted on the Fides Github . Implementing a custom Data Use A Data Use is a label that denotes the way data is used in your system. The following is an example of extending the default Data Use taxonomy : data_use.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 data_use : - fides_key : third_party_sharing.legal_obligation.payroll name : Payroll description : Legally obliged sharing of payroll information recipients : - HMRC - IRS - NYDTF legal_basis : Legal Obligation special_category : Employment parent_key : third_party_sharing.legal_obligation - fides_key : third_party_sharing.personalized_advertising.direct_marketing name : Direct Marketing description : Consented user information for direct marketing purposes recipients : - Processor - marketing co. legal_basis : Consent special_category : Consent parent_key : third_party_sharing.personalized_advertising The above example uses the existing demo_data_uses.yml from the Fides project . Further details for each field are below: Field Description fides_key Ideally extended from the existing taxonomy using the dot ( . ) separator. A string token that uniquely identifies this Data Use. name A UI-friendly name that will also be surfaced as the Purpose of Processing when exporting data from Fides. description An optional description of the purpose of processing. recipients A list of recipients of personal data for this data use. The Payroll example above has multiple recipients for tax purposes. legal_basis The legal basis category for processing, used as part of exporting data from Fides. Loosely tied to article 6 of the GDPR. special_category The special category associated to processing of personal data. Loosely tied to article 9 of the GDPR. parent_key The parent Data Use fides_key extended from. Implementing a custom Data Subject A Data Subject is a label that describes a segment of individuals whose data you store. The following is an example of extending the Data Subject taxonomy : data_subject.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 data_subject : - fides_key : potential_customer name : Potential Customer description : A prospective individual or other organization that purchases goods or services from the organization. rights : strategy : INCLUDE values : - Informed - Access - Rectification - Erasure - Object automated_decisions_or_profiling : true The above example uses the existing demo_data_subjects.yml from the Fides project . Further details for each field are below: Label Description fides_key Ideally extended from the existing taxonomy using the dot ( . ) separator. A string token that uniquely identifies this Data Use. name A UI-friendly name that will also be surfaced as the Categories of individuals when exporting data from Fides. description An optional description of the data subject. rights A strategy of how to apply data subject rights, along with an optional list to complement the strategy. automated_decisions_or_profiling If automated decision-making or profiling exists for this data subject, set as either true or false. Next Steps Once created, your new Data Subject or Data Use can be referenced as part of a privacy declaration in a system , throughout your policies , and in other Fides resources .","title":"Extend the Taxonomy"},{"location":"guides/extend_taxonomy/#extending-the-default-taxonomy","text":"Fides' default taxonomy can be extended to ensure interoperability inside and outside your organization. Extending the existing categories allows the use of attribution when exporting data from Fides, and when adding context or clarity for legal teams. If you have suggestions for core categories that should ship with the taxonomy, requests can be submitted on the Fides Github .","title":"Extending the Default Taxonomy"},{"location":"guides/extend_taxonomy/#implementing-a-custom-data-use","text":"A Data Use is a label that denotes the way data is used in your system. The following is an example of extending the default Data Use taxonomy : data_use.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 data_use : - fides_key : third_party_sharing.legal_obligation.payroll name : Payroll description : Legally obliged sharing of payroll information recipients : - HMRC - IRS - NYDTF legal_basis : Legal Obligation special_category : Employment parent_key : third_party_sharing.legal_obligation - fides_key : third_party_sharing.personalized_advertising.direct_marketing name : Direct Marketing description : Consented user information for direct marketing purposes recipients : - Processor - marketing co. legal_basis : Consent special_category : Consent parent_key : third_party_sharing.personalized_advertising The above example uses the existing demo_data_uses.yml from the Fides project . Further details for each field are below: Field Description fides_key Ideally extended from the existing taxonomy using the dot ( . ) separator. A string token that uniquely identifies this Data Use. name A UI-friendly name that will also be surfaced as the Purpose of Processing when exporting data from Fides. description An optional description of the purpose of processing. recipients A list of recipients of personal data for this data use. The Payroll example above has multiple recipients for tax purposes. legal_basis The legal basis category for processing, used as part of exporting data from Fides. Loosely tied to article 6 of the GDPR. special_category The special category associated to processing of personal data. Loosely tied to article 9 of the GDPR. parent_key The parent Data Use fides_key extended from.","title":"Implementing a custom Data Use"},{"location":"guides/extend_taxonomy/#implementing-a-custom-data-subject","text":"A Data Subject is a label that describes a segment of individuals whose data you store. The following is an example of extending the Data Subject taxonomy : data_subject.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 data_subject : - fides_key : potential_customer name : Potential Customer description : A prospective individual or other organization that purchases goods or services from the organization. rights : strategy : INCLUDE values : - Informed - Access - Rectification - Erasure - Object automated_decisions_or_profiling : true The above example uses the existing demo_data_subjects.yml from the Fides project . Further details for each field are below: Label Description fides_key Ideally extended from the existing taxonomy using the dot ( . ) separator. A string token that uniquely identifies this Data Use. name A UI-friendly name that will also be surfaced as the Categories of individuals when exporting data from Fides. description An optional description of the data subject. rights A strategy of how to apply data subject rights, along with an optional list to complement the strategy. automated_decisions_or_profiling If automated decision-making or profiling exists for this data subject, set as either true or false.","title":"Implementing a custom Data Subject"},{"location":"guides/extend_taxonomy/#next-steps","text":"Once created, your new Data Subject or Data Use can be referenced as part of a privacy declaration in a system , throughout your policies , and in other Fides resources .","title":"Next Steps"},{"location":"guides/fidesops_workflow/","text":"Fidesops Privacy Request Execution When a Privacy Request is submitted, fidesops performs several prerequisite checks, and then visits your collections in two passes: first, to retrieve relevant data for the subject across all your collections, and again to mask the subject's data, if necessary. The following guide outlines the steps fidesops takes to fulfill a privacy request from end to end, including optional configurations and manual data retrieval. Privacy request submission Prior to processing a privacy request, fidesops first creates records to store the relevant information, and can perform a number of other actions based on your configuration: Step Description Persist Fidesops creates a privacy request in long-term storage to capture high-level information (e.g. date created, current status). Fidesops saves the identity of the subject to both short- and long-term storage. Verify If configured, Fidesops sends an email to the user to verify their identity before proceeding. Notify If configured, the user will receive an email verifying that their request has been received. Approve If configured, Fidesops will require a system administrator to approve the request before proceeding. Privacy request execution Once the required submission steps have been completed, the request status is updated to in_processing status, and the privacy request is dispatched to a separate queue for processing. Request execution involves gathering data from multiple sources, and/or masking data in multiple locations. Fidesops will follow the steps below in order, skipping any that are not applicable for the given request: Respond to manual webhooks Run policy pre-execution webhooks Access request automation Upload results Erasure request automation Send erasure request emails Run policy post-execution webhooks Send email notifications Respond to manual webhooks Manual webhooks allow data pertaining a subject to be manually uploaded by a fidesops admin. If manual webhooks are enabled, request execution will exit with a status of requires_input until a submission has been received for each manual webhook configured. The privacy request can then be resumed, and request execution will continue from this step. See Manual Webhooks for more information on configuration options and resuming a requires_input request. Data uploaded for manual webhooks will be returned to the data subject directly at the end of request execution. Data gathered here is not used to locate data from other sources. Run pre-execution webhooks Policy pre-execution webhooks let your system take care of prerequisite tasks, or locate additional identities for the data subject. Examples include turning on a specific database in your infrastructure, or locating a phone number for a subject from a table for which you do not want to give Fidesops direct access. Configuration involves defining endpoint(s) for fidesops to call in order. See Policy Webhooks for more details. Fidesops sends a request to each pre-execution webhook with a policy webhooks request format , which your endpoints should be prepared to unpack. If you need more time to carry out an action, your webhook can instruct fidesops to halt , which will cause execution to exit with a status of paused . Request execution can be continued when ready using a token supplied in the original request. No data uploaded by policy webhooks is returned to the data subject, but identities discovered can be used to later locate data pertaining to the subject during access request automation. If a request to a pre-execution webhook fails, request execution will exit with a status of error . Retrying the privacy request will resume from this step and attempt to re-run all pre-execution webhooks. Access request automation Access request automation is performed regardless of whether there are access or erasure Rules defined, as both Rules require this data. See how to configure policies, rules, and rule targets for additional information. This step visits all Collections and retrieves all Fields that you've defined in your Datasets . Fidesops builds a graph in accordance with how you've designated your Collections are related, visits each Collection in turn, and gathers all the results together. Graph building Fidesops builds a Directed Acyclic Graph, or DAG, where each location or node corresponds to a Collection in one of your Datasets. The graph helps determine the order in which nodes will be visited. Fidesops begins with any Collections that can be queried using the supplied identity data, and then points those Collections toward dependent Collections, etc. If fidesops can't determine how to reach a Collection, it will exit early with a status of error . To remedy an errored access request, you update how your Collections are related to each other in your Datasets, and resubmit the privacy request. Graph Execution After the graph is built, Fidesops passes the result to Dask to execute sequentially. Fidesops visits one Collection at a time, following the graph created, and uses Dask to determine ordering for ties. For the first Collections in the graph connected to the root, Fidesops uses the customers' provided identity to locate subject data, by either making database queries or HTTP requests to a configured API endpoint. The details on how to access your data are determined by the Connection type. Fidesops retrieves all Fields that have been configured on the Collection, and caches the results in temporary storage for usage later. Fidesops then passes the results of that Collection to downstream Collections that similarly make queries, temporarily cache the results, and return their results to their own downstream Collections. A Collection isn't visited until Fidesops has searched for data across all of its upstream Collections. This continues until all Collections have been visited. See Query Execution for more information. If there is a failure trying to retrieve data on any Collections, the request is retried the number of times configured by task_retry_count until the request exits with status error . Both the access step and errored Collection are cached in temporary storage. Restarting the privacy request will restart from this step and failed Collection. Collections that have already been visited will not be visited again. Final result retrieval The final step of an automated access request gathers all the results for each Collection from temporary storage. Upload results If configured, Fidesops uploads the results retrieved from access automation for the data subject. For each configured access Rule, Fidesops filter the graph results to match targeted Data Categories. See Datasets for more details. Fidesops also supplements the results with any data manually uploaded from manual webhooks . Each data package is uploaded in JSON or CSV format to a specified storage location like Amazon S3. See Storage for more information. Erasure request automation If applicable, (erasure Rules are configured on your execution policy), Fidesops builds a simpler version of the access request graph, and visits each Collection in turn, performing masking requests as necessary. Graph building The \"graph\" for an erasure runs on the data from the access request, which is kept in temporary storage, and can be used to locate data for each Collection individually. Because the data has already been found, each Collection could be visited in any order or run in parallel. The graph is configured so each Collection has its previous access request results passed in as inputs, and each Collection returns a count of records masked when complete. Graph execution Fidesops visits each Collection sequentially, using a deterministic order set by Dask. For each row of data retrieved in the access request step, Fidesops attempts to mask the data targeting the fields specified on your execution policy, using the masking strategies you've defined. If no rows exist from the access request, or no Fields on that Collection match the targeted Data Categories, no masking occurs. Fidesops caches a count of the records that had fields masked in temporary storage. The masking request might involve an update database query or an update or delete HTTP request depending on the Connection Type . The Email Connector type doesn't mask any data itself, but instead persists how to locate and mask that Collection in temporary storage for use later. If masking fails on a given Collection, Fidesops retries the requests for a configured number of times, and then request execution will exit with a status of error . Fidesops will cache both the failed Collection and that the failure occurred on the erasure step. Retrying the privacy request will resume from the erasure step at the failed Collection. Previously masked Collections will not be masked again. Send erasure request emails After the access and erasure steps have both executed, Fidesops checks if there are any third parties that need to be additionally emailed to complete erasure requests on your behalf. See emailing third party services to mask data for more information. Fidesops retrieves any masking instructions cached by Email Connectors in the erasure request step, and combines them into a single email per Dataset. This step is only performed if you have Email Connectors configured. If the email send fails for any reason, the request will exit with status error . Fidesops will cache this step in temporary storage, so retrying the request will resume from this point. Run policy post-execution webhooks After automated access and erasures have completed, post-execution webhooks can be used to perform any cleanup steps in your system. Examples include setting up a webhook to shut down a database, or to delete user data from a source you don't want Fidesops to access directly. Post-execution webhooks are more limited than Pre-execution webhooks. They currently cannot pause the graph, and should be configured as a series of API endpoints you would like Fidesops to call. See policy webhooks for more details on configuration. If a request to a post-execution webhook fails, request execution will exit with a status of error . Retrying the privacy request will resume from this step and attempt to re-run all the post-execution webhooks. Send email notifications If configured, Fidesops will send a followup email to the data subject to let them know their request has finished processing. For access Rules, the emails will contain links to where the data subject can retrieve data. For erasure Rules, the emails will simplify notify them that their request is complete. Request execution will then exit with the status complete . Additional notes Fidesops uses Redis as temporary storage to support executing your request. Data automatically retrieved from each Collection, manually uploaded data, and details about where the Privacy Request may be paused or where it failed may all be temporarily stored. This information will expire in accordance with the FIDESOPS__REDIS__DEFAULT_TTL_SECONDS setting . The current fidesops execution strategy prioritizes being able to erase as many of the original Collections requested as possible. If Fidesops masks some Collections and then registers a failure, the current logic will mask the original remaining Collections using the temporarily saved data retrieved in the original access step instead of re-querying the Collections. Once data is masked in one Collection, it could potentially prevent us from being able to locate data in downstream Collections, and so will use temporarily stored data. Data added in the interim, or data related to newly added Collections, can be missed. If the automated access step fails part of the way through, a new Collection is added, and then the request is restarted from failure, Fidesops may miss data from already completed Collections downstream, and any Collections further downstream of that set. If the erasure step fails, a new Collection is added, and the request is restarted from failure, Fidesops may miss masking data from the new Collection and data downstream of the new Collection. Nodes on the graph correspond to individual Collections within Datasets, not Datasets. The graph built may result in Fidesops visiting a Collection in one Dataset to be able to find data on a Collection in a separate Dataset, which is used to find data on a Collection in the original Dataset. Automated access requests often select more Fields than may be returned specifically to the user because this data has multiple uses. Fidesops selects all Fields defined to be able to potentially query downstream Collections, filter data according to multiple access Rules, and mask data in accordance with multiple erasure Rules.","title":"Understanding Privacy Request Execution"},{"location":"guides/fidesops_workflow/#fidesops-privacy-request-execution","text":"When a Privacy Request is submitted, fidesops performs several prerequisite checks, and then visits your collections in two passes: first, to retrieve relevant data for the subject across all your collections, and again to mask the subject's data, if necessary. The following guide outlines the steps fidesops takes to fulfill a privacy request from end to end, including optional configurations and manual data retrieval.","title":"Fidesops Privacy Request Execution"},{"location":"guides/fidesops_workflow/#privacy-request-submission","text":"Prior to processing a privacy request, fidesops first creates records to store the relevant information, and can perform a number of other actions based on your configuration: Step Description Persist Fidesops creates a privacy request in long-term storage to capture high-level information (e.g. date created, current status). Fidesops saves the identity of the subject to both short- and long-term storage. Verify If configured, Fidesops sends an email to the user to verify their identity before proceeding. Notify If configured, the user will receive an email verifying that their request has been received. Approve If configured, Fidesops will require a system administrator to approve the request before proceeding.","title":"Privacy request submission"},{"location":"guides/fidesops_workflow/#privacy-request-execution","text":"Once the required submission steps have been completed, the request status is updated to in_processing status, and the privacy request is dispatched to a separate queue for processing. Request execution involves gathering data from multiple sources, and/or masking data in multiple locations. Fidesops will follow the steps below in order, skipping any that are not applicable for the given request: Respond to manual webhooks Run policy pre-execution webhooks Access request automation Upload results Erasure request automation Send erasure request emails Run policy post-execution webhooks Send email notifications","title":"Privacy request execution"},{"location":"guides/fidesops_workflow/#respond-to-manual-webhooks","text":"Manual webhooks allow data pertaining a subject to be manually uploaded by a fidesops admin. If manual webhooks are enabled, request execution will exit with a status of requires_input until a submission has been received for each manual webhook configured. The privacy request can then be resumed, and request execution will continue from this step. See Manual Webhooks for more information on configuration options and resuming a requires_input request. Data uploaded for manual webhooks will be returned to the data subject directly at the end of request execution. Data gathered here is not used to locate data from other sources.","title":"Respond to manual webhooks"},{"location":"guides/fidesops_workflow/#run-pre-execution-webhooks","text":"Policy pre-execution webhooks let your system take care of prerequisite tasks, or locate additional identities for the data subject. Examples include turning on a specific database in your infrastructure, or locating a phone number for a subject from a table for which you do not want to give Fidesops direct access. Configuration involves defining endpoint(s) for fidesops to call in order. See Policy Webhooks for more details. Fidesops sends a request to each pre-execution webhook with a policy webhooks request format , which your endpoints should be prepared to unpack. If you need more time to carry out an action, your webhook can instruct fidesops to halt , which will cause execution to exit with a status of paused . Request execution can be continued when ready using a token supplied in the original request. No data uploaded by policy webhooks is returned to the data subject, but identities discovered can be used to later locate data pertaining to the subject during access request automation. If a request to a pre-execution webhook fails, request execution will exit with a status of error . Retrying the privacy request will resume from this step and attempt to re-run all pre-execution webhooks.","title":"Run pre-execution webhooks"},{"location":"guides/fidesops_workflow/#access-request-automation","text":"Access request automation is performed regardless of whether there are access or erasure Rules defined, as both Rules require this data. See how to configure policies, rules, and rule targets for additional information. This step visits all Collections and retrieves all Fields that you've defined in your Datasets . Fidesops builds a graph in accordance with how you've designated your Collections are related, visits each Collection in turn, and gathers all the results together.","title":"Access request automation"},{"location":"guides/fidesops_workflow/#graph-building","text":"Fidesops builds a Directed Acyclic Graph, or DAG, where each location or node corresponds to a Collection in one of your Datasets. The graph helps determine the order in which nodes will be visited. Fidesops begins with any Collections that can be queried using the supplied identity data, and then points those Collections toward dependent Collections, etc. If fidesops can't determine how to reach a Collection, it will exit early with a status of error . To remedy an errored access request, you update how your Collections are related to each other in your Datasets, and resubmit the privacy request.","title":"Graph building"},{"location":"guides/fidesops_workflow/#graph-execution","text":"After the graph is built, Fidesops passes the result to Dask to execute sequentially. Fidesops visits one Collection at a time, following the graph created, and uses Dask to determine ordering for ties. For the first Collections in the graph connected to the root, Fidesops uses the customers' provided identity to locate subject data, by either making database queries or HTTP requests to a configured API endpoint. The details on how to access your data are determined by the Connection type. Fidesops retrieves all Fields that have been configured on the Collection, and caches the results in temporary storage for usage later. Fidesops then passes the results of that Collection to downstream Collections that similarly make queries, temporarily cache the results, and return their results to their own downstream Collections. A Collection isn't visited until Fidesops has searched for data across all of its upstream Collections. This continues until all Collections have been visited. See Query Execution for more information. If there is a failure trying to retrieve data on any Collections, the request is retried the number of times configured by task_retry_count until the request exits with status error . Both the access step and errored Collection are cached in temporary storage. Restarting the privacy request will restart from this step and failed Collection. Collections that have already been visited will not be visited again.","title":"Graph Execution"},{"location":"guides/fidesops_workflow/#final-result-retrieval","text":"The final step of an automated access request gathers all the results for each Collection from temporary storage.","title":"Final result retrieval"},{"location":"guides/fidesops_workflow/#upload-results","text":"If configured, Fidesops uploads the results retrieved from access automation for the data subject. For each configured access Rule, Fidesops filter the graph results to match targeted Data Categories. See Datasets for more details. Fidesops also supplements the results with any data manually uploaded from manual webhooks . Each data package is uploaded in JSON or CSV format to a specified storage location like Amazon S3. See Storage for more information.","title":"Upload results"},{"location":"guides/fidesops_workflow/#erasure-request-automation","text":"If applicable, (erasure Rules are configured on your execution policy), Fidesops builds a simpler version of the access request graph, and visits each Collection in turn, performing masking requests as necessary.","title":"Erasure request automation"},{"location":"guides/fidesops_workflow/#graph-building_1","text":"The \"graph\" for an erasure runs on the data from the access request, which is kept in temporary storage, and can be used to locate data for each Collection individually. Because the data has already been found, each Collection could be visited in any order or run in parallel. The graph is configured so each Collection has its previous access request results passed in as inputs, and each Collection returns a count of records masked when complete.","title":"Graph building"},{"location":"guides/fidesops_workflow/#graph-execution_1","text":"Fidesops visits each Collection sequentially, using a deterministic order set by Dask. For each row of data retrieved in the access request step, Fidesops attempts to mask the data targeting the fields specified on your execution policy, using the masking strategies you've defined. If no rows exist from the access request, or no Fields on that Collection match the targeted Data Categories, no masking occurs. Fidesops caches a count of the records that had fields masked in temporary storage. The masking request might involve an update database query or an update or delete HTTP request depending on the Connection Type . The Email Connector type doesn't mask any data itself, but instead persists how to locate and mask that Collection in temporary storage for use later. If masking fails on a given Collection, Fidesops retries the requests for a configured number of times, and then request execution will exit with a status of error . Fidesops will cache both the failed Collection and that the failure occurred on the erasure step. Retrying the privacy request will resume from the erasure step at the failed Collection. Previously masked Collections will not be masked again.","title":"Graph execution"},{"location":"guides/fidesops_workflow/#send-erasure-request-emails","text":"After the access and erasure steps have both executed, Fidesops checks if there are any third parties that need to be additionally emailed to complete erasure requests on your behalf. See emailing third party services to mask data for more information. Fidesops retrieves any masking instructions cached by Email Connectors in the erasure request step, and combines them into a single email per Dataset. This step is only performed if you have Email Connectors configured. If the email send fails for any reason, the request will exit with status error . Fidesops will cache this step in temporary storage, so retrying the request will resume from this point.","title":"Send erasure request emails"},{"location":"guides/fidesops_workflow/#run-policy-post-execution-webhooks","text":"After automated access and erasures have completed, post-execution webhooks can be used to perform any cleanup steps in your system. Examples include setting up a webhook to shut down a database, or to delete user data from a source you don't want Fidesops to access directly. Post-execution webhooks are more limited than Pre-execution webhooks. They currently cannot pause the graph, and should be configured as a series of API endpoints you would like Fidesops to call. See policy webhooks for more details on configuration. If a request to a post-execution webhook fails, request execution will exit with a status of error . Retrying the privacy request will resume from this step and attempt to re-run all the post-execution webhooks.","title":"Run policy post-execution webhooks"},{"location":"guides/fidesops_workflow/#send-email-notifications","text":"If configured, Fidesops will send a followup email to the data subject to let them know their request has finished processing. For access Rules, the emails will contain links to where the data subject can retrieve data. For erasure Rules, the emails will simplify notify them that their request is complete. Request execution will then exit with the status complete .","title":"Send email notifications"},{"location":"guides/fidesops_workflow/#additional-notes","text":"Fidesops uses Redis as temporary storage to support executing your request. Data automatically retrieved from each Collection, manually uploaded data, and details about where the Privacy Request may be paused or where it failed may all be temporarily stored. This information will expire in accordance with the FIDESOPS__REDIS__DEFAULT_TTL_SECONDS setting . The current fidesops execution strategy prioritizes being able to erase as many of the original Collections requested as possible. If Fidesops masks some Collections and then registers a failure, the current logic will mask the original remaining Collections using the temporarily saved data retrieved in the original access step instead of re-querying the Collections. Once data is masked in one Collection, it could potentially prevent us from being able to locate data in downstream Collections, and so will use temporarily stored data. Data added in the interim, or data related to newly added Collections, can be missed. If the automated access step fails part of the way through, a new Collection is added, and then the request is restarted from failure, Fidesops may miss data from already completed Collections downstream, and any Collections further downstream of that set. If the erasure step fails, a new Collection is added, and the request is restarted from failure, Fidesops may miss masking data from the new Collection and data downstream of the new Collection. Nodes on the graph correspond to individual Collections within Datasets, not Datasets. The graph built may result in Fidesops visiting a Collection in one Dataset to be able to find data on a Collection in a separate Dataset, which is used to find data on a Collection in the original Dataset. Automated access requests often select more Fields than may be returned specifically to the user because this data has multiple uses. Fidesops selects all Fields defined to be able to potentially query downstream Collections, filter data according to multiple access Rules, and mask data in accordance with multiple erasure Rules.","title":"Additional notes"},{"location":"guides/generate_datamaps/","text":"Generating a Data Map Fides is capable of exporting a data map of your resources to generate an Article 30-compliant Record of Processing Activities (RoPA). This guide will walk through generating a mock RoPA using predefined resources included in the Fides repository . To follow along, ensure you have the Fides repository cloned and Fides installed. Export the Demo Resources First, ensure fides is running with nox -s dev . To push and export the provided demo_resources , run the following commands: Push and Export Defaults 1 2 fides push demo_resources/ fides export datamap --output-dir demo_resources/ This will export a data map to the demo_resources/ directory. Organization The header block at the top of a data map is composed of properties found in the Organization resource . In a production deployment, this would be composed of publicly available information for your company/organization, but has been pre-populated here to allow exploration. The newly-generated data map is a direct result of the provided Organization resource manifest ( demo_resources/demo_organization.yml ): demo_organization.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 organization : - fides_key : default_organization name : Demo Organization description : An e-commerce organization security_policy : https://ethyca.com/privacy-policy/ controller : name : Con Troller address : 123 demo street, New York, NY, USA email : controller@demo_company.com phone : +1 555 555 5555 data_protection_officer : name : DataPro Tection address : 123 demo street, New York, NY, USA email : dpo@demo_company.com phone : +1 555 555 5555 representative : name : Rep Resentative address : 123 demo street, New York, NY, USA email : representative@demo_company.com phone : +1 555 555 5555 Each of controller , data_protection_officer , and representative are composed of Contact Detail properties populated in the exported data map. Additionally, the link to the security policy of an organization can be populated from the Organization resource's security_policy field. Dataset The Dataset is primarily used to provide a list of Data Categories which populate the data map. Additional properties can optionally be applied for retention and third_country_transfers . The newly-generated data map is a direct result of the provided Dataset resource manifest ( demo_resources/demo_dataset.yml ): demo_dataset.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 dataset : - fides_key : demo_users_dataset organization_fides_key : default_organization name : Demo Users Dataset description : Data collected about users for our analytics system. meta : null data_categories : [] data_qualifiers : - aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified retention : \"30 days after account deletion\" third_country_transfers : - GBR - CAN collections : - name : users description : User information data_categories : [] data_qualifiers : - aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : created_at description : User's creation timestamp data_categories : - system.operations data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified ... data_categories and retention can be set at any/all of the Dataset, DatasetCollection, and DatasetField levels. third_country_transfers should be set at the dataset level. Any Datasets referenced by a System will have this information included as rows of your data map. System The System contains the remainder of the attributes on the initial data map. Each populated property is referenced directly from an associated label in fides_resources/demo_system.yml : Data Map Label Resource Label Description Fides Dataset dataset_references Used to join dataset(s) to the system. Fides System name The name defined at the top level of the system. Department or Business Function administering_department Set at the top level of the system. Purpose of Processing data_use The data_use defined in the privacy_declaration . Categories of Individuals data_subject A data_subject list defined in the privacy_declaration . Categories of Personal Data data_categories Any data_categories set as part of the privacy_declaration (see the output for Demo Marketing System as a clear example). Role or Responsibility data_responsibility_title Set at the top level of the system. Source of the Personal Data dataset_references The Fides dataset name, if referenced by the system. Data Protection Impact Assessment data_protection_impact_assessment All the information related to a Data Protection Impact Assessment, set at the top level of the system. Extend the Default Taxonomy In your initial export, several data map columns are populated with N/A . The default Fides Taxonomy can be extended to replace these empty values with additional data required as part of a Record of Processing Activities. Example manifest updates are included in demo_resources/demo_extended_taxonomy.yml . Auditing Resources Your Organization and System datasets can also be assessed using the --audit flag as part of the evaluate command, which will identify how your resources could be extended to generate a compliant data map. fides evaluate demo_resources/ --audit The output of this command will highlight any missing information: Example Output: fides audit 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ... \"Auditing Organization Resource Compliance\" Found 1 Organization resource ( s ) to audit... Auditing Organization: Demo Organization controller for default_organization in Demo Organization is compliant data_protection_officer for default_organization in Demo Organization is compliant representative for default_organization in Demo Organization is compliant security_policy for default_organization in Demo Organization is compliant All audited organization resource ( s ) compliant! ---------- \"Auditing System Resource Compliance\" Found 2 System resource ( s ) to audit... \"Auditing System: Demo Analytics System\" improve.system missing recipients in Demo Analytics System. improve.system missing legal_basis in Demo Analytics System. improve.system missing special_category in Demo Analytics System. customer missing rights in Demo Analytics System. customer missing automated_decisions_or_profiling in Demo Analytics System. \"Auditing System: Demo Marketing System\" advertising missing recipients in Demo Marketing System. advertising missing legal_basis in Demo Marketing System. advertising missing special_category in Demo Marketing System. customer missing rights in Demo Marketing System. customer missing automated_decisions_or_profiling in Demo Marketing System. 10 issue ( s ) were detected in auditing system completeness. Data Use Below is an extended Data Use example. Each of these properties is responsible for populating a field on your data map. Extended Data Use 1 2 3 4 5 6 7 8 9 10 data_use : - fides_key : third_party_sharing.personalized_advertising.direct_marketing name : Direct Marketing description : User information for direct marketing purposes recipients : - Processor - marketing co. legal_basis : Legitimate Interests special_category : Vital Interests legitimate_interest_impact_assessment : https://example.org/legitimate_interest_assessment parent_key : third_party_sharing.personalized_advertising Apply this data_subject by adding it to the Demo Marketing System in demo_system.yml . Replace the Demo Marketing System's Data Use of advertising with the above fides_key of third_party_sharing.personalized_advertising.direct_marketing to include its information in your data map. Data Subject A Data Subject , shown below, can also be extended to populate your data map with additional information. Extended Data Subject 1 2 3 4 5 6 7 8 9 10 11 12 13 data_subject : - fides_key : potential_customer name : Potential Customer description : A prospective individual or other organization that purchases goods or services from the organization. rights : strategy : INCLUDE values : - Informed - Access - Rectification - Erasure - Object automated_decisions_or_profiling : true Apply this data_subject by adding it to the Demo Marketing System in demo_system.yml . Replace the Demo Marketing System's Data Subject of customer with the above fides_key of potential_customer to include its information in your data map. Testing Your Changes Your resulting demo_system.yml should look like the following: demo_system.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 system : - fides_key : demo_analytics_system name : Demo Analytics System description : A system used for analyzing customer behavior. system_type : Service administrating_department : Engineering data_responsibility_title : Controller third_country_transfers : - USA - CAN data_protection_impact_assessment : is_required : True progress : Complete link : https://example.org/analytics_system_data_protection_impact_assessment privacy_declarations : - name : Analyze customer behavior for improvements. data_categories : - user.provided.identifiable.contact - user.derived.identifiable.device.cookie_id data_use : improve.system data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified dataset_references : - demo_users_dataset - fides_key : demo_marketing_system name : Demo Marketing System description : Collect data about our users for marketing. system_type : Service administrating_department : Marketing data_responsibility_title : Processor privacy_declarations : - name : Collect data for marketing data_categories : #- user.provided.identifiable.contact # uncomment to add this category to the system - user.derived.identifiable.device.cookie_id data_use : third_party_sharing.personalized_advertising.direct_marketing data_subjects : - potential_customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified data_use : - fides_key : third_party_sharing.personalized_advertising.direct_marketing name : Direct Marketing description : User information for direct marketing purposes recipients : - Processor - marketing co. legal_basis : Legitimate Interests special_category : Vital Interests legitimate_interest_impact_assessment : https://example.org/legitimate_interest_assessment parent_key : third_party_sharing.personalized_advertising data_subject : - fides_key : potential_customer name : Potential Customer description : A prospective individual or other organization that purchases goods or services from the organization. rights : strategy : INCLUDE values : - Informed - Access - Rectification - Erasure - Object automated_decisions_or_profiling : true Running fides push demo_resources/ will push your changes. Now, auditing this resource with fides evaluate demo_resources --audit will show the Demo Marketing System issues are resolved: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ... \"Auditing Organization Resource Compliance\" Found 1 Organization resource ( s ) to audit... Auditing Organization: Demo Organization controller for default_organization in Demo Organization is compliant data_protection_officer for default_organization in Demo Organization is compliant representative for default_organization in Demo Organization is compliant security_policy for default_organization in Demo Organization is compliant All audited organization resource ( s ) compliant! ---------- \"Auditing System Resource Compliance\" Found 2 System resource ( s ) to audit... \"Auditing System: Demo Analytics System\" improve.system missing recipients in Demo Analytics System. improve.system missing legal_basis in Demo Analytics System. improve.system missing special_category in Demo Analytics System. customer missing rights in Demo Analytics System. customer missing automated_decisions_or_profiling in Demo Analytics System. \"Auditing System: Demo Marketing System\" recipients for third_party_sharing.personalized_advertising.direct_marketing in Demo Marketing System is compliant legal_basis for third_party_sharing.personalized_advertising.direct_marketing in Demo Marketing System is compliant special_category for third_party_sharing.personalized_advertising.direct_marketing in Demo Marketing System is compliant rights for potential_customer in Demo Marketing System is compliant automated_decisions_or_profiling for potential_customer in Demo Marketing System is compliant 5 issue ( s ) were detected in auditing system completeness. Generate a RoPA Now that you have added the additional information around privacy notices and data subject rights, you can export a fresh copy of your data map: Push and Export Defaults 1 2 $ fides push demo_resources/ $ fides export datamap --output_dir demo_resources/ Populated Fields Opening the new data map will show the previously N/A columns are now populated, resulting in an Article 30-compliant RoPA for one of the two systems defined in demo_resources/ . Below is a mapping of the newly populated columns with their respective values: Data Map Label Description Purpose of Processing The name of your newly extended data_use set in a Privacy Declaration. Categories of Individuals The name of your newly extended data_subject set in a Privacy Declaration. Categories of Recipients The recipients defined in your extended Data Use. Article 6 Lawful Basis for Processing Personal Data The legal_basis defined in your extended Data Use. Article 9 Condition for Processing Special Category Data The special_category defined in your extended Data Use. Legitimate Interests for the Processing If the legal_basis is \"Legitimate Interests\" , the Data Use name is used to identify what the legitimate interest data use is. Link to Record of Legitimate Interests Assessment If the legal_basis is \"Legitimate Interests\" , a legitimate interests impact assessment is required and should be set using the legitimate_interest_impact_assessment property. Rights Available to Individuals The rights defined in your extended Data Subject based on the strategy used. Existence of Automated Decision-Making, Including Profiling The boolean value for automated_decisions_or_profiling , defined in your extended Data Subject. Additional Learning The provided demo_system.yml includes a second System, Demo Analytics , which can be enhanced in the same way as the Demo Marketing System. Follow the guide to extend the taxonomy again, this time for the Demo Analytics System, to have both systems fully compliant.","title":"Generate Data Maps"},{"location":"guides/generate_datamaps/#generating-a-data-map","text":"Fides is capable of exporting a data map of your resources to generate an Article 30-compliant Record of Processing Activities (RoPA). This guide will walk through generating a mock RoPA using predefined resources included in the Fides repository . To follow along, ensure you have the Fides repository cloned and Fides installed.","title":"Generating a Data Map"},{"location":"guides/generate_datamaps/#export-the-demo-resources","text":"First, ensure fides is running with nox -s dev . To push and export the provided demo_resources , run the following commands: Push and Export Defaults 1 2 fides push demo_resources/ fides export datamap --output-dir demo_resources/ This will export a data map to the demo_resources/ directory.","title":"Export the Demo Resources"},{"location":"guides/generate_datamaps/#organization","text":"The header block at the top of a data map is composed of properties found in the Organization resource . In a production deployment, this would be composed of publicly available information for your company/organization, but has been pre-populated here to allow exploration. The newly-generated data map is a direct result of the provided Organization resource manifest ( demo_resources/demo_organization.yml ): demo_organization.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 organization : - fides_key : default_organization name : Demo Organization description : An e-commerce organization security_policy : https://ethyca.com/privacy-policy/ controller : name : Con Troller address : 123 demo street, New York, NY, USA email : controller@demo_company.com phone : +1 555 555 5555 data_protection_officer : name : DataPro Tection address : 123 demo street, New York, NY, USA email : dpo@demo_company.com phone : +1 555 555 5555 representative : name : Rep Resentative address : 123 demo street, New York, NY, USA email : representative@demo_company.com phone : +1 555 555 5555 Each of controller , data_protection_officer , and representative are composed of Contact Detail properties populated in the exported data map. Additionally, the link to the security policy of an organization can be populated from the Organization resource's security_policy field.","title":"Organization"},{"location":"guides/generate_datamaps/#dataset","text":"The Dataset is primarily used to provide a list of Data Categories which populate the data map. Additional properties can optionally be applied for retention and third_country_transfers . The newly-generated data map is a direct result of the provided Dataset resource manifest ( demo_resources/demo_dataset.yml ): demo_dataset.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 dataset : - fides_key : demo_users_dataset organization_fides_key : default_organization name : Demo Users Dataset description : Data collected about users for our analytics system. meta : null data_categories : [] data_qualifiers : - aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified retention : \"30 days after account deletion\" third_country_transfers : - GBR - CAN collections : - name : users description : User information data_categories : [] data_qualifiers : - aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : created_at description : User's creation timestamp data_categories : - system.operations data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified ... data_categories and retention can be set at any/all of the Dataset, DatasetCollection, and DatasetField levels. third_country_transfers should be set at the dataset level. Any Datasets referenced by a System will have this information included as rows of your data map.","title":"Dataset"},{"location":"guides/generate_datamaps/#system","text":"The System contains the remainder of the attributes on the initial data map. Each populated property is referenced directly from an associated label in fides_resources/demo_system.yml : Data Map Label Resource Label Description Fides Dataset dataset_references Used to join dataset(s) to the system. Fides System name The name defined at the top level of the system. Department or Business Function administering_department Set at the top level of the system. Purpose of Processing data_use The data_use defined in the privacy_declaration . Categories of Individuals data_subject A data_subject list defined in the privacy_declaration . Categories of Personal Data data_categories Any data_categories set as part of the privacy_declaration (see the output for Demo Marketing System as a clear example). Role or Responsibility data_responsibility_title Set at the top level of the system. Source of the Personal Data dataset_references The Fides dataset name, if referenced by the system. Data Protection Impact Assessment data_protection_impact_assessment All the information related to a Data Protection Impact Assessment, set at the top level of the system.","title":"System"},{"location":"guides/generate_datamaps/#extend-the-default-taxonomy","text":"In your initial export, several data map columns are populated with N/A . The default Fides Taxonomy can be extended to replace these empty values with additional data required as part of a Record of Processing Activities. Example manifest updates are included in demo_resources/demo_extended_taxonomy.yml .","title":"Extend the Default Taxonomy"},{"location":"guides/generate_datamaps/#auditing-resources","text":"Your Organization and System datasets can also be assessed using the --audit flag as part of the evaluate command, which will identify how your resources could be extended to generate a compliant data map. fides evaluate demo_resources/ --audit The output of this command will highlight any missing information: Example Output: fides audit 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ... \"Auditing Organization Resource Compliance\" Found 1 Organization resource ( s ) to audit... Auditing Organization: Demo Organization controller for default_organization in Demo Organization is compliant data_protection_officer for default_organization in Demo Organization is compliant representative for default_organization in Demo Organization is compliant security_policy for default_organization in Demo Organization is compliant All audited organization resource ( s ) compliant! ---------- \"Auditing System Resource Compliance\" Found 2 System resource ( s ) to audit... \"Auditing System: Demo Analytics System\" improve.system missing recipients in Demo Analytics System. improve.system missing legal_basis in Demo Analytics System. improve.system missing special_category in Demo Analytics System. customer missing rights in Demo Analytics System. customer missing automated_decisions_or_profiling in Demo Analytics System. \"Auditing System: Demo Marketing System\" advertising missing recipients in Demo Marketing System. advertising missing legal_basis in Demo Marketing System. advertising missing special_category in Demo Marketing System. customer missing rights in Demo Marketing System. customer missing automated_decisions_or_profiling in Demo Marketing System. 10 issue ( s ) were detected in auditing system completeness.","title":"Auditing Resources"},{"location":"guides/generate_datamaps/#data-use","text":"Below is an extended Data Use example. Each of these properties is responsible for populating a field on your data map. Extended Data Use 1 2 3 4 5 6 7 8 9 10 data_use : - fides_key : third_party_sharing.personalized_advertising.direct_marketing name : Direct Marketing description : User information for direct marketing purposes recipients : - Processor - marketing co. legal_basis : Legitimate Interests special_category : Vital Interests legitimate_interest_impact_assessment : https://example.org/legitimate_interest_assessment parent_key : third_party_sharing.personalized_advertising Apply this data_subject by adding it to the Demo Marketing System in demo_system.yml . Replace the Demo Marketing System's Data Use of advertising with the above fides_key of third_party_sharing.personalized_advertising.direct_marketing to include its information in your data map.","title":"Data Use"},{"location":"guides/generate_datamaps/#data-subject","text":"A Data Subject , shown below, can also be extended to populate your data map with additional information. Extended Data Subject 1 2 3 4 5 6 7 8 9 10 11 12 13 data_subject : - fides_key : potential_customer name : Potential Customer description : A prospective individual or other organization that purchases goods or services from the organization. rights : strategy : INCLUDE values : - Informed - Access - Rectification - Erasure - Object automated_decisions_or_profiling : true Apply this data_subject by adding it to the Demo Marketing System in demo_system.yml . Replace the Demo Marketing System's Data Subject of customer with the above fides_key of potential_customer to include its information in your data map.","title":"Data Subject"},{"location":"guides/generate_datamaps/#testing-your-changes","text":"Your resulting demo_system.yml should look like the following: demo_system.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 system : - fides_key : demo_analytics_system name : Demo Analytics System description : A system used for analyzing customer behavior. system_type : Service administrating_department : Engineering data_responsibility_title : Controller third_country_transfers : - USA - CAN data_protection_impact_assessment : is_required : True progress : Complete link : https://example.org/analytics_system_data_protection_impact_assessment privacy_declarations : - name : Analyze customer behavior for improvements. data_categories : - user.provided.identifiable.contact - user.derived.identifiable.device.cookie_id data_use : improve.system data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified dataset_references : - demo_users_dataset - fides_key : demo_marketing_system name : Demo Marketing System description : Collect data about our users for marketing. system_type : Service administrating_department : Marketing data_responsibility_title : Processor privacy_declarations : - name : Collect data for marketing data_categories : #- user.provided.identifiable.contact # uncomment to add this category to the system - user.derived.identifiable.device.cookie_id data_use : third_party_sharing.personalized_advertising.direct_marketing data_subjects : - potential_customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified data_use : - fides_key : third_party_sharing.personalized_advertising.direct_marketing name : Direct Marketing description : User information for direct marketing purposes recipients : - Processor - marketing co. legal_basis : Legitimate Interests special_category : Vital Interests legitimate_interest_impact_assessment : https://example.org/legitimate_interest_assessment parent_key : third_party_sharing.personalized_advertising data_subject : - fides_key : potential_customer name : Potential Customer description : A prospective individual or other organization that purchases goods or services from the organization. rights : strategy : INCLUDE values : - Informed - Access - Rectification - Erasure - Object automated_decisions_or_profiling : true Running fides push demo_resources/ will push your changes. Now, auditing this resource with fides evaluate demo_resources --audit will show the Demo Marketing System issues are resolved: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ... \"Auditing Organization Resource Compliance\" Found 1 Organization resource ( s ) to audit... Auditing Organization: Demo Organization controller for default_organization in Demo Organization is compliant data_protection_officer for default_organization in Demo Organization is compliant representative for default_organization in Demo Organization is compliant security_policy for default_organization in Demo Organization is compliant All audited organization resource ( s ) compliant! ---------- \"Auditing System Resource Compliance\" Found 2 System resource ( s ) to audit... \"Auditing System: Demo Analytics System\" improve.system missing recipients in Demo Analytics System. improve.system missing legal_basis in Demo Analytics System. improve.system missing special_category in Demo Analytics System. customer missing rights in Demo Analytics System. customer missing automated_decisions_or_profiling in Demo Analytics System. \"Auditing System: Demo Marketing System\" recipients for third_party_sharing.personalized_advertising.direct_marketing in Demo Marketing System is compliant legal_basis for third_party_sharing.personalized_advertising.direct_marketing in Demo Marketing System is compliant special_category for third_party_sharing.personalized_advertising.direct_marketing in Demo Marketing System is compliant rights for potential_customer in Demo Marketing System is compliant automated_decisions_or_profiling for potential_customer in Demo Marketing System is compliant 5 issue ( s ) were detected in auditing system completeness.","title":"Testing Your Changes"},{"location":"guides/generate_datamaps/#generate-a-ropa","text":"Now that you have added the additional information around privacy notices and data subject rights, you can export a fresh copy of your data map: Push and Export Defaults 1 2 $ fides push demo_resources/ $ fides export datamap --output_dir demo_resources/","title":"Generate a RoPA"},{"location":"guides/generate_datamaps/#populated-fields","text":"Opening the new data map will show the previously N/A columns are now populated, resulting in an Article 30-compliant RoPA for one of the two systems defined in demo_resources/ . Below is a mapping of the newly populated columns with their respective values: Data Map Label Description Purpose of Processing The name of your newly extended data_use set in a Privacy Declaration. Categories of Individuals The name of your newly extended data_subject set in a Privacy Declaration. Categories of Recipients The recipients defined in your extended Data Use. Article 6 Lawful Basis for Processing Personal Data The legal_basis defined in your extended Data Use. Article 9 Condition for Processing Special Category Data The special_category defined in your extended Data Use. Legitimate Interests for the Processing If the legal_basis is \"Legitimate Interests\" , the Data Use name is used to identify what the legitimate interest data use is. Link to Record of Legitimate Interests Assessment If the legal_basis is \"Legitimate Interests\" , a legitimate interests impact assessment is required and should be set using the legitimate_interest_impact_assessment property. Rights Available to Individuals The rights defined in your extended Data Subject based on the strategy used. Existence of Automated Decision-Making, Including Profiling The boolean value for automated_decisions_or_profiling , defined in your extended Data Subject.","title":"Populated Fields"},{"location":"guides/generate_datamaps/#additional-learning","text":"The provided demo_system.yml includes a second System, Demo Analytics , which can be enhanced in the same way as the Demo Marketing System. Follow the guide to extend the taxonomy again, this time for the Demo Analytics System, to have both systems fully compliant.","title":"Additional Learning"},{"location":"guides/manual_webhooks/","text":"Manual Webhooks Manual webhooks are a simple way for data to be manually uploaded for an access request. Erasure requests are not supported at this time. They differ from the more complex manual connection configs that integrate directly with the graph. Manual webhooks gather data outside of the graph as a first step, and are more similar to policy_webhooks . If you have manual webhooks defined, privacy request execution will exit early and remain in a state of requires_input . Once data has been manually uploaded for all the manual webhooks, then the privacy request can be resumed. Data uploaded for manual webhooks is passed on directly to the data subject alongside the data package. It is not filtered on data category. Any manual data uploaded is passed on as-is. Configuration Create a connection config of type manual_webhook POST api/v1/connection 1 2 3 4 5 6 7 [ { \"name\" : \"Manual Webhook ConnectionConfig\" , \"key\" : \"manual_webhook_key\" , \"connection_type\" : \"manual_webhook\" , \"access\" : \"read\" } ] Field Description key Optional. A unique key used to manage your connection config. This is auto-generated from name if left blank. Accepted values are alphanumeric, _ , and . . name A unique user-friendly name for your connection config. This key will also be used to identity the manual webhook connection_type Should be manual_webhook for the resource described here. access One of read or write Define the fields expected for your manual_webhook Submit a list of fields that will need to be manually uploaded. PATCH api/v1/connection/{{manual_webhook_key}}/access_manual_webhook 1 2 3 4 5 6 7 8 { \"fields\" : [ { \"pii_field\" : \"First Name\" , \"dsr_package_label\" : \"first_name\" }, { \"pii_field\" : \"Last Name\" , \"dsr_package_label\" : \"last_name\" }, { \"pii_field\" : \"Phone Number\" , \"dsr_package_label\" : null }, { \"pii_field\" : \"Height\" , \"dsr_package_label\" : \"height\" } ] } Field Description fields Required. A list of field mappings with pii_field and dsr_package_label keys. The pii_field is the label fidesops will display when it solicits manual input, and the dsr_package_label is the identifier fidesops will use when it uploads the data to the data subject. If no dsr_package_label is supplied, it will be created from the pii_field . Upload manual webhook data for a given privacy request Privacy request execution will exit early with a status of requires_input if we're missing data for manual_webhooks . A request will need to be made for each manual_webhook to upload the requested data before request execution can proceed. Note that the fields here are dynamic and should match the fields specified on the manual webhook. All fields are optional. If no data exists, an empty dictionary should be uploaded. Fidesops treats this upload as confirmation that the system was searched for data related to the data subject. PATCH /privacy-request/{{privacy_request_id}}/access_manual_webhook/{{manual_webhook_key}} 1 2 3 4 { \"first_name\" : \"Jane\" , \"last_name\" : \"Customer\" } Resume Privacy Request Execution Once a PrivacyRequest with requires_input has had all of its manual data uploaded, prompt the privacy request to resume. POST /privacy-request/{{privacy_request_id}}/resume_from_requires_input 1 Example Upload In this example, we visited one postgres collection automatically and retrieved Jane's name , email , and id . Her first_name and last_name were manually uploaded as part of the manual_webhook_key Manual Webhook and directly included here. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"postgres_example:customer\" : [ { \"name\" : \"Jane Customer\" , \"email\" : \"customer-3@example.com\" , \"id\" : 1 } ], \"manual_webhook_key\" : [ { \"first_name\" : \"Jane\" , \"last_name\" : \"Customer\" } ] }","title":"Configure Manual Webhooks"},{"location":"guides/manual_webhooks/#manual-webhooks","text":"Manual webhooks are a simple way for data to be manually uploaded for an access request. Erasure requests are not supported at this time. They differ from the more complex manual connection configs that integrate directly with the graph. Manual webhooks gather data outside of the graph as a first step, and are more similar to policy_webhooks . If you have manual webhooks defined, privacy request execution will exit early and remain in a state of requires_input . Once data has been manually uploaded for all the manual webhooks, then the privacy request can be resumed. Data uploaded for manual webhooks is passed on directly to the data subject alongside the data package. It is not filtered on data category. Any manual data uploaded is passed on as-is.","title":"Manual Webhooks"},{"location":"guides/manual_webhooks/#configuration","text":"","title":"Configuration"},{"location":"guides/manual_webhooks/#create-a-connection-config-of-type-manual_webhook","text":"POST api/v1/connection 1 2 3 4 5 6 7 [ { \"name\" : \"Manual Webhook ConnectionConfig\" , \"key\" : \"manual_webhook_key\" , \"connection_type\" : \"manual_webhook\" , \"access\" : \"read\" } ] Field Description key Optional. A unique key used to manage your connection config. This is auto-generated from name if left blank. Accepted values are alphanumeric, _ , and . . name A unique user-friendly name for your connection config. This key will also be used to identity the manual webhook connection_type Should be manual_webhook for the resource described here. access One of read or write","title":"Create a connection config of type manual_webhook"},{"location":"guides/manual_webhooks/#define-the-fields-expected-for-your-manual_webhook","text":"Submit a list of fields that will need to be manually uploaded. PATCH api/v1/connection/{{manual_webhook_key}}/access_manual_webhook 1 2 3 4 5 6 7 8 { \"fields\" : [ { \"pii_field\" : \"First Name\" , \"dsr_package_label\" : \"first_name\" }, { \"pii_field\" : \"Last Name\" , \"dsr_package_label\" : \"last_name\" }, { \"pii_field\" : \"Phone Number\" , \"dsr_package_label\" : null }, { \"pii_field\" : \"Height\" , \"dsr_package_label\" : \"height\" } ] } Field Description fields Required. A list of field mappings with pii_field and dsr_package_label keys. The pii_field is the label fidesops will display when it solicits manual input, and the dsr_package_label is the identifier fidesops will use when it uploads the data to the data subject. If no dsr_package_label is supplied, it will be created from the pii_field .","title":"Define the fields expected for your manual_webhook"},{"location":"guides/manual_webhooks/#upload-manual-webhook-data-for-a-given-privacy-request","text":"Privacy request execution will exit early with a status of requires_input if we're missing data for manual_webhooks . A request will need to be made for each manual_webhook to upload the requested data before request execution can proceed. Note that the fields here are dynamic and should match the fields specified on the manual webhook. All fields are optional. If no data exists, an empty dictionary should be uploaded. Fidesops treats this upload as confirmation that the system was searched for data related to the data subject. PATCH /privacy-request/{{privacy_request_id}}/access_manual_webhook/{{manual_webhook_key}} 1 2 3 4 { \"first_name\" : \"Jane\" , \"last_name\" : \"Customer\" }","title":"Upload manual webhook data for a given privacy request"},{"location":"guides/manual_webhooks/#resume-privacy-request-execution","text":"Once a PrivacyRequest with requires_input has had all of its manual data uploaded, prompt the privacy request to resume. POST /privacy-request/{{privacy_request_id}}/resume_from_requires_input 1","title":"Resume Privacy Request Execution"},{"location":"guides/manual_webhooks/#example-upload","text":"In this example, we visited one postgres collection automatically and retrieved Jane's name , email , and id . Her first_name and last_name were manually uploaded as part of the manual_webhook_key Manual Webhook and directly included here. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"postgres_example:customer\" : [ { \"name\" : \"Jane Customer\" , \"email\" : \"customer-3@example.com\" , \"id\" : 1 } ], \"manual_webhook_key\" : [ { \"first_name\" : \"Jane\" , \"last_name\" : \"Customer\" } ] }","title":"Example Upload"},{"location":"guides/masking_strategies/","text":"Configure Data Masking What is data masking? Data masking is the process of obfuscating data in client systems, so it is no longer recognizable as PII (personally identifiable information). For example, if a customer requests that your remove all information associated with their email, test@example.com , you might choose to \"mask\" that email with a random string, xgoi4301nkyi79fjfdopvyjc5lnbr9 , and their associated address with another random string 2ab6jghdg37uhkaz3hpyavpss1dvg2 . Masking does not equal anonymization. Since records are not deleted, a masked dataset is pseudonymized in most cases, and may still be identifiable if the masking is reversible or easy to predict. In Fides, your options to pseudonymize data are captured in \"masking strategies\". Fides supports a wide variety of masking strategies for different purposes when used directly as an API including HMAC, Hash, AES encryption, string rewrite, random string rewrite, and null rewrite. Why mask instead of delete? Deleting customer data may involve entirely deleting a whole record (all attributes of the entity) or permanent and irreversible anonymization of the record by updating specific fields within a record with masked values. Using a masking strategy instead of straight deletion to obscure PII helps ensure referential integrity in your database. For example, you might have an orders table with a foreign key to user without cascade delete. Say you first deleted a user with email test@example.com without addressing their orders, you could potentially have lingering orphans in the orders table. Using masking as a \"soft delete\" might be a safer strategy depending on how your tables are defined. In order to ensure referential integrity is retained, any values that represent foreign keys must be consistently updated with the same masked values across all sources. Other reasons to mask instead of delete include legal requirements that have you retain certain data for a certain length of time. Using Fides as a masking service To use Fides as a masking service, send a PUT request to the masking endpoint with the value(s) you'd like pseudonymized. This endpoint is also useful for viewing how different masking strategies work. Masking example PUT /masking/mask 1 2 3 4 5 6 7 8 9 10 11 12 { \"values\" : [ \"test@example.com\" ], \"masking_strategy\" : { \"strategy\" : \"random_string_rewrite\" , \"configuration\" : { \"length\" : 20 , \"format_preservation\" : { \"suffix\" : \"@masked.com\" } } } } Response 200 OK 1 2 3 4 { \"plain\" : [ \"test@example.com\" ], \"masked_value\" : [ \"idkeaotbrub346ycbmpo@masked.com\" ] } The email has been replaced with a random string of 20 characters, while still preserving that the value is an email. See the masking values API on how to use Fides to as a masking service. Configuration Erasure requests will mask data with the chosen masking strategy. To configure a specific masking strategy to be used for a Policy, you will create an erasure rule that captures that strategy for the Policy. PATCH /policy/policy_key/rule 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [{ \"name\" : \"Global erasure rule\" , \"action_type\" : \"erasure\" , \"key\" : \"string_rewrite_rule\" , \"masking_strategy\" : { \"strategy\" : \"random_string_rewrite\" , \"configuration\" : { \"length\" : 20 , \"format_preservation\" : { \"suffix\" : \"@masked.com\" } } } }] Supported masking strategies Null rewrite Masks the input value with a null value. strategy : null_rewrite No config needed. String rewrite Masks the input value with a default string value. strategy : string_rewrite configuration : rewrite_value : str that will replace input values format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value Hash Masks the data by hashing the input before returning it. The hash is deterministic such that the same input will return the same output within the context of the same privacy request. This is not the case when the masking service is called as a standalone service, outside the context of a privacy request. strategy : hash configuration : algorithm (optional): str that specifies Hash masking algorithm. Options include SHA-512 or SHA_256 . Default = SHA_256 format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value Random string rewrite Masks the input value with a random string of a specified length. strategy : random_string_rewrite configuration : length (optional): int that specifies length of randomly generated string. Default = 30 format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value AES encrypt Masks the data using AES encryption before returning it. The AES encryption strategy is deterministic such that the same input will return the same output within the context of the same privacy request. This is not the case when the masking service is called as a standalone service, outside the context of a privacy request. strategy : aes_encrypt configuration : mode (optional): str that specifies AES encryption mode. Only supported option is GCM . Default = GCM format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value HMAC Masks the data using HMAC before returning it. The HMAC encryption strategy is deterministic such that the same input will return the same output within the context of the same privacy request. This is not the case when the masking service is called as a standalone service, outside the context of a privacy request. strategy : hmac configuration : algorithm (optional): str that specifies HMAC masking algorithm. Options include SHA-512 or SHA_256 . Default = SHA_256 format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value See the Policy guide for more detailed instructions on creating Policies and Rules. Getting masking options Issue a GET request to /api/v1/masking/strategy to preview the different masking strategies available, along with their configuration options. Extensibility Fides asking strategies are built on top of an abstract MaskingStrategy base class. MaskingStrategy has five methods: mask , secrets_required , get_configuration_model , get_description , and data_type_supported . For more detail on these methods, visit the class in the Fides repository. The below example focuses on the implementation of RandomStringRewriteMaskingStrategy : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import string from typing import Optional from secrets import choice from fides.api.ops.schemas.masking.masking_configuration import RandomStringMaskingConfiguration , MaskingConfiguration from fides.api.ops.schemas.masking.masking_strategy_description import MaskingStrategyDescription from fides.api.ops.service.masking.strategy.format_preservation import FormatPreservation from fides.api.ops.service.masking.strategy.masking_strategy import MaskingStrategy from fides.api.ops.service.masking.strategy.masking_strategy_factory import ( MaskingStrategyFactory , ) RANDOM_STRING_REWRITE_STRATEGY_NAME = \"random_string_rewrite\" @MaskingStrategyFactory . register ( RANDOM_STRING_REWRITE_STRATEGY_NAME ) class RandomStringRewriteMaskingStrategy ( MaskingStrategy ): \"\"\"Masks a value with a random string of the length specified in the configuration.\"\"\" def __init__ ( self , configuration : RandomStringMaskingConfiguration , ): self . length = configuration . length self . format_preservation = configuration . format_preservation def mask ( self , values : Optional [ List [ str ]], privacy_request_id : Optional [ str ]) -> Optional [ List [ str ]]: \"\"\"Replaces the value with a random lowercase string of the configured length\"\"\" if values is None : return None masked_values : List [ str ] = [] for _ in range ( len ( values )): masked : str = \"\" . join ( [ choice ( string . ascii_lowercase + string . digits ) for _ in range ( self . length ) ] ) if self . format_preservation is not None : formatter = FormatPreservation ( self . format_preservation ) masked = formatter . format ( masked ) masked_values . append ( masked ) return masked_values @staticmethod def get_configuration_model () -> MaskingConfiguration : \"\"\"Not covered in this example\"\"\" @staticmethod def get_description () -> MaskingStrategyDescription : \"\"\"Not covered in this example\"\"\" @staticmethod def data_type_supported ( data_type : Optional [ str ]) -> bool : \"\"\"Not covered in this example\"\"\" The mask method will be called with the list of values to be masked and the masked values will be the output. In this case, we want to replace the supplied values with a random mixture of ascii lowercase letters and digits of the specified length. If format preservation is specified, for example, we still want to know that an email was an email, we might tack on an email-like suffix. Note the arguments to the init method. There is a field configuration of type RandomStringMaskingConfiguration . This is the configuration for the masking strategy. It is used to house the options specified by the client as well as any defaults that should be applied in their absence. All configuration classes extend from the MaskingConfiguration class. Integrate the masking strategy factory In order to leverage an implemented masking strategy, the MaskingStrategy subclass must be registered with the MaskingStrategyFactory . To register a new MaskingStrategy , use the register decorator on the MaskingStrategy subclass definition, as shown in the above example. The value passed as the argument to the decorator must be the registered name of the MaskingStrategy subclass. This is the same value defined by callers in the \"masking_strategy\".\"strategy\" field.","title":"Configure Data Masking"},{"location":"guides/masking_strategies/#configure-data-masking","text":"","title":"Configure Data Masking"},{"location":"guides/masking_strategies/#what-is-data-masking","text":"Data masking is the process of obfuscating data in client systems, so it is no longer recognizable as PII (personally identifiable information). For example, if a customer requests that your remove all information associated with their email, test@example.com , you might choose to \"mask\" that email with a random string, xgoi4301nkyi79fjfdopvyjc5lnbr9 , and their associated address with another random string 2ab6jghdg37uhkaz3hpyavpss1dvg2 . Masking does not equal anonymization. Since records are not deleted, a masked dataset is pseudonymized in most cases, and may still be identifiable if the masking is reversible or easy to predict. In Fides, your options to pseudonymize data are captured in \"masking strategies\". Fides supports a wide variety of masking strategies for different purposes when used directly as an API including HMAC, Hash, AES encryption, string rewrite, random string rewrite, and null rewrite.","title":"What is data masking?"},{"location":"guides/masking_strategies/#why-mask-instead-of-delete","text":"Deleting customer data may involve entirely deleting a whole record (all attributes of the entity) or permanent and irreversible anonymization of the record by updating specific fields within a record with masked values. Using a masking strategy instead of straight deletion to obscure PII helps ensure referential integrity in your database. For example, you might have an orders table with a foreign key to user without cascade delete. Say you first deleted a user with email test@example.com without addressing their orders, you could potentially have lingering orphans in the orders table. Using masking as a \"soft delete\" might be a safer strategy depending on how your tables are defined. In order to ensure referential integrity is retained, any values that represent foreign keys must be consistently updated with the same masked values across all sources. Other reasons to mask instead of delete include legal requirements that have you retain certain data for a certain length of time.","title":"Why mask instead of delete?"},{"location":"guides/masking_strategies/#using-fides-as-a-masking-service","text":"To use Fides as a masking service, send a PUT request to the masking endpoint with the value(s) you'd like pseudonymized. This endpoint is also useful for viewing how different masking strategies work.","title":"Using Fides as a masking service"},{"location":"guides/masking_strategies/#masking-example","text":"PUT /masking/mask 1 2 3 4 5 6 7 8 9 10 11 12 { \"values\" : [ \"test@example.com\" ], \"masking_strategy\" : { \"strategy\" : \"random_string_rewrite\" , \"configuration\" : { \"length\" : 20 , \"format_preservation\" : { \"suffix\" : \"@masked.com\" } } } } Response 200 OK 1 2 3 4 { \"plain\" : [ \"test@example.com\" ], \"masked_value\" : [ \"idkeaotbrub346ycbmpo@masked.com\" ] } The email has been replaced with a random string of 20 characters, while still preserving that the value is an email. See the masking values API on how to use Fides to as a masking service.","title":"Masking example"},{"location":"guides/masking_strategies/#configuration","text":"Erasure requests will mask data with the chosen masking strategy. To configure a specific masking strategy to be used for a Policy, you will create an erasure rule that captures that strategy for the Policy. PATCH /policy/policy_key/rule 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [{ \"name\" : \"Global erasure rule\" , \"action_type\" : \"erasure\" , \"key\" : \"string_rewrite_rule\" , \"masking_strategy\" : { \"strategy\" : \"random_string_rewrite\" , \"configuration\" : { \"length\" : 20 , \"format_preservation\" : { \"suffix\" : \"@masked.com\" } } } }]","title":"Configuration"},{"location":"guides/masking_strategies/#supported-masking-strategies","text":"","title":"Supported masking strategies"},{"location":"guides/masking_strategies/#null-rewrite","text":"Masks the input value with a null value. strategy : null_rewrite No config needed.","title":"Null rewrite"},{"location":"guides/masking_strategies/#string-rewrite","text":"Masks the input value with a default string value. strategy : string_rewrite configuration : rewrite_value : str that will replace input values format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value","title":"String rewrite"},{"location":"guides/masking_strategies/#hash","text":"Masks the data by hashing the input before returning it. The hash is deterministic such that the same input will return the same output within the context of the same privacy request. This is not the case when the masking service is called as a standalone service, outside the context of a privacy request. strategy : hash configuration : algorithm (optional): str that specifies Hash masking algorithm. Options include SHA-512 or SHA_256 . Default = SHA_256 format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value","title":"Hash"},{"location":"guides/masking_strategies/#random-string-rewrite","text":"Masks the input value with a random string of a specified length. strategy : random_string_rewrite configuration : length (optional): int that specifies length of randomly generated string. Default = 30 format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value","title":"Random string rewrite"},{"location":"guides/masking_strategies/#aes-encrypt","text":"Masks the data using AES encryption before returning it. The AES encryption strategy is deterministic such that the same input will return the same output within the context of the same privacy request. This is not the case when the masking service is called as a standalone service, outside the context of a privacy request. strategy : aes_encrypt configuration : mode (optional): str that specifies AES encryption mode. Only supported option is GCM . Default = GCM format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value","title":"AES encrypt"},{"location":"guides/masking_strategies/#hmac","text":"Masks the data using HMAC before returning it. The HMAC encryption strategy is deterministic such that the same input will return the same output within the context of the same privacy request. This is not the case when the masking service is called as a standalone service, outside the context of a privacy request. strategy : hmac configuration : algorithm (optional): str that specifies HMAC masking algorithm. Options include SHA-512 or SHA_256 . Default = SHA_256 format_preservation (optional): Dict with the following key/vals: suffix : str that specifies suffix to append to masked value See the Policy guide for more detailed instructions on creating Policies and Rules.","title":"HMAC"},{"location":"guides/masking_strategies/#getting-masking-options","text":"Issue a GET request to /api/v1/masking/strategy to preview the different masking strategies available, along with their configuration options.","title":"Getting masking options"},{"location":"guides/masking_strategies/#extensibility","text":"Fides asking strategies are built on top of an abstract MaskingStrategy base class. MaskingStrategy has five methods: mask , secrets_required , get_configuration_model , get_description , and data_type_supported . For more detail on these methods, visit the class in the Fides repository. The below example focuses on the implementation of RandomStringRewriteMaskingStrategy : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import string from typing import Optional from secrets import choice from fides.api.ops.schemas.masking.masking_configuration import RandomStringMaskingConfiguration , MaskingConfiguration from fides.api.ops.schemas.masking.masking_strategy_description import MaskingStrategyDescription from fides.api.ops.service.masking.strategy.format_preservation import FormatPreservation from fides.api.ops.service.masking.strategy.masking_strategy import MaskingStrategy from fides.api.ops.service.masking.strategy.masking_strategy_factory import ( MaskingStrategyFactory , ) RANDOM_STRING_REWRITE_STRATEGY_NAME = \"random_string_rewrite\" @MaskingStrategyFactory . register ( RANDOM_STRING_REWRITE_STRATEGY_NAME ) class RandomStringRewriteMaskingStrategy ( MaskingStrategy ): \"\"\"Masks a value with a random string of the length specified in the configuration.\"\"\" def __init__ ( self , configuration : RandomStringMaskingConfiguration , ): self . length = configuration . length self . format_preservation = configuration . format_preservation def mask ( self , values : Optional [ List [ str ]], privacy_request_id : Optional [ str ]) -> Optional [ List [ str ]]: \"\"\"Replaces the value with a random lowercase string of the configured length\"\"\" if values is None : return None masked_values : List [ str ] = [] for _ in range ( len ( values )): masked : str = \"\" . join ( [ choice ( string . ascii_lowercase + string . digits ) for _ in range ( self . length ) ] ) if self . format_preservation is not None : formatter = FormatPreservation ( self . format_preservation ) masked = formatter . format ( masked ) masked_values . append ( masked ) return masked_values @staticmethod def get_configuration_model () -> MaskingConfiguration : \"\"\"Not covered in this example\"\"\" @staticmethod def get_description () -> MaskingStrategyDescription : \"\"\"Not covered in this example\"\"\" @staticmethod def data_type_supported ( data_type : Optional [ str ]) -> bool : \"\"\"Not covered in this example\"\"\" The mask method will be called with the list of values to be masked and the masked values will be the output. In this case, we want to replace the supplied values with a random mixture of ascii lowercase letters and digits of the specified length. If format preservation is specified, for example, we still want to know that an email was an email, we might tack on an email-like suffix. Note the arguments to the init method. There is a field configuration of type RandomStringMaskingConfiguration . This is the configuration for the masking strategy. It is used to house the options specified by the client as well as any defaults that should be applied in their absence. All configuration classes extend from the MaskingConfiguration class.","title":"Extensibility"},{"location":"guides/masking_strategies/#integrate-the-masking-strategy-factory","text":"In order to leverage an implemented masking strategy, the MaskingStrategy subclass must be registered with the MaskingStrategyFactory . To register a new MaskingStrategy , use the register decorator on the MaskingStrategy subclass definition, as shown in the above example. The value passed as the argument to the decorator must be the registered name of the MaskingStrategy subclass. This is the same value defined by callers in the \"masking_strategy\".\"strategy\" field.","title":"Integrate the masking strategy factory"},{"location":"guides/oauth/","text":"Authenticate with OAuth When you invoke a Fides API, you must pass an access token as the value of the Authorization header. This token must also include a scope that gives you permission to take an action on the API. For example, to create a new execution policy, the token that you pass to the Authorization header must include the policy:create_or_update scope. When running the Fides webserver, navigate to the interactive API docs at http://{server_url}/docs (e.g., http://0.0.0.0:8080/docs ) to access the following endpoints. Create the root client Create an access client ID and secret for the \"root\" client. In your fides.toml , these are defined as oauth_root_client_id and oauth_root_client_secret . The root client token contains all scopes, and can call any of the Fides APIs. Once authenticated, creating additional users with individual scopes is recommended. To create a root token, call the POST /api/v1/oauth/token endpoint: POST /api/v1/oauth/token 1 2 3 4 5 { \"client_id\" : \"{oauth_root_client_id}\" , \"client_secret\" : \"{oauth_root_client_secret}\" , \"grant_type\" : \"client_credentials\" } Curl options 1 2 3 4 5 curl \\ -X POST 'http://<HOST>:8080/api/v1/oauth/token' \\ -d client_id ={ oauth_root_client_id } \\ -d client_secret ={ oauth_root_client_secret } \\ -d grant_type = client_credentials Substitute the oauth_root_client_id and oauth_root_client_secret for the values in your fides.toml , or provide their environment variables. If the token call is successful, the response will return the root client's access token in the access_token property: 1 2 3 4 5 6 7 HTTP/1.1 200 OK Content-Type: application/json { \"access_token\" : \"MTI4Q0JDJSrgyplbmMiOiJBjU2I..._X0hTMyXAyPx\", /* ignore any other properties */ } Create additional clients Because the root client's token contains all scopes, it can create new clients and new client ID/client secret pairs which can be used to create additional access tokens. Best practices recommend creating a client with the scope CLIENT_CREATE to create any new clients. This will help to reduce the utilization of the all-scopes root client. To create the client ID/secret pair, call POST /api/v1/oauth/client . If using the interactive Swagger docs, ensure you have provided your credentials in the Authorize option, and for the endpoint. Curl options 1 2 3 4 5 curl \\ -X POST 'http://<HOST>:8080/api/v1/oauth/client' \\ -H 'Authorization: Bearer <root_access_token>' -H 'Content-Type: application/json' -d '{ \"scopes\": [\"policy:read\", \"rule:read\"]}' The authorization header value is formed as Bearer <token> , and the request's Content-Type is application/json . Authorize a client with scopes To add scopes to the client, the body of your request must contain an array of scope tokens. You can retrieve the available scopes by calling GET /api/v1/oauth/scopes . If the call is successful, Fides will respond with a new client ID/client secret pair: 1 2 3 4 5 6 7 HTTP/1.1 200 OK Content-Type: application/json { \"client_id\" : \"<new_client_id>\" \"client_secret\" : \"<new_client_secret>\", } Create an access token You then create a new access token by calling POST /api/v1/oauth/token with the new credentials. In the above example, the new access token only lets the client read policies and rules. The client cannot create other clients, write policies, or perform other operations using Fides APIs. Access token expiration By default, access tokens expire after 11520 minutes (8 days). To specify a different expiration time (in minutes) set the OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES environment variable, or the oauth_access_token_expire_minutes value in your fides.toml . If you call the Fides API with an expired token, the call returns 401 . Other OAuth Calls Fides defines OAuth operations that let you delete a client, and read and write a client's scopes. See the OAuth section of the API documentation for details.","title":"Authenticate with OAuth"},{"location":"guides/oauth/#authenticate-with-oauth","text":"When you invoke a Fides API, you must pass an access token as the value of the Authorization header. This token must also include a scope that gives you permission to take an action on the API. For example, to create a new execution policy, the token that you pass to the Authorization header must include the policy:create_or_update scope. When running the Fides webserver, navigate to the interactive API docs at http://{server_url}/docs (e.g., http://0.0.0.0:8080/docs ) to access the following endpoints.","title":"Authenticate with OAuth"},{"location":"guides/oauth/#create-the-root-client","text":"Create an access client ID and secret for the \"root\" client. In your fides.toml , these are defined as oauth_root_client_id and oauth_root_client_secret . The root client token contains all scopes, and can call any of the Fides APIs. Once authenticated, creating additional users with individual scopes is recommended. To create a root token, call the POST /api/v1/oauth/token endpoint: POST /api/v1/oauth/token 1 2 3 4 5 { \"client_id\" : \"{oauth_root_client_id}\" , \"client_secret\" : \"{oauth_root_client_secret}\" , \"grant_type\" : \"client_credentials\" } Curl options 1 2 3 4 5 curl \\ -X POST 'http://<HOST>:8080/api/v1/oauth/token' \\ -d client_id ={ oauth_root_client_id } \\ -d client_secret ={ oauth_root_client_secret } \\ -d grant_type = client_credentials Substitute the oauth_root_client_id and oauth_root_client_secret for the values in your fides.toml , or provide their environment variables. If the token call is successful, the response will return the root client's access token in the access_token property: 1 2 3 4 5 6 7 HTTP/1.1 200 OK Content-Type: application/json { \"access_token\" : \"MTI4Q0JDJSrgyplbmMiOiJBjU2I..._X0hTMyXAyPx\", /* ignore any other properties */ }","title":"Create the root client"},{"location":"guides/oauth/#create-additional-clients","text":"Because the root client's token contains all scopes, it can create new clients and new client ID/client secret pairs which can be used to create additional access tokens. Best practices recommend creating a client with the scope CLIENT_CREATE to create any new clients. This will help to reduce the utilization of the all-scopes root client. To create the client ID/secret pair, call POST /api/v1/oauth/client . If using the interactive Swagger docs, ensure you have provided your credentials in the Authorize option, and for the endpoint. Curl options 1 2 3 4 5 curl \\ -X POST 'http://<HOST>:8080/api/v1/oauth/client' \\ -H 'Authorization: Bearer <root_access_token>' -H 'Content-Type: application/json' -d '{ \"scopes\": [\"policy:read\", \"rule:read\"]}' The authorization header value is formed as Bearer <token> , and the request's Content-Type is application/json .","title":"Create additional clients"},{"location":"guides/oauth/#authorize-a-client-with-scopes","text":"To add scopes to the client, the body of your request must contain an array of scope tokens. You can retrieve the available scopes by calling GET /api/v1/oauth/scopes . If the call is successful, Fides will respond with a new client ID/client secret pair: 1 2 3 4 5 6 7 HTTP/1.1 200 OK Content-Type: application/json { \"client_id\" : \"<new_client_id>\" \"client_secret\" : \"<new_client_secret>\", }","title":"Authorize a client with scopes"},{"location":"guides/oauth/#create-an-access-token","text":"You then create a new access token by calling POST /api/v1/oauth/token with the new credentials. In the above example, the new access token only lets the client read policies and rules. The client cannot create other clients, write policies, or perform other operations using Fides APIs.","title":"Create an access token"},{"location":"guides/oauth/#access-token-expiration","text":"By default, access tokens expire after 11520 minutes (8 days). To specify a different expiration time (in minutes) set the OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES environment variable, or the oauth_access_token_expire_minutes value in your fides.toml . If you call the Fides API with an expired token, the call returns 401 .","title":"Access token expiration"},{"location":"guides/oauth/#other-oauth-calls","text":"Fides defines OAuth operations that let you delete a client, and read and write a client's scopes. See the OAuth section of the API documentation for details.","title":"Other OAuth Calls"},{"location":"guides/onetrust/","text":"Configure a OneTrust Integration API docs for OneTrust are part of the storage module. Overview OneTrust is a DSAR automation provider that provides an interface to manage privacy requests. Fides handles the integration to OneTrust to fulfill subject requests, and returns the data package back to OneTrust. How it works The Fides integration with OneTrust looks like the follow: Set up a new storage destination of type onetrust A new scheduled task kicks off that pings OneTrust for subtasks labeled for Fides Fides processes those DSARs normally Upon completion of DSAR processing, Fides will: Ping OneTrust to set the subtask status appropriately If applicable, upload a data package back to OneTrust Configuration Fides OneTrust request intake is configured as part of the possible Fides storage locations . To configure Fides to connect to OneTrust: Add a new storage location with a onetrust destination type Use appropriate credentials to authenticate with OneTrust Decide what day of the week and hour of the day you wish to retrieve requests from OneTrust OneTrust When the Fides scheduled task runs, it looks for subtasks with an exact string name of \"fides task\". Be sure tasks you wish to pass through the Fides ecosystem are correctly labeled in the OneTrust interface. Testing To test the OneTrust integration works correctly, you must: Ensure that you have subtasks with a name of \"fides task\" in OneTrust Set your OneTrust destination config in Fides such that day of week and hour of request intake is appropriate for testing Confirm that the subtask status has been updated at that time, and any DSAR data packages have been uploaded at the request level in OneTrust","title":"Integrate with OneTrust"},{"location":"guides/onetrust/#configure-a-onetrust-integration","text":"API docs for OneTrust are part of the storage module.","title":"Configure a OneTrust Integration"},{"location":"guides/onetrust/#overview","text":"OneTrust is a DSAR automation provider that provides an interface to manage privacy requests. Fides handles the integration to OneTrust to fulfill subject requests, and returns the data package back to OneTrust.","title":"Overview"},{"location":"guides/onetrust/#how-it-works","text":"The Fides integration with OneTrust looks like the follow: Set up a new storage destination of type onetrust A new scheduled task kicks off that pings OneTrust for subtasks labeled for Fides Fides processes those DSARs normally Upon completion of DSAR processing, Fides will: Ping OneTrust to set the subtask status appropriately If applicable, upload a data package back to OneTrust","title":"How it works"},{"location":"guides/onetrust/#configuration","text":"","title":"Configuration"},{"location":"guides/onetrust/#fides","text":"OneTrust request intake is configured as part of the possible Fides storage locations . To configure Fides to connect to OneTrust: Add a new storage location with a onetrust destination type Use appropriate credentials to authenticate with OneTrust Decide what day of the week and hour of the day you wish to retrieve requests from OneTrust","title":"Fides"},{"location":"guides/onetrust/#onetrust","text":"When the Fides scheduled task runs, it looks for subtasks with an exact string name of \"fides task\". Be sure tasks you wish to pass through the Fides ecosystem are correctly labeled in the OneTrust interface.","title":"OneTrust"},{"location":"guides/onetrust/#testing","text":"To test the OneTrust integration works correctly, you must: Ensure that you have subtasks with a name of \"fides task\" in OneTrust Set your OneTrust destination config in Fides such that day of week and hour of request intake is appropriate for testing Confirm that the subtask status has been updated at that time, and any DSAR data packages have been uploaded at the request level in OneTrust","title":"Testing"},{"location":"guides/policies/","text":"Create a Fides Policy What is a Policy? Fides resources provide metadata about systems and services, the data categories they process, and the uses of that data. Policies allow you to enforce constraints on these declarations, decide what combinations to allow or reject, and begin to control data privacy at its source. The purpose of a privacy policy is to state what types of data are allowed for certain means of use. In Fides, a Policy is made up of rules against which the system's resources are evaluated. Policies evaluate the data subjects, data category, and data qualifier values against data use cases. This generates a boolean output to either allow or reject the process from proceeding. Policy attributes Policies use the following attributes: Name Type Description fides_key FidesKey An identifier label that must be unique within your organization. A fides_key can only contain alphanumeric characters and _ . data_categories List[DataRule] The types of sensitive data as defined by the taxonomy. data_uses List[DataRule] The various categories of data processing and operations within your organization. data_subjects List[DataRule] The individual persons to whom you data rule pertains. data_qualifier String The acceptable or non-acceptable level of de-identification. For more detail on Policy resources, see the full Policy resource documentation . Sample Policy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 policy : - fides_key : flaskr_policy name : Flaskr Privacy Policy description : A privacy policy for the example Flask app rules : - fides_key : minimize_user_identifiable_data name : Minimize User Identifiable Data description : Reject collecting any user identifiable data for uses other than system operations data_categories : matches : ANY values : - user.provided.identifiable - user.derived.identifiable data_uses : matches : ANY values : - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - fides_key : reject_sensitive_data name : Reject Sensitive Data description : Reject collecting sensitive user data for any use data_categories : matches : ANY values : - user.provided.identifiable.biometric - user.provided.identifiable.childrens - user.provided.identifiable.genetic - user.provided.identifiable.health_and_medical - user.provided.identifiable.political_opinion - user.provided.identifiable.race - user.provided.identifiable.religious_belief - user.provided.identifiable.sexual_orientation data_uses : matches : ANY values : - provide - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated This Fides policy is relatively restrictive. The two rules ( minimize_user_identifiable_data and reject_sensitive_data ) can be interpreted as: Do not use identifiable data for anything other than the app's primary functions. Do not collect any sensitive data at all. As a safe default, this is the type of policy you might add to all projects. Maintaining your Policies As global privacy laws change and businesses scale, a company's policies will evolve with them. Updating this resource file should become a regular part of the development planning process when building a new feature. Example Policies The following are examples of real-world use cases for Fides Policies, representing common business requirements or legislation. Always ensure your Policies accurately represent your business needs prior to using them in production environments. No Third-Party Data Sharing data_sharing_policy.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 policy : - fides_key : data_sharing_policy name : Data Sharing description : The privacy policy that governs sharing of data with third parties. rules : - name : Disallow Third-Party Marketing description : Disallow collecting any user contact info to use for marketing. data_categories : matches : ANY # If any of these data categories are being used values : - account - user data_uses : matches : ANY # And the use of the data is for third-party sharing values : - third_party_sharing data_subjects : matches : ANY # And the data subject is a customer values : - customer # And the data is identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified Respecting Employee Data Privacy employee_data_processing_policy.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 policy : - fides_key : employee_data_processing name : Employee Data Processing description : Restrict employee data processing only to that which is required for systematic business functions. rules : - name : Disallow Non-System Use of Employee Data data_categories : matches : ANY # If any of these data categories are being used values : - account - user data_uses : matches : OTHER # And the use of the data is something other than... values : - provide.service.operations - improve.system - collect data_subjects : matches : ANY # And the data subject is an employee values : - employee # And the data is identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified Respecting Biometric PII biometric_data_policy.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 policy : - fides_key : biometric_data_policy name : Biometric Data description : Policy that describes valid uses of biometric and health data. rules : - name : Disallow Biometrics for Profit. description : Disallow the use of biometric data for profit-related purposes. data_categories : matches : ANY # If any of these data categories are being used values : - user.derived - user.provided.identifiable.credentials.biometric_credentials - user.provided.identifiable.biometric data_uses : matches : ANY # And the use of the data is for any of the following... values : - advertising - train_ai_system - improve - third_party_sharing data_subjects : matches : ANY # And the data subject is a customer values : - customer # And the data is identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified Anonymous Derived User Contact Data derived_user_data_policy.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 policy : - fides_key : protect_derived_user_data name : Protect Derived User Data description : Policy that describes the proper use of derived user data. rules : - name : Disallow Non-Anonymized Derived User Data. description : Require that any use of derived user data must be de-identified to the anonymous level, as opposed to the pseudonymous. data_categories : matches : ANY # If any of these data categories are being used values : - user - account data_uses : matches : NONE # And for any data use values : [] data_subjects : matches : ANY # And the data subject is a customer values : - customer # And the data is either pseudonymized or more identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized Phone Numbers for Transactional Messaging transactional_messaging_policy.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 policy : - fides_key : transactional_messaging_policy rules : - name : Transactional Messaging only for phone numbers. description : Allows use of phone numbers for transactional messaging only. data_categories : matches : ANY # If any of these data categories are being used values : - user.provided.identifiable.contact.phone_number data_uses : matches : OTHER # And a data use other than these have been declared values : - provide.service.operations - provide.service.operations.support data_subjects : matches : ANY # And the data subject is a customer values : - customer # And the data is identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified","title":"Create Policies"},{"location":"guides/policies/#create-a-fides-policy","text":"","title":"Create a Fides Policy"},{"location":"guides/policies/#what-is-a-policy","text":"Fides resources provide metadata about systems and services, the data categories they process, and the uses of that data. Policies allow you to enforce constraints on these declarations, decide what combinations to allow or reject, and begin to control data privacy at its source. The purpose of a privacy policy is to state what types of data are allowed for certain means of use. In Fides, a Policy is made up of rules against which the system's resources are evaluated. Policies evaluate the data subjects, data category, and data qualifier values against data use cases. This generates a boolean output to either allow or reject the process from proceeding.","title":"What is a Policy?"},{"location":"guides/policies/#policy-attributes","text":"Policies use the following attributes: Name Type Description fides_key FidesKey An identifier label that must be unique within your organization. A fides_key can only contain alphanumeric characters and _ . data_categories List[DataRule] The types of sensitive data as defined by the taxonomy. data_uses List[DataRule] The various categories of data processing and operations within your organization. data_subjects List[DataRule] The individual persons to whom you data rule pertains. data_qualifier String The acceptable or non-acceptable level of de-identification. For more detail on Policy resources, see the full Policy resource documentation .","title":"Policy attributes"},{"location":"guides/policies/#sample-policy","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 policy : - fides_key : flaskr_policy name : Flaskr Privacy Policy description : A privacy policy for the example Flask app rules : - fides_key : minimize_user_identifiable_data name : Minimize User Identifiable Data description : Reject collecting any user identifiable data for uses other than system operations data_categories : matches : ANY values : - user.provided.identifiable - user.derived.identifiable data_uses : matches : ANY values : - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - fides_key : reject_sensitive_data name : Reject Sensitive Data description : Reject collecting sensitive user data for any use data_categories : matches : ANY values : - user.provided.identifiable.biometric - user.provided.identifiable.childrens - user.provided.identifiable.genetic - user.provided.identifiable.health_and_medical - user.provided.identifiable.political_opinion - user.provided.identifiable.race - user.provided.identifiable.religious_belief - user.provided.identifiable.sexual_orientation data_uses : matches : ANY values : - provide - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated This Fides policy is relatively restrictive. The two rules ( minimize_user_identifiable_data and reject_sensitive_data ) can be interpreted as: Do not use identifiable data for anything other than the app's primary functions. Do not collect any sensitive data at all. As a safe default, this is the type of policy you might add to all projects.","title":"Sample Policy"},{"location":"guides/policies/#maintaining-your-policies","text":"As global privacy laws change and businesses scale, a company's policies will evolve with them. Updating this resource file should become a regular part of the development planning process when building a new feature.","title":"Maintaining your Policies"},{"location":"guides/policies/#example-policies","text":"The following are examples of real-world use cases for Fides Policies, representing common business requirements or legislation. Always ensure your Policies accurately represent your business needs prior to using them in production environments.","title":"Example Policies"},{"location":"guides/policies/#no-third-party-data-sharing","text":"data_sharing_policy.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 policy : - fides_key : data_sharing_policy name : Data Sharing description : The privacy policy that governs sharing of data with third parties. rules : - name : Disallow Third-Party Marketing description : Disallow collecting any user contact info to use for marketing. data_categories : matches : ANY # If any of these data categories are being used values : - account - user data_uses : matches : ANY # And the use of the data is for third-party sharing values : - third_party_sharing data_subjects : matches : ANY # And the data subject is a customer values : - customer # And the data is identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified","title":"No Third-Party Data Sharing"},{"location":"guides/policies/#respecting-employee-data-privacy","text":"employee_data_processing_policy.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 policy : - fides_key : employee_data_processing name : Employee Data Processing description : Restrict employee data processing only to that which is required for systematic business functions. rules : - name : Disallow Non-System Use of Employee Data data_categories : matches : ANY # If any of these data categories are being used values : - account - user data_uses : matches : OTHER # And the use of the data is something other than... values : - provide.service.operations - improve.system - collect data_subjects : matches : ANY # And the data subject is an employee values : - employee # And the data is identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified","title":"Respecting Employee Data Privacy"},{"location":"guides/policies/#respecting-biometric-pii","text":"biometric_data_policy.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 policy : - fides_key : biometric_data_policy name : Biometric Data description : Policy that describes valid uses of biometric and health data. rules : - name : Disallow Biometrics for Profit. description : Disallow the use of biometric data for profit-related purposes. data_categories : matches : ANY # If any of these data categories are being used values : - user.derived - user.provided.identifiable.credentials.biometric_credentials - user.provided.identifiable.biometric data_uses : matches : ANY # And the use of the data is for any of the following... values : - advertising - train_ai_system - improve - third_party_sharing data_subjects : matches : ANY # And the data subject is a customer values : - customer # And the data is identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified","title":"Respecting Biometric PII"},{"location":"guides/policies/#anonymous-derived-user-contact-data","text":"derived_user_data_policy.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 policy : - fides_key : protect_derived_user_data name : Protect Derived User Data description : Policy that describes the proper use of derived user data. rules : - name : Disallow Non-Anonymized Derived User Data. description : Require that any use of derived user data must be de-identified to the anonymous level, as opposed to the pseudonymous. data_categories : matches : ANY # If any of these data categories are being used values : - user - account data_uses : matches : NONE # And for any data use values : [] data_subjects : matches : ANY # And the data subject is a customer values : - customer # And the data is either pseudonymized or more identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized","title":"Anonymous Derived User Contact Data"},{"location":"guides/policies/#phone-numbers-for-transactional-messaging","text":"transactional_messaging_policy.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 policy : - fides_key : transactional_messaging_policy rules : - name : Transactional Messaging only for phone numbers. description : Allows use of phone numbers for transactional messaging only. data_categories : matches : ANY # If any of these data categories are being used values : - user.provided.identifiable.contact.phone_number data_uses : matches : OTHER # And a data use other than these have been declared values : - provide.service.operations - provide.service.operations.support data_subjects : matches : ANY # And the data subject is a customer values : - customer # And the data is identifiable, trigger a violation data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified","title":"Phone Numbers for Transactional Messaging"},{"location":"guides/policy_webhooks/","text":"Configure Execution Policy Webhooks What is a Policy webhook? An webhook is an HTTPS callback that you've defined on an execution policy to call an external REST API endpoint either before or after a privacy bequest executes. Webhooks can be one_way , where the API is pinged and the privacy request continues, or two_way , where Fides will wait for a response. Any derived values returned from a two_way webhook will be saved, and can be used to locate other user information. For example, a webhook might take a known email identity and use that to find a phone_number derived_identity . Configuration The process below will define an https Connection that contains the details to make a request to your API endpoint, and then create a PolicyPreWebhook or a PolicyPostWebhook for a specific execution policy using that Connection. Create an HTTPS Connection The information that describes how to connect to your API endpoint is represented by a Fides Connection PATCH /v1/connection 1 2 3 4 5 6 7 8 [ { \"name\" : \"My Webhook Connection Configuration\" , \"key\" : \"test_webhook_connection_config\" , \"connection_type\" : \"https\" , \"access\" : \"read\" } ] Add your Connection secrets The credentials needed to access your API endpoint are defined by making a PUT to the Connection Secrets endpoint. These credentials are encrypted in the Fides app database PUT /v1/connection/test_webhook_connection_config 1 2 3 4 { \"url\" : \"https://www.example.com\" , \"authorization\" : \"test_authorization\" } Define pre-execution or post-execution webhooks After you've defined a new Connection, you can create lists of webhooks to run before ( PolicyPreWebhooks ) or after ( PolicyPostWebhooks ) a privacy request is executed. When defining webhooks, they should be included in the request body in the desired order. Any webhooks on the execution policy not included in the request will be removed from the policy. To update a list of PolicyPreWebhooks PUT /policy/{policy_key}/webhook/pre_execution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [ { \"connection_config_key\" : \"test_webhook_connection_config\" , \"direction\" : \"one_way\" , \"key\" : \"wake_up_snowflake_db\" , \"name\" : \"Wake up Snowflake DB Webhook\" }, { \"connection_config_key\" : \"test_webhook_connection_config\" , \"direction\" : \"two_way\" , \"key\" : \"prep_systems_webhook\" , \"name\" : \"Prep Systems Webhook\" } ] This creates two webhooks that are run sequentially for the execution policy before a privacy request runs. Similarly, to update your list of post-execution webhooks on a policy, use the following endpoint 1 PUT /policy/{policy_key}/webhook/post_execution See API docs for more information on how to Update PolicyPreWebhooks and how to Update PolicyPostWebhooks . Update a single webhook To update a single webhook, send a PATCH request to update selected attributes. Updates to order can likewise update the order of related webhooks. The following example will update the PolicyPreWebhook with key webhook_hook to be two_way instead of one_way , and will update its order from 0 to 1. Because we've defined two PolicyPreWebhooks, this causes the webhook at position 1 to move to position 0. PATCH /policy/{policy_key}/webhook/pre-execution/wake_up_snowflake_db 1 2 3 4 { \"direction\" : \"two_way\" , \"order\" : 1 } Because this PATCH request updated the order of other webhooks, a reordered summary is included under the new_order attribute: Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"resource\" : { \"direction\" : \"two_way\" , \"key\" : \"wake_up_snowflake_db\" , \"name\" : \"Wake up Snowflake DB Webhook\" , \"connection_config\" : \"<TRUNCATED>\" , \"order\" : 1 }, \"new_order\" : [ { \"key\" : \"prep_systems_webhook\" , \"order\" : 0 }, { \"key\" : \"wake_up_snowflake_db\" , \"order\" : 1 } ] } Similarly, to update your a post-execution webhook on an execution policy, use the following endpoint: 1 PATCH /policy/{policy_key}/webhook/post_execution/{post_execution_key} See API docs for more information on how to PATCH a PolicyPreWebhook and how to PATCH a PolicyPostWebhook . Webhook request format Before and after running access or erasure requests, Fides will send requests to any configured webhooks in sequential order with the following request body: POST {user-defined URL} 1 2 3 4 5 6 7 8 9 { \"privacy_request_id\" : \"pri_029832ba-3b84-40f7-8946-82aec6f95448\" , \"direction\" : \"one_way | two_way\" , \"callback_type\" : \"pre | post\" , \"identity\" : { \"email\" : \"customer-1@example.com\" , \"phone_number\" : \"555-5555\" } } These attributes were configured at the time of webhook creation. Known identities are also embedded in the request. For two-way webhooks, Fides includes specific headers to pause request execution while any additional processing takes place 1 2 3 4 { \"reply-to\" : \"/privacy-request/{privacy_request_id}/resume\" , \"reply-to-token\" : \"<jwe_token>\" } To resume, send a request to the reply-to URL with the reply-to-token . The reply-to-token will expire when your Redis cache expires (represented by default_ttl_seconds in your Fides config . When a request expires, it is be given an error status, and requires resubmission. Webhook response format Your webhook should respond immediately. If more processing time is needed, either make sure it is configured as a one-way webhook, or reply with halt=True if you want to pause execution and wait for any processing to finish. Note that only pre-execution webhooks can pause execution. Responses aren ot expected from one-way webhooks, but two-way webhooks should respond with the following 1 2 3 4 5 6 7 { \"derived_identity\" : { \"email\" : \"customer-1@gmail.com\" , \"phone_number\" : \"555-5555\" }, \"halt\" : \"true | false\" } Derived identity is optional: a returned email or phone number will replace currently known emails or phone numbers. Resuming request execution Once a paused webhook has completed processing, send a request to the reply-to URL sent in the original request header, along with the reply-to-token auth token. POST privacy_request/{privacy-request-id}/resume 1 2 3 4 5 6 { \"derived_identity\" : { \"email\" : \"customer-1@gmail.com\" , \"phone_number\" : \"555-5555\" } } If there are no derived identities, send an empty {} request body. The reply-to-token is a JWE containing the current webhook ID, scopes to access the callback endpoint, and the datetime the token is issued. Fides unpacks this and resumes the privacy request execution after the specified webhook. The reply-to-token expires after a set amount of time, (the privacy_request_delay_timeout in your Fides config ). Once the Redis cache expires, Fides no longer has the original identity data and the privacy request should be resubmitted","title":"Execution Policy Webhooks"},{"location":"guides/policy_webhooks/#configure-execution-policy-webhooks","text":"","title":"Configure Execution Policy Webhooks"},{"location":"guides/policy_webhooks/#what-is-a-policy-webhook","text":"An webhook is an HTTPS callback that you've defined on an execution policy to call an external REST API endpoint either before or after a privacy bequest executes. Webhooks can be one_way , where the API is pinged and the privacy request continues, or two_way , where Fides will wait for a response. Any derived values returned from a two_way webhook will be saved, and can be used to locate other user information. For example, a webhook might take a known email identity and use that to find a phone_number derived_identity .","title":"What is a Policy webhook?"},{"location":"guides/policy_webhooks/#configuration","text":"The process below will define an https Connection that contains the details to make a request to your API endpoint, and then create a PolicyPreWebhook or a PolicyPostWebhook for a specific execution policy using that Connection.","title":"Configuration"},{"location":"guides/policy_webhooks/#create-an-https-connection","text":"The information that describes how to connect to your API endpoint is represented by a Fides Connection PATCH /v1/connection 1 2 3 4 5 6 7 8 [ { \"name\" : \"My Webhook Connection Configuration\" , \"key\" : \"test_webhook_connection_config\" , \"connection_type\" : \"https\" , \"access\" : \"read\" } ]","title":"Create an HTTPS Connection"},{"location":"guides/policy_webhooks/#add-your-connection-secrets","text":"The credentials needed to access your API endpoint are defined by making a PUT to the Connection Secrets endpoint. These credentials are encrypted in the Fides app database PUT /v1/connection/test_webhook_connection_config 1 2 3 4 { \"url\" : \"https://www.example.com\" , \"authorization\" : \"test_authorization\" }","title":"Add your Connection secrets"},{"location":"guides/policy_webhooks/#define-pre-execution-or-post-execution-webhooks","text":"After you've defined a new Connection, you can create lists of webhooks to run before ( PolicyPreWebhooks ) or after ( PolicyPostWebhooks ) a privacy request is executed. When defining webhooks, they should be included in the request body in the desired order. Any webhooks on the execution policy not included in the request will be removed from the policy. To update a list of PolicyPreWebhooks PUT /policy/{policy_key}/webhook/pre_execution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [ { \"connection_config_key\" : \"test_webhook_connection_config\" , \"direction\" : \"one_way\" , \"key\" : \"wake_up_snowflake_db\" , \"name\" : \"Wake up Snowflake DB Webhook\" }, { \"connection_config_key\" : \"test_webhook_connection_config\" , \"direction\" : \"two_way\" , \"key\" : \"prep_systems_webhook\" , \"name\" : \"Prep Systems Webhook\" } ] This creates two webhooks that are run sequentially for the execution policy before a privacy request runs. Similarly, to update your list of post-execution webhooks on a policy, use the following endpoint 1 PUT /policy/{policy_key}/webhook/post_execution See API docs for more information on how to Update PolicyPreWebhooks and how to Update PolicyPostWebhooks .","title":"Define pre-execution or post-execution webhooks"},{"location":"guides/policy_webhooks/#update-a-single-webhook","text":"To update a single webhook, send a PATCH request to update selected attributes. Updates to order can likewise update the order of related webhooks. The following example will update the PolicyPreWebhook with key webhook_hook to be two_way instead of one_way , and will update its order from 0 to 1. Because we've defined two PolicyPreWebhooks, this causes the webhook at position 1 to move to position 0. PATCH /policy/{policy_key}/webhook/pre-execution/wake_up_snowflake_db 1 2 3 4 { \"direction\" : \"two_way\" , \"order\" : 1 } Because this PATCH request updated the order of other webhooks, a reordered summary is included under the new_order attribute: Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"resource\" : { \"direction\" : \"two_way\" , \"key\" : \"wake_up_snowflake_db\" , \"name\" : \"Wake up Snowflake DB Webhook\" , \"connection_config\" : \"<TRUNCATED>\" , \"order\" : 1 }, \"new_order\" : [ { \"key\" : \"prep_systems_webhook\" , \"order\" : 0 }, { \"key\" : \"wake_up_snowflake_db\" , \"order\" : 1 } ] } Similarly, to update your a post-execution webhook on an execution policy, use the following endpoint: 1 PATCH /policy/{policy_key}/webhook/post_execution/{post_execution_key} See API docs for more information on how to PATCH a PolicyPreWebhook and how to PATCH a PolicyPostWebhook .","title":"Update a single webhook"},{"location":"guides/policy_webhooks/#webhook-request-format","text":"Before and after running access or erasure requests, Fides will send requests to any configured webhooks in sequential order with the following request body: POST {user-defined URL} 1 2 3 4 5 6 7 8 9 { \"privacy_request_id\" : \"pri_029832ba-3b84-40f7-8946-82aec6f95448\" , \"direction\" : \"one_way | two_way\" , \"callback_type\" : \"pre | post\" , \"identity\" : { \"email\" : \"customer-1@example.com\" , \"phone_number\" : \"555-5555\" } } These attributes were configured at the time of webhook creation. Known identities are also embedded in the request. For two-way webhooks, Fides includes specific headers to pause request execution while any additional processing takes place 1 2 3 4 { \"reply-to\" : \"/privacy-request/{privacy_request_id}/resume\" , \"reply-to-token\" : \"<jwe_token>\" } To resume, send a request to the reply-to URL with the reply-to-token . The reply-to-token will expire when your Redis cache expires (represented by default_ttl_seconds in your Fides config . When a request expires, it is be given an error status, and requires resubmission.","title":"Webhook request format"},{"location":"guides/policy_webhooks/#webhook-response-format","text":"Your webhook should respond immediately. If more processing time is needed, either make sure it is configured as a one-way webhook, or reply with halt=True if you want to pause execution and wait for any processing to finish. Note that only pre-execution webhooks can pause execution. Responses aren ot expected from one-way webhooks, but two-way webhooks should respond with the following 1 2 3 4 5 6 7 { \"derived_identity\" : { \"email\" : \"customer-1@gmail.com\" , \"phone_number\" : \"555-5555\" }, \"halt\" : \"true | false\" } Derived identity is optional: a returned email or phone number will replace currently known emails or phone numbers.","title":"Webhook response format"},{"location":"guides/policy_webhooks/#resuming-request-execution","text":"Once a paused webhook has completed processing, send a request to the reply-to URL sent in the original request header, along with the reply-to-token auth token. POST privacy_request/{privacy-request-id}/resume 1 2 3 4 5 6 { \"derived_identity\" : { \"email\" : \"customer-1@gmail.com\" , \"phone_number\" : \"555-5555\" } } If there are no derived identities, send an empty {} request body. The reply-to-token is a JWE containing the current webhook ID, scopes to access the callback endpoint, and the datetime the token is issued. Fides unpacks this and resumes the privacy request execution after the specified webhook. The reply-to-token expires after a set amount of time, (the privacy_request_delay_timeout in your Fides config ). Once the Redis cache expires, Fides no longer has the original identity data and the privacy request should be resubmitted","title":"Resuming request execution"},{"location":"guides/query_execution/","text":"Query Execution Graphs and Traversals Fides uses your Datasets to generate a graph of the resources. Based on the identity data you provide, Fides then generates a specific traversal , which is the order of steps that will be taken to fulfill a specific request. The graph supports both directed and non-directed edges using the optional direction parameter on the relation (non-directional edges may be traversed in either direction). You can preview the queries that will be generated or manually control the order of operations by making relations explicitly directional and with the after Collection parameters. If you specify a Collection that can't be reached, Fides generates an error. An example graph In this example there are three databases: a mysql database that stores users and their comments, a postgres DB that stores purchase information, and a mongoDB that stores user accounts. Each of them may have related data that we'd like to retrieve. The Dataset specification looks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 dataset : - fides_key : mongo_1 collections : - name : users fields : - name : _id fidesops_meta : primary_key : True - name : user_name fidesops_meta : identity : username - name : full_name - name : accounts fields : - name : _id fidesops_meta : primary_key : True - name : name fidesops_meta : references : - dataset : mongo_1 name : users.full_name direction : from - name : comments 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dataset : - fides_key : mysql_1 collections : - name : users fields : - name : id fidesops_meta : primary_key : True references : - dataset : postgres_1 field : users.id direction : from - name : internal_id - name : comment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 dataset : - fides_key : postgres_1 collections : - name : purchase_items fields : - name : id fidesops_meta : primary_key : True - name : purchase_id fidesops_meta : references : - dataset : postgres_1 field : purchases.id direction : from - name : amount - name : rating - name : purchases fields : - name : id fidesops_meta : primary_key : True - name : user_id fidesops_meta : references : - dataset : postgres_1 field : users.id - name : amount - name : users fields : - name : id fidesops_meta : primary_key : True - name : email fidesops_meta : identity : email - name : address_id Fides triggers a retrieval with identity data, such as an email address or user ID, that's provided by the user, and will then: Identify the collections that contain the identity data that belong to the user. Find all related records. Use the data to find all connected data. Continue until we've found all related data. For the first step, Fides uses the concept of an identity . In the Fides Dataset specification, any field may be marked with an identity notation: 1 2 3 4 5 6 collection : - name : foo fields : - name : bar fidesop_meta : identity : email Fides will initiate the data retrieval process with provided data that looks like {\"email\": \"user@example.com\", \"username\": \"someone\"} by looking for values in the collection users where email == user@example.com . Note that the names of the provided starter data do not need to match the field names Fides will use this data to search. In the above case, you can also choose to start a search using the username provided value. This would result in enough data to search in both postgres_1.users.email and mongo_1.users.user_name noted in the diagram. How does Fides execute queries? The next step is to follow any links provided in field relationship information. In the abbreviated dataset declarations below, the mongo_1.accounts data contains data related to mongo_1.users . Data can be retrieved from mongo_1.accounts by generating this set of queries: 1 2 3 4 5 6 7 8 9 10 11 # mongo_1 1 . db . users . find ( { \"user_name\" : \"someone\" } , { \"_id\" : 1 , \"full_name\" : 1 } ) 2 . db . accounts . find ( { \"name\" : { \"$in\" :[ < full_name value from ( 1 ) > ] }} , { \"_id\" : 1 , \"comments\" : 1 } ) # postgres_1 3 . select id , address_id from users where email = 'user@example.com' ; 4 . select id , amount from purchases where user_id in [ < id values from ( 3 ) > ] 5 . select id , amount , rating from purchase_items where purchase_id in [ < id values from ( 4 ) > ] # mysql_1 6 . select internal_id , comment from users where id in [ < id values from ( 3 ) > ] Behind the scenes, Fides is creating linked graph using the connections you've specified between your collections to retrieve your data. Notes about Dataset traversals You can define multiple links between collections, which will generate OR queries like SELECT a,b,c from TABLE_1 where name in (values from TABLE\\_2) OR email in (values from TABLE\\_3) . It's an error to specify a collection in your Dataset can't be reached through the relations you've specified. Fides uses your Datasets and your input data to \"solve\" the graph of your collections and how it is traversed. If your Dataset has multiple identity values, you can create a situation where the query behavior depends on the values you provide. In the example above, starting the graph traversal with {\"email\": \"value1\", \"username\":\" value2\"} is valid, but starting with {\"email\": \"value1\"} fails because mongo_1.users is no longer reachable. As shown in the example, you can create queries between Datasets.","title":"Preview Query Execution"},{"location":"guides/query_execution/#query-execution","text":"","title":"Query Execution"},{"location":"guides/query_execution/#graphs-and-traversals","text":"Fides uses your Datasets to generate a graph of the resources. Based on the identity data you provide, Fides then generates a specific traversal , which is the order of steps that will be taken to fulfill a specific request. The graph supports both directed and non-directed edges using the optional direction parameter on the relation (non-directional edges may be traversed in either direction). You can preview the queries that will be generated or manually control the order of operations by making relations explicitly directional and with the after Collection parameters. If you specify a Collection that can't be reached, Fides generates an error.","title":"Graphs and Traversals"},{"location":"guides/query_execution/#an-example-graph","text":"In this example there are three databases: a mysql database that stores users and their comments, a postgres DB that stores purchase information, and a mongoDB that stores user accounts. Each of them may have related data that we'd like to retrieve. The Dataset specification looks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 dataset : - fides_key : mongo_1 collections : - name : users fields : - name : _id fidesops_meta : primary_key : True - name : user_name fidesops_meta : identity : username - name : full_name - name : accounts fields : - name : _id fidesops_meta : primary_key : True - name : name fidesops_meta : references : - dataset : mongo_1 name : users.full_name direction : from - name : comments 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dataset : - fides_key : mysql_1 collections : - name : users fields : - name : id fidesops_meta : primary_key : True references : - dataset : postgres_1 field : users.id direction : from - name : internal_id - name : comment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 dataset : - fides_key : postgres_1 collections : - name : purchase_items fields : - name : id fidesops_meta : primary_key : True - name : purchase_id fidesops_meta : references : - dataset : postgres_1 field : purchases.id direction : from - name : amount - name : rating - name : purchases fields : - name : id fidesops_meta : primary_key : True - name : user_id fidesops_meta : references : - dataset : postgres_1 field : users.id - name : amount - name : users fields : - name : id fidesops_meta : primary_key : True - name : email fidesops_meta : identity : email - name : address_id Fides triggers a retrieval with identity data, such as an email address or user ID, that's provided by the user, and will then: Identify the collections that contain the identity data that belong to the user. Find all related records. Use the data to find all connected data. Continue until we've found all related data. For the first step, Fides uses the concept of an identity . In the Fides Dataset specification, any field may be marked with an identity notation: 1 2 3 4 5 6 collection : - name : foo fields : - name : bar fidesop_meta : identity : email Fides will initiate the data retrieval process with provided data that looks like {\"email\": \"user@example.com\", \"username\": \"someone\"} by looking for values in the collection users where email == user@example.com . Note that the names of the provided starter data do not need to match the field names Fides will use this data to search. In the above case, you can also choose to start a search using the username provided value. This would result in enough data to search in both postgres_1.users.email and mongo_1.users.user_name noted in the diagram.","title":"An example graph"},{"location":"guides/query_execution/#how-does-fides-execute-queries","text":"The next step is to follow any links provided in field relationship information. In the abbreviated dataset declarations below, the mongo_1.accounts data contains data related to mongo_1.users . Data can be retrieved from mongo_1.accounts by generating this set of queries: 1 2 3 4 5 6 7 8 9 10 11 # mongo_1 1 . db . users . find ( { \"user_name\" : \"someone\" } , { \"_id\" : 1 , \"full_name\" : 1 } ) 2 . db . accounts . find ( { \"name\" : { \"$in\" :[ < full_name value from ( 1 ) > ] }} , { \"_id\" : 1 , \"comments\" : 1 } ) # postgres_1 3 . select id , address_id from users where email = 'user@example.com' ; 4 . select id , amount from purchases where user_id in [ < id values from ( 3 ) > ] 5 . select id , amount , rating from purchase_items where purchase_id in [ < id values from ( 4 ) > ] # mysql_1 6 . select internal_id , comment from users where id in [ < id values from ( 3 ) > ] Behind the scenes, Fides is creating linked graph using the connections you've specified between your collections to retrieve your data.","title":"How does Fides execute queries?"},{"location":"guides/query_execution/#notes-about-dataset-traversals","text":"You can define multiple links between collections, which will generate OR queries like SELECT a,b,c from TABLE_1 where name in (values from TABLE\\_2) OR email in (values from TABLE\\_3) . It's an error to specify a collection in your Dataset can't be reached through the relations you've specified. Fides uses your Datasets and your input data to \"solve\" the graph of your collections and how it is traversed. If your Dataset has multiple identity values, you can create a situation where the query behavior depends on the values you provide. In the example above, starting the graph traversal with {\"email\": \"value1\", \"username\":\" value2\"} is valid, but starting with {\"email\": \"value1\"} fails because mongo_1.users is no longer reachable. As shown in the example, you can create queries between Datasets.","title":"Notes about Dataset traversals"},{"location":"guides/reporting/","text":"Report on Privacy Requests Overview The reporting feature allows you to fetch information about privacy requests. You can opt for high-level status information, or get more detailed information about the status of the requests on each of your collections. View high-level statuses This request displays concise, high-level information for all your privacy requests including their status and related timestamps. View he API docs here . GET api/v1/privacy-request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"items\" : [ { \"id\" : \"pri_5f4feff5-fb60-4286-82bd-7e0748ce90ac\" , \"created_at\" : \"2021-10-04T17:36:32.223287+00:00\" , \"started_processing_at\" : \"2021-10-04T17:36:37.248880+00:00\" , \"finished_processing_at\" : \"2021-10-04T17:36:37.263121+00:00\" , \"status\" : \"pending\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } View a single privacy request Use the id query param to view the high level status of a single privacy request. 1 GET api/v1/privacy-request?request_id=<privacy_request_id> If an external_id was provided at request creation, we can also track the privacy request using: 1 GET api/v1/privacy-request?external_id=<external_id> These parameters will return matching privacy requests based on startswith matches. Filtering options Use the following query params to further filter your privacy requests. Filters can be chained, for example, 1 GET api/v1/privacy-request?created_gt=2021-10-01&created_lt=2021-10-05&status=pending id status (one of in_processing , pending , paused , complete , or error ) created_lt created_gt started_lt started_gt completed_lt completed_gt errored_lt errored_gt You can filter for multiple statuses by repeating the status query param: 1 GET api/v1/privacy-request?status=paused&status=complete View privacy request logs To view all the execution logs for a privacy request, visit /api/v1/privacy-request/{privacy_request_id}/logs . Embedded logs in the previous endpoints are truncated at 50 logs. View the API docs here . View a request's identity data Use the optional include_identities query param to include all identity data that was submitted for the privacy request. Due to the way Fides stores identity data, this data will expire automatically according to the FIDES__REDIS__DEFAULT_TTL_SECONDS variable in your Fides config . If the identity data fetched by include_identities has expired, an empty JSON dictionary will be returned. View individual request log details The verbose query parameter will display more details about individual collections visited as part of the privacy request, along with individual statuses. Individual collection statuses include in_processing , retrying , complete or error . You may see multiple logs for each collection as they reach different steps in the lifecycle. The verbose parameter will embed a \u201cresults\u201d key in the response, with both audit logs containing information about the overall request, as well as execution logs grouped by dataset name. In the example below, there are two datasets: my-mongo-db and my-postgres-db . There are two execution logs for my-mongo-db (when the flights collection is starting execution, and when the flights collection has finished), and two execution logs for my-postgres-db (when the order collection is starting and finishing execution). The fields_affected are the fields that were potentially returned or masked based on the Rules you've specified on the execution policy. The embedded execution logs are automatically truncated at 50 logs. To view the entire list of logs, visit the execution logs endpoint separately. \"Request approved\" and \"Request finished\" audit logs are also included in the response. GET api/v1/privacy-request?request_id={privacy_request_id}&verbose=True 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 { \"items\" : [ { \"id\" : \"pri_2e0655c3-7a76-425e-8c4c-52fee32ce14b\" , \"created_at\" : \"2022-02-28T16:38:03.878898+00:00\" , \"started_processing_at\" : \"2022-02-28T16:38:04.021763+00:00\" , \"finished_processing_at\" : \"2022-02-28T16:38:06.211547+00:00\" , \"status\" : \"complete\" , \"external_id\" : null , \"results\" : { \"Request approved\" : [ { \"collection_name\" : null , \"fields_affected\" : null , \"message\" : \"\" , \"action_type\" : null , \"status\" : \"approved\" , \"updated_at\" : \"2022-08-11T14:03:37.679732+00:00\" , \"user_id\" : \"system\" } ], \"my-mongo-db\" : [ { \"collection_name\" : \"flights\" , \"fields_affected\" : [], \"message\" : \"starting\" , \"action_type\" : \"access\" , \"status\" : \"in_processing\" , \"updated_at\" : \"2022-02-28T16:38:04.668513+00:00\" }, { \"collection_name\" : \"flights\" , \"fields_affected\" : [ { \"path\" : \"mongo_test:flights:passenger_information.full_name\" , \"field_name\" : \"passenger_information.full_name\" , \"data_categories\" : [ \"user.name\" ] } ], \"message\" : \"success\" , \"action_type\" : \"access\" , \"status\" : \"complete\" , \"updated_at\" : \"2022-02-28T16:38:04.727094+00:00\" , \"user_id\" : null } ], \"my-postgres-db\" : [ { \"collection_name\" : \"order\" , \"fields_affected\" : [], \"message\" : \"starting\" , \"action_type\" : \"access\" , \"status\" : \"in_processing\" , \"updated_at\" : \"2022-02-28T16:38:04.668513+00:00\" }, { \"collection_name\" : \"order\" , \"fields_affected\" : [ { \"path\" : \"order.customer_name\" , \"field_name\" : \"name\" , \"data_categories\" : [ \"user.name\" ] } ], \"message\" : \"success\" , \"action_type\" : \"access\" , \"status\" : \"complete\" , \"updated_at\" : \"2022-02-28T16:39:04.668513+00:00\" , \"user_id\" : null } ] }, \"Request finished\" : [ { \"collection_name\" : null , \"fields_affected\" : null , \"message\" : \"\" , \"action_type\" : null , \"status\" : \"finished\" , \"updated_at\" : \"2022-08-11T14:04:29.611878+00:00\" , \"user_id\" : \"system\" } ] } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } Download all privacy requests as a CSV To get all privacy requests in CSV format, use the download_csv query param: GET api/v1/privacy-request/?download_csv=True 1 2 Time received,Subject identity,Policy key,Request status,Reviewer,Time approved/denied 2022-03-14 16:53:28.869258+00:00,{'email': 'customer-1@example.com'},my_primary_policy,complete,fid_16ffde2f-613b-4f79-bbae-41420b0f836b,2022-03-14 16:54:08.804283+00:00 Paused or failed request details A privacy request may pause when manual input is needed from the user, or it might fail for various reasons on a specific collection. To retrieve information to resume or retry a privacy request, the following endpoint is available: 1 GET api/v1/privacy-request?request_id=<privacy_request_id> Paused access request example The request below is in a paused state as it waits on manual input from the user to proceed. Looking at the stopped_collection_details key shows the request paused execution during the access step of the manual_key:filing_cabinet collection. The action_needed.locators field shows the user they should fetch the record in the filing cabinet with a customer_id of 72909 , and pull the authorized_user , customer_id , id , and payment_card_id fields from that record. These values should be manually uploaded to the resume_endpoint . See the manual data guides for more information on resuming a paused access request. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 { \"items\" : [ { \"id\" : \"pri_ed4a6b7d-deab-489a-9a9f-9c2b19cd0713\" , \"created_at\" : \"2022-06-06T20:12:28.809815+00:00\" , \"started_processing_at\" : \"2022-06-06T20:12:28.986462+00:00\" , ... , \"stopped_collection_details\" : { \"step\" : \"access\" , \"collection\" : \"manual_key:filing_cabinet\" , \"action_needed\" : [ { \"locators\" : { \"customer_id\" : [ 72909 ] }, \"get\" : [ \"authorized_user\" , \"customer_id\" , \"id\" , \"payment_card_id\" ], \"update\" : null } ] }, \"resume_endpoint\" : \"/privacy-request/pri_ed4a6b7d-deab-489a-9a9f-9c2b19cd0713/manual_input\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } Paused erasure request example The request below is in a paused state for user to confirm they've masked the appropriate data before proceeding. The stopped_collection_details shows that the request paused execution during the erasure step of the manual_key:filing_cabinet collection. Looking at action_needed.locators field shows that the user should find the record in the filing cabinet with an id of 2, and replace its authorized_user with None . A confirmation of the masked records count should be uploaded to the resume_endpoint . See the manual data guides for more information on resuming a paused erasure request. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 { \"items\" : [ { \"id\" : \"pri_59ea0129-fc6d-4a12-a5bd-2ee647bf5cec\" , \"created_at\" : \"2022-06-06T20:22:05.436361+00:00\" , \"started_processing_at\" : \"2022-06-06T20:22:05.473280+00:00\" , \"finished_processing_at\" : null , \"status\" : \"paused\" , ... , \"stopped_collection_details\" : { \"step\" : \"erasure\" , \"collection\" : \"manual_key:filing_cabinet\" , \"action_needed\" : [ { \"locators\" : { \"id\" : 2 }, \"get\" : null , \"update\" : { \"authorized_user\" : null } } ] }, \"resume_endpoint\" : \"/privacy-request/pri_59ea0129-fc6d-4a12-a5bd-2ee647bf5cec/erasure_confirm\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } Failed request example The below request is an error state because something failed in the erasure step of the postgres_dataset:payment_card collection. After troubleshooting the issues with your postgres connection, resume the request with a POST to the resume_endpoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"items\" : [ { \"id\" : \"pri_59ea0129-fc6d-4a12-a5bd-2ee647bf5cec\" , \"created_at\" : \"2022-06-06T20:22:05.436361+00:00\" , \"started_processing_at\" : \"2022-06-06T20:22:05.473280+00:00\" , \"finished_processing_at\" : null , \"status\" : \"error\" , ... , \"stopped_collection_details\" : { \"step\" : \"erasure\" , \"collection\" : \"postgres_dataset:payment_card\" , \"action_needed\" : null }, \"resume_endpoint\" : \"/privacy-request/pri_59ea0129-fc6d-4a12-a5bd-2ee647bf5cec/retry\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"Report on Privacy Requests"},{"location":"guides/reporting/#report-on-privacy-requests","text":"","title":"Report on Privacy Requests"},{"location":"guides/reporting/#overview","text":"The reporting feature allows you to fetch information about privacy requests. You can opt for high-level status information, or get more detailed information about the status of the requests on each of your collections.","title":"Overview"},{"location":"guides/reporting/#view-high-level-statuses","text":"This request displays concise, high-level information for all your privacy requests including their status and related timestamps. View he API docs here . GET api/v1/privacy-request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"items\" : [ { \"id\" : \"pri_5f4feff5-fb60-4286-82bd-7e0748ce90ac\" , \"created_at\" : \"2021-10-04T17:36:32.223287+00:00\" , \"started_processing_at\" : \"2021-10-04T17:36:37.248880+00:00\" , \"finished_processing_at\" : \"2021-10-04T17:36:37.263121+00:00\" , \"status\" : \"pending\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"View high-level statuses"},{"location":"guides/reporting/#view-a-single-privacy-request","text":"Use the id query param to view the high level status of a single privacy request. 1 GET api/v1/privacy-request?request_id=<privacy_request_id> If an external_id was provided at request creation, we can also track the privacy request using: 1 GET api/v1/privacy-request?external_id=<external_id> These parameters will return matching privacy requests based on startswith matches.","title":"View a single privacy request"},{"location":"guides/reporting/#filtering-options","text":"Use the following query params to further filter your privacy requests. Filters can be chained, for example, 1 GET api/v1/privacy-request?created_gt=2021-10-01&created_lt=2021-10-05&status=pending id status (one of in_processing , pending , paused , complete , or error ) created_lt created_gt started_lt started_gt completed_lt completed_gt errored_lt errored_gt You can filter for multiple statuses by repeating the status query param: 1 GET api/v1/privacy-request?status=paused&status=complete","title":"Filtering options"},{"location":"guides/reporting/#view-privacy-request-logs","text":"To view all the execution logs for a privacy request, visit /api/v1/privacy-request/{privacy_request_id}/logs . Embedded logs in the previous endpoints are truncated at 50 logs. View the API docs here .","title":"View privacy request logs"},{"location":"guides/reporting/#view-a-requests-identity-data","text":"Use the optional include_identities query param to include all identity data that was submitted for the privacy request. Due to the way Fides stores identity data, this data will expire automatically according to the FIDES__REDIS__DEFAULT_TTL_SECONDS variable in your Fides config . If the identity data fetched by include_identities has expired, an empty JSON dictionary will be returned.","title":"View a request's identity data"},{"location":"guides/reporting/#view-individual-request-log-details","text":"The verbose query parameter will display more details about individual collections visited as part of the privacy request, along with individual statuses. Individual collection statuses include in_processing , retrying , complete or error . You may see multiple logs for each collection as they reach different steps in the lifecycle. The verbose parameter will embed a \u201cresults\u201d key in the response, with both audit logs containing information about the overall request, as well as execution logs grouped by dataset name. In the example below, there are two datasets: my-mongo-db and my-postgres-db . There are two execution logs for my-mongo-db (when the flights collection is starting execution, and when the flights collection has finished), and two execution logs for my-postgres-db (when the order collection is starting and finishing execution). The fields_affected are the fields that were potentially returned or masked based on the Rules you've specified on the execution policy. The embedded execution logs are automatically truncated at 50 logs. To view the entire list of logs, visit the execution logs endpoint separately. \"Request approved\" and \"Request finished\" audit logs are also included in the response. GET api/v1/privacy-request?request_id={privacy_request_id}&verbose=True 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 { \"items\" : [ { \"id\" : \"pri_2e0655c3-7a76-425e-8c4c-52fee32ce14b\" , \"created_at\" : \"2022-02-28T16:38:03.878898+00:00\" , \"started_processing_at\" : \"2022-02-28T16:38:04.021763+00:00\" , \"finished_processing_at\" : \"2022-02-28T16:38:06.211547+00:00\" , \"status\" : \"complete\" , \"external_id\" : null , \"results\" : { \"Request approved\" : [ { \"collection_name\" : null , \"fields_affected\" : null , \"message\" : \"\" , \"action_type\" : null , \"status\" : \"approved\" , \"updated_at\" : \"2022-08-11T14:03:37.679732+00:00\" , \"user_id\" : \"system\" } ], \"my-mongo-db\" : [ { \"collection_name\" : \"flights\" , \"fields_affected\" : [], \"message\" : \"starting\" , \"action_type\" : \"access\" , \"status\" : \"in_processing\" , \"updated_at\" : \"2022-02-28T16:38:04.668513+00:00\" }, { \"collection_name\" : \"flights\" , \"fields_affected\" : [ { \"path\" : \"mongo_test:flights:passenger_information.full_name\" , \"field_name\" : \"passenger_information.full_name\" , \"data_categories\" : [ \"user.name\" ] } ], \"message\" : \"success\" , \"action_type\" : \"access\" , \"status\" : \"complete\" , \"updated_at\" : \"2022-02-28T16:38:04.727094+00:00\" , \"user_id\" : null } ], \"my-postgres-db\" : [ { \"collection_name\" : \"order\" , \"fields_affected\" : [], \"message\" : \"starting\" , \"action_type\" : \"access\" , \"status\" : \"in_processing\" , \"updated_at\" : \"2022-02-28T16:38:04.668513+00:00\" }, { \"collection_name\" : \"order\" , \"fields_affected\" : [ { \"path\" : \"order.customer_name\" , \"field_name\" : \"name\" , \"data_categories\" : [ \"user.name\" ] } ], \"message\" : \"success\" , \"action_type\" : \"access\" , \"status\" : \"complete\" , \"updated_at\" : \"2022-02-28T16:39:04.668513+00:00\" , \"user_id\" : null } ] }, \"Request finished\" : [ { \"collection_name\" : null , \"fields_affected\" : null , \"message\" : \"\" , \"action_type\" : null , \"status\" : \"finished\" , \"updated_at\" : \"2022-08-11T14:04:29.611878+00:00\" , \"user_id\" : \"system\" } ] } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"View individual request log details"},{"location":"guides/reporting/#download-all-privacy-requests-as-a-csv","text":"To get all privacy requests in CSV format, use the download_csv query param: GET api/v1/privacy-request/?download_csv=True 1 2 Time received,Subject identity,Policy key,Request status,Reviewer,Time approved/denied 2022-03-14 16:53:28.869258+00:00,{'email': 'customer-1@example.com'},my_primary_policy,complete,fid_16ffde2f-613b-4f79-bbae-41420b0f836b,2022-03-14 16:54:08.804283+00:00","title":"Download all privacy requests as a CSV"},{"location":"guides/reporting/#paused-or-failed-request-details","text":"A privacy request may pause when manual input is needed from the user, or it might fail for various reasons on a specific collection. To retrieve information to resume or retry a privacy request, the following endpoint is available: 1 GET api/v1/privacy-request?request_id=<privacy_request_id>","title":"Paused or failed request details"},{"location":"guides/reporting/#paused-access-request-example","text":"The request below is in a paused state as it waits on manual input from the user to proceed. Looking at the stopped_collection_details key shows the request paused execution during the access step of the manual_key:filing_cabinet collection. The action_needed.locators field shows the user they should fetch the record in the filing cabinet with a customer_id of 72909 , and pull the authorized_user , customer_id , id , and payment_card_id fields from that record. These values should be manually uploaded to the resume_endpoint . See the manual data guides for more information on resuming a paused access request. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 { \"items\" : [ { \"id\" : \"pri_ed4a6b7d-deab-489a-9a9f-9c2b19cd0713\" , \"created_at\" : \"2022-06-06T20:12:28.809815+00:00\" , \"started_processing_at\" : \"2022-06-06T20:12:28.986462+00:00\" , ... , \"stopped_collection_details\" : { \"step\" : \"access\" , \"collection\" : \"manual_key:filing_cabinet\" , \"action_needed\" : [ { \"locators\" : { \"customer_id\" : [ 72909 ] }, \"get\" : [ \"authorized_user\" , \"customer_id\" , \"id\" , \"payment_card_id\" ], \"update\" : null } ] }, \"resume_endpoint\" : \"/privacy-request/pri_ed4a6b7d-deab-489a-9a9f-9c2b19cd0713/manual_input\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"Paused access request example"},{"location":"guides/reporting/#paused-erasure-request-example","text":"The request below is in a paused state for user to confirm they've masked the appropriate data before proceeding. The stopped_collection_details shows that the request paused execution during the erasure step of the manual_key:filing_cabinet collection. Looking at action_needed.locators field shows that the user should find the record in the filing cabinet with an id of 2, and replace its authorized_user with None . A confirmation of the masked records count should be uploaded to the resume_endpoint . See the manual data guides for more information on resuming a paused erasure request. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 { \"items\" : [ { \"id\" : \"pri_59ea0129-fc6d-4a12-a5bd-2ee647bf5cec\" , \"created_at\" : \"2022-06-06T20:22:05.436361+00:00\" , \"started_processing_at\" : \"2022-06-06T20:22:05.473280+00:00\" , \"finished_processing_at\" : null , \"status\" : \"paused\" , ... , \"stopped_collection_details\" : { \"step\" : \"erasure\" , \"collection\" : \"manual_key:filing_cabinet\" , \"action_needed\" : [ { \"locators\" : { \"id\" : 2 }, \"get\" : null , \"update\" : { \"authorized_user\" : null } } ] }, \"resume_endpoint\" : \"/privacy-request/pri_59ea0129-fc6d-4a12-a5bd-2ee647bf5cec/erasure_confirm\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"Paused erasure request example"},{"location":"guides/reporting/#failed-request-example","text":"The below request is an error state because something failed in the erasure step of the postgres_dataset:payment_card collection. After troubleshooting the issues with your postgres connection, resume the request with a POST to the resume_endpoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"items\" : [ { \"id\" : \"pri_59ea0129-fc6d-4a12-a5bd-2ee647bf5cec\" , \"created_at\" : \"2022-06-06T20:22:05.436361+00:00\" , \"started_processing_at\" : \"2022-06-06T20:22:05.473280+00:00\" , \"finished_processing_at\" : null , \"status\" : \"error\" , ... , \"stopped_collection_details\" : { \"step\" : \"erasure\" , \"collection\" : \"postgres_dataset:payment_card\" , \"action_needed\" : null }, \"resume_endpoint\" : \"/privacy-request/pri_59ea0129-fc6d-4a12-a5bd-2ee647bf5cec/retry\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"Failed request example"},{"location":"guides/utility_scripts/","text":"Configuring Fides via utility functions Fides is a complex product, and accurate configuration can be hard. Rather than using the built-in Fides postman collection, you may find it faster to build configuration scripts in Python, using the primitives provided in the scripts/setup/ directory. Available functions The available functions are listed below: Function setup.authentication.get_auth_header setup.healthcheck.check_health setup.s3_storage.create_s3_storage setup.policy.create_policy setup.rule.create_rule setup.rule_target.create_rule_target setup.email.create_email_integration setup.rule.create_rule_target setup.postgres_connector.create_postgres_connector setup.mongodb_connector.create_mongodb_connector setup.privacy_request.create_privacy_request setup.subject_identity_verification.verify_subject_identity Each script uses the Fides API to create its corresponding primitive object in Fides config. Secrets management Some third party integrations require secrets to grant access. Custom scripts are configured to read these secrets as constant variables from a scripts/setup/secrets.py file. Due to its sensitive nature, this file is not supplied in the repository, and should instead be stored somewhere more secure such as a password manager. It must be a valid Python file and the format of the secrets should be: 1 2 3 4 5 6 7 8 9 10 AWS_ACCESS_KEY_ID = \"\" AWS_ACCESS_SECRET_ID = \"\" MAILCHIMP_SECRETS = { \"domain\" : \"\" , \"username\" : \"\" , \"api_key\" : \"\" , } MAILGUN_API_KEY = \"\" Writing custom scripts Custom scripts can be written in the style of scripts/setup/example_script.py , where each method is called and given the requisite auth_header obtained from the get_auth_header primitive. Custom scripts should live in the scripts/ directory in the root to ensure they are runnable with the nox command detailed below. Invoking custom scripts Custom scripts can be invoked using the run_script nox command, and passing the script name as an argument. For example: nox -s run_script -- example_script will run the example script. Please note that custom scripts will not run the Fides webserver, and should be invoked after the nox -s dev command (or similar) has been run.","title":"Configuring Fides with Scripts"},{"location":"guides/utility_scripts/#configuring-fides-via-utility-functions","text":"Fides is a complex product, and accurate configuration can be hard. Rather than using the built-in Fides postman collection, you may find it faster to build configuration scripts in Python, using the primitives provided in the scripts/setup/ directory.","title":"Configuring Fides via utility functions"},{"location":"guides/utility_scripts/#available-functions","text":"The available functions are listed below: Function setup.authentication.get_auth_header setup.healthcheck.check_health setup.s3_storage.create_s3_storage setup.policy.create_policy setup.rule.create_rule setup.rule_target.create_rule_target setup.email.create_email_integration setup.rule.create_rule_target setup.postgres_connector.create_postgres_connector setup.mongodb_connector.create_mongodb_connector setup.privacy_request.create_privacy_request setup.subject_identity_verification.verify_subject_identity Each script uses the Fides API to create its corresponding primitive object in Fides config.","title":"Available functions"},{"location":"guides/utility_scripts/#secrets-management","text":"Some third party integrations require secrets to grant access. Custom scripts are configured to read these secrets as constant variables from a scripts/setup/secrets.py file. Due to its sensitive nature, this file is not supplied in the repository, and should instead be stored somewhere more secure such as a password manager. It must be a valid Python file and the format of the secrets should be: 1 2 3 4 5 6 7 8 9 10 AWS_ACCESS_KEY_ID = \"\" AWS_ACCESS_SECRET_ID = \"\" MAILCHIMP_SECRETS = { \"domain\" : \"\" , \"username\" : \"\" , \"api_key\" : \"\" , } MAILGUN_API_KEY = \"\"","title":"Secrets management"},{"location":"guides/utility_scripts/#writing-custom-scripts","text":"Custom scripts can be written in the style of scripts/setup/example_script.py , where each method is called and given the requisite auth_header obtained from the get_auth_header primitive. Custom scripts should live in the scripts/ directory in the root to ensure they are runnable with the nox command detailed below.","title":"Writing custom scripts"},{"location":"guides/utility_scripts/#invoking-custom-scripts","text":"Custom scripts can be invoked using the run_script nox command, and passing the script name as an argument. For example: nox -s run_script -- example_script will run the example script. Please note that custom scripts will not run the Fides webserver, and should be invoked after the nox -s dev command (or similar) has been run.","title":"Invoking custom scripts"},{"location":"installation/configuration/","text":"Configuration The Fides application configuration variables are provided in a fides.toml file. Fides will use the first config file it reads from the following locations, in order: At the path specified using the config file argument passed through the CLI At the path specified by the FIDES__CONFIG_PATH environment variable In the current working directory In the parent working directory Two directories up from the current working directory The parent directory followed by /.fides The user's home ( ~ ) directory Fides can also run exclusively via environment variables. These can be used in tandem with a toml configuration file, with the environment variables overriding the toml configuration values. Configuration file After initializing Fides, a default configuration file will be generated and placed within the .fides directory: fides.toml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 [database] server = \"fides-db\" user = \"postgres\" password = \"fides\" port = \"5432\" db = \"fides\" [logging] level = \"INFO\" [cli] server_host = \"localhost\" server_port = 8080 analytics_id = \"\" [user] analytics_opt_out = false [redis] host = \"redis\" password = \"testpassword\" port = 6379 charset = \"utf8\" default_ttl_seconds = 604800 db_index = 0 enabled = true ssl = false ssl_cert_reqs = \"required\" [security] app_encryption_key = \"\" cors_origins = [ \"http://localhost\" , \"http://localhost:8080\" , \"http://localhost:3000\" , \"http://localhost:3001\" ,] encoding = \"UTF-8\" oauth_root_client_id = \"adminid\" oauth_root_client_secret = \"adminsecret\" drp_jwt_secret = \"secret\" root_username = \"root_user\" root_password = \"Testpassword1!\" [execution] masking_strict = true require_manual_request_approval = false task_retry_backoff = 1 subject_identity_verification_required = false task_retry_count = 0 task_retry_delay = 1 worker_enabled = false [admin_ui] enabled = true Configuration variable reference The fides.toml file should specify the following variables: Posgtres database Name Type Default Description user String postgres The database user with which to login to the application database. password String fides The password with which to login to the application database. server String fides-db The hostname of the Postgres database server. port String 5432 The port at which the Postgres database will be accessible. db String fides The name of the Postgres database. test_db String \"\" Used instead of the db config when the FIDES_TEST_MODE environment variable is set to True , to avoid overwriting production data. Redis cache Name Type Default Description host string N/A The network address for the application Redis cache. port int 6379 The port at which the application cache will be accessible. user string N/A The user with which to login to the Redis cache. password string N/A The password with which to login to the Redis cache. db_index int N/A The application will use this index in the Redis cache to cache data. connection_url string N/A A full connection URL to the Redis cache. If not specified, this URL is automatically assembled from the host , port , password and db_index specified above. default_ttl_seconds int 604800 The number of seconds for which data will live in Redis before automatically expiring. enabled bool True Whether the application's Redis cache should be enabled. Only set to false for certain narrow uses of the application. Logging Name Type Default Description destination String \"\" The output location for log files. Accepts any valid file path. If left unset, log entries are printed to stdout and log files are not produced. level Enum (String) INFO The minimum log entry level to produce. Also accepts TRACE , DEBUG , WARNING , ERROR , or CRITICAL (case insensitive). serialization Enum (String) \"\" The format with which to produce log entries. If left unset, produces log entries formatted using the internal custom formatter. Also accepts \"JSON\" (case insensitive). CLI Name Type Default Description local_mode Boolean False When set to True , forbids the Fides CLI from making calls to the Fides webserver. server_host String localhost The hostname of the Fides webserver. server_protocol String http The protocol used by the Fides webserver. server_port Integer The optional port of the Fides webserver. analytics_id String \"\" A fully anonymized unique identifier that is automatically generated by the application and stored in the toml file. Security Name Type Default Description app_encryption_key string N/A The key used to sign Fides API access tokens. cors_origins List[AnyHttpUrl] N/A A list of pre-approved addresses of clients allowed to communicate with the Fides application server. oauth_root_client_id string N/A The value used to identify the Fides application root API client. oauth_root_client_secret string N/A The secret value used to authenticate the Fides application root API client. oauth_access_token_expire_minutes int 11520 The time for which Fides API tokens will be valid. root_username string None If set, this can be used in conjunction with root_password to log in without first creating a user in the database. root_password string None If set, this can be used in conjunction with root_username to log in without first creating a user in the database. root_user_scopes list of strings All available scopes The scopes granted to the root user when logging in with root_username and root_password . Execution Name Type Default Description privacy_request_delay_timeout int 3600 The amount of time to wait for actions which delay privacy requests (e.g., pre- and post-processing webhooks). task_retry_count int 0 The number of times a failed request will be retried. task_retry_delay int 1 The delays between retries in seconds. task_retry_backoff int 1 The backoff factor for retries, to space out repeated retries. subject_identity_verification_required bool False Whether privacy requests require user identity verification. require_manual_request_approval bool False Whether privacy requests require explicit approval to execute. masking_strict bool True If set to True , only use UPDATE requests to mask data. If False , Fides will use any defined DELETE or GDPR DELETE endpoints to remove PII, which may extend beyond the specific data categories that configured in your execution policy. celery_config_path string N/A An optional override for the Celery configuration file path. worker_enabled bool True By default, Fides uses a dedicated Celery worker to process privacy requests asynchronously. Setting worker_enabled to False will run the worker on the same node as the webserver. User Name Type Default Description encryption_key String \"\" An arbitrary string used to encrypt the user data stored in the database. Encryption is implemented using PGP. analytics_opt_out Boolean \"\" When set to true , prevents sending anonymous analytics data to Ethyca. Credentials The credentials section uses custom keys which can be referenced in certain commands. Name Type Description my_postgres.connection_string String Sets the connection_string for my_postgres database credentials my_aws.aws_access_key_id String Sets the aws_access_key_id for my_aws credentials my_aws.aws_secret_access_key String Sets the aws_secret_access_key for my_aws credentials my_aws.region_name String Sets the region_name for my_aws credentials my_okta.orgUrl String Sets the orgUrl for my_okta credentials my_okta.token String Sets the token for my_okta credentials Admin UI Name Type Default Description enabled bool True Toggle whether the Admin UI is served from / . Set environment variables To configure environment variables for Fides, the following pattern is used: 1 FIDES__<SECTION>__<VAR_NAME> For example, to set the server_url on a Linux machine: 1 2 3 export FIDES__CLI__SERVER_HOST = \"localhost\" export FIDES__CLI__SERVER_PORT = \"8080\" export FIDES__CLI__SERVER_PROTOCOL = \"http\" Additional environment variables The following environment variables are not included in the default fides.toml configuration, but may be set in your environment: ENV Variable Default Description FIDES__LOG_PII False If True , PII values will display unmasked in log output. This variable should always be set to \"False\" in production systems. FIDES__HOT_RELOAD False If True , the Fides server will reload code changes without needing to restart the server. This variable should always be set to False in production systems. FIDES__DEV_MODE False If True , the Fides server will log error tracebacks, and log details of third party requests. This variable should always be set to False in production systems. FIDES_CONFIG_PATH None If this is set to a path, that path will be used to load .toml files first. Any .toml files on this path will override any installed .toml files. FIDES__DATABASE__SQLALCHEMY_DATABASE_URI None An optional override for the URI used for the database connection, in the form of postgresql://<user>:<password>@<hostname>:<port>/<database> . Celery configuration Fides uses Celery for asynchronous task management. The celery.toml file provided contains a brief configuration reference for managing Celery variables. By default, Fides will look for this file in the root directory of your application, but this location can be optionally overridden by specifying an alternate celery_config_path in your fides.toml . For a full list of possible variable overrides, see the Celery configuration documentation. Example celery.toml 1 2 3 default_queue_name = \"fides\" broker_url = \"redis://:testpassword@redis:6379/1\" result_backend = \"redis://:testpassword@redis:6379/1\" Celery Variable Example Description default_queue_name fides A name to use for your Celery task queue. broker_url redis://:testpassword@redis:6379/1 The datastore to use as a Celery broker , which maintains an ordered list of asynchronous tasks to execute. If not specified, Fides will default to the connection_url or Redis config values specified in your fides.toml . result_backend redis://:testpassword@redis:6379/1 The backend datastore where Celery will store results from asynchronously processed tasks. If not specified, Fides will default to the connection_url or Redis config values specified in your fides.toml . View a live configuration You can view the currently running configuration of your application with the following request: 1 GET /api/v1/config Fides will filter out any sensitive configuration variables. The full list of variables deemed safe to return is: Postgres database server user port db test_db Redis cache host port charset decode_responses default_ttl_seconds db_index Security settings cors_origins encoding oauth_access_token_expire_minutes Execution settings task_retry_count task_retry_delay task_retry_backoff require_manual_request_approval masking_strict For more information, see the API docs .","title":"Configuration"},{"location":"installation/configuration/#configuration","text":"The Fides application configuration variables are provided in a fides.toml file. Fides will use the first config file it reads from the following locations, in order: At the path specified using the config file argument passed through the CLI At the path specified by the FIDES__CONFIG_PATH environment variable In the current working directory In the parent working directory Two directories up from the current working directory The parent directory followed by /.fides The user's home ( ~ ) directory Fides can also run exclusively via environment variables. These can be used in tandem with a toml configuration file, with the environment variables overriding the toml configuration values.","title":"Configuration"},{"location":"installation/configuration/#configuration-file","text":"After initializing Fides, a default configuration file will be generated and placed within the .fides directory: fides.toml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 [database] server = \"fides-db\" user = \"postgres\" password = \"fides\" port = \"5432\" db = \"fides\" [logging] level = \"INFO\" [cli] server_host = \"localhost\" server_port = 8080 analytics_id = \"\" [user] analytics_opt_out = false [redis] host = \"redis\" password = \"testpassword\" port = 6379 charset = \"utf8\" default_ttl_seconds = 604800 db_index = 0 enabled = true ssl = false ssl_cert_reqs = \"required\" [security] app_encryption_key = \"\" cors_origins = [ \"http://localhost\" , \"http://localhost:8080\" , \"http://localhost:3000\" , \"http://localhost:3001\" ,] encoding = \"UTF-8\" oauth_root_client_id = \"adminid\" oauth_root_client_secret = \"adminsecret\" drp_jwt_secret = \"secret\" root_username = \"root_user\" root_password = \"Testpassword1!\" [execution] masking_strict = true require_manual_request_approval = false task_retry_backoff = 1 subject_identity_verification_required = false task_retry_count = 0 task_retry_delay = 1 worker_enabled = false [admin_ui] enabled = true","title":"Configuration file"},{"location":"installation/configuration/#configuration-variable-reference","text":"The fides.toml file should specify the following variables:","title":"Configuration variable reference"},{"location":"installation/configuration/#posgtres-database","text":"Name Type Default Description user String postgres The database user with which to login to the application database. password String fides The password with which to login to the application database. server String fides-db The hostname of the Postgres database server. port String 5432 The port at which the Postgres database will be accessible. db String fides The name of the Postgres database. test_db String \"\" Used instead of the db config when the FIDES_TEST_MODE environment variable is set to True , to avoid overwriting production data.","title":"Posgtres database"},{"location":"installation/configuration/#redis-cache","text":"Name Type Default Description host string N/A The network address for the application Redis cache. port int 6379 The port at which the application cache will be accessible. user string N/A The user with which to login to the Redis cache. password string N/A The password with which to login to the Redis cache. db_index int N/A The application will use this index in the Redis cache to cache data. connection_url string N/A A full connection URL to the Redis cache. If not specified, this URL is automatically assembled from the host , port , password and db_index specified above. default_ttl_seconds int 604800 The number of seconds for which data will live in Redis before automatically expiring. enabled bool True Whether the application's Redis cache should be enabled. Only set to false for certain narrow uses of the application.","title":"Redis cache"},{"location":"installation/configuration/#logging","text":"Name Type Default Description destination String \"\" The output location for log files. Accepts any valid file path. If left unset, log entries are printed to stdout and log files are not produced. level Enum (String) INFO The minimum log entry level to produce. Also accepts TRACE , DEBUG , WARNING , ERROR , or CRITICAL (case insensitive). serialization Enum (String) \"\" The format with which to produce log entries. If left unset, produces log entries formatted using the internal custom formatter. Also accepts \"JSON\" (case insensitive).","title":"Logging"},{"location":"installation/configuration/#cli","text":"Name Type Default Description local_mode Boolean False When set to True , forbids the Fides CLI from making calls to the Fides webserver. server_host String localhost The hostname of the Fides webserver. server_protocol String http The protocol used by the Fides webserver. server_port Integer The optional port of the Fides webserver. analytics_id String \"\" A fully anonymized unique identifier that is automatically generated by the application and stored in the toml file.","title":"CLI"},{"location":"installation/configuration/#security","text":"Name Type Default Description app_encryption_key string N/A The key used to sign Fides API access tokens. cors_origins List[AnyHttpUrl] N/A A list of pre-approved addresses of clients allowed to communicate with the Fides application server. oauth_root_client_id string N/A The value used to identify the Fides application root API client. oauth_root_client_secret string N/A The secret value used to authenticate the Fides application root API client. oauth_access_token_expire_minutes int 11520 The time for which Fides API tokens will be valid. root_username string None If set, this can be used in conjunction with root_password to log in without first creating a user in the database. root_password string None If set, this can be used in conjunction with root_username to log in without first creating a user in the database. root_user_scopes list of strings All available scopes The scopes granted to the root user when logging in with root_username and root_password .","title":"Security"},{"location":"installation/configuration/#execution","text":"Name Type Default Description privacy_request_delay_timeout int 3600 The amount of time to wait for actions which delay privacy requests (e.g., pre- and post-processing webhooks). task_retry_count int 0 The number of times a failed request will be retried. task_retry_delay int 1 The delays between retries in seconds. task_retry_backoff int 1 The backoff factor for retries, to space out repeated retries. subject_identity_verification_required bool False Whether privacy requests require user identity verification. require_manual_request_approval bool False Whether privacy requests require explicit approval to execute. masking_strict bool True If set to True , only use UPDATE requests to mask data. If False , Fides will use any defined DELETE or GDPR DELETE endpoints to remove PII, which may extend beyond the specific data categories that configured in your execution policy. celery_config_path string N/A An optional override for the Celery configuration file path. worker_enabled bool True By default, Fides uses a dedicated Celery worker to process privacy requests asynchronously. Setting worker_enabled to False will run the worker on the same node as the webserver.","title":"Execution"},{"location":"installation/configuration/#user","text":"Name Type Default Description encryption_key String \"\" An arbitrary string used to encrypt the user data stored in the database. Encryption is implemented using PGP. analytics_opt_out Boolean \"\" When set to true , prevents sending anonymous analytics data to Ethyca.","title":"User"},{"location":"installation/configuration/#credentials","text":"The credentials section uses custom keys which can be referenced in certain commands. Name Type Description my_postgres.connection_string String Sets the connection_string for my_postgres database credentials my_aws.aws_access_key_id String Sets the aws_access_key_id for my_aws credentials my_aws.aws_secret_access_key String Sets the aws_secret_access_key for my_aws credentials my_aws.region_name String Sets the region_name for my_aws credentials my_okta.orgUrl String Sets the orgUrl for my_okta credentials my_okta.token String Sets the token for my_okta credentials","title":"Credentials"},{"location":"installation/configuration/#admin-ui","text":"Name Type Default Description enabled bool True Toggle whether the Admin UI is served from / .","title":"Admin UI"},{"location":"installation/configuration/#set-environment-variables","text":"To configure environment variables for Fides, the following pattern is used: 1 FIDES__<SECTION>__<VAR_NAME> For example, to set the server_url on a Linux machine: 1 2 3 export FIDES__CLI__SERVER_HOST = \"localhost\" export FIDES__CLI__SERVER_PORT = \"8080\" export FIDES__CLI__SERVER_PROTOCOL = \"http\"","title":"Set environment variables"},{"location":"installation/configuration/#additional-environment-variables","text":"The following environment variables are not included in the default fides.toml configuration, but may be set in your environment: ENV Variable Default Description FIDES__LOG_PII False If True , PII values will display unmasked in log output. This variable should always be set to \"False\" in production systems. FIDES__HOT_RELOAD False If True , the Fides server will reload code changes without needing to restart the server. This variable should always be set to False in production systems. FIDES__DEV_MODE False If True , the Fides server will log error tracebacks, and log details of third party requests. This variable should always be set to False in production systems. FIDES_CONFIG_PATH None If this is set to a path, that path will be used to load .toml files first. Any .toml files on this path will override any installed .toml files. FIDES__DATABASE__SQLALCHEMY_DATABASE_URI None An optional override for the URI used for the database connection, in the form of postgresql://<user>:<password>@<hostname>:<port>/<database> .","title":"Additional environment variables"},{"location":"installation/configuration/#celery-configuration","text":"Fides uses Celery for asynchronous task management. The celery.toml file provided contains a brief configuration reference for managing Celery variables. By default, Fides will look for this file in the root directory of your application, but this location can be optionally overridden by specifying an alternate celery_config_path in your fides.toml . For a full list of possible variable overrides, see the Celery configuration documentation. Example celery.toml 1 2 3 default_queue_name = \"fides\" broker_url = \"redis://:testpassword@redis:6379/1\" result_backend = \"redis://:testpassword@redis:6379/1\" Celery Variable Example Description default_queue_name fides A name to use for your Celery task queue. broker_url redis://:testpassword@redis:6379/1 The datastore to use as a Celery broker , which maintains an ordered list of asynchronous tasks to execute. If not specified, Fides will default to the connection_url or Redis config values specified in your fides.toml . result_backend redis://:testpassword@redis:6379/1 The backend datastore where Celery will store results from asynchronously processed tasks. If not specified, Fides will default to the connection_url or Redis config values specified in your fides.toml .","title":"Celery configuration"},{"location":"installation/configuration/#view-a-live-configuration","text":"You can view the currently running configuration of your application with the following request: 1 GET /api/v1/config Fides will filter out any sensitive configuration variables. The full list of variables deemed safe to return is: Postgres database server user port db test_db Redis cache host port charset decode_responses default_ttl_seconds db_index Security settings cors_origins encoding oauth_access_token_expire_minutes Execution settings task_retry_count task_retry_delay task_retry_backoff require_manual_request_approval masking_strict For more information, see the API docs .","title":"View a live configuration"},{"location":"installation/docker/","text":"Installation from Docker The fides image is published on the ethyca/fides DockerHub and maintained by the Fides team. To decide if a Docker installation is right for your use case, see the installation overview . These reference images contain all of the extras and dependencies for running the Python application, but do not contain the required Postgres database. To quickly experiment with Fides, clone the source repository , and use the built-in docker compose configuration to run a complete demo environment. System requirements Ensure that Docker is running on your host prior to starting. See the the Prerequisites and Dependencies page for the minimum Docker requirements. Pull the docker image Run the following command to pull the latest image from Ethyca's DockerHub : 1 docker pull ethyca/fides Set up your database Configure your own Postgres database according to the configuration of your choice, ensuring it satisfies the project requirements . Enable a username and password, and keep track of your connection credentials. Set up your cache Configure your own Redis cache according to the configuration of your choice, ensuring it satisfies the project requirements . Enable a password (via Redis AUTH ) to provide additional security, and keep track of your connection credentials. Configure Fides Fides configuration variables are maintained in either a fides.toml file, or environment variables. These should be replaced with the connection credentials for your Postgres and Redis instances, as well as any other information unique to your deployment. See the Configuration guide for a full list of settings, and a sample fides.toml . Running the webserver Once configured, you can start your server: 1 docker run ethyca/fides With the Fides webserver running, the hosted UI is available at http://{server_url}/ (e.g. http://localhost:8080/ ).","title":"Installation from Docker"},{"location":"installation/docker/#installation-from-docker","text":"The fides image is published on the ethyca/fides DockerHub and maintained by the Fides team. To decide if a Docker installation is right for your use case, see the installation overview . These reference images contain all of the extras and dependencies for running the Python application, but do not contain the required Postgres database. To quickly experiment with Fides, clone the source repository , and use the built-in docker compose configuration to run a complete demo environment.","title":"Installation from Docker"},{"location":"installation/docker/#system-requirements","text":"Ensure that Docker is running on your host prior to starting. See the the Prerequisites and Dependencies page for the minimum Docker requirements.","title":"System requirements"},{"location":"installation/docker/#pull-the-docker-image","text":"Run the following command to pull the latest image from Ethyca's DockerHub : 1 docker pull ethyca/fides","title":"Pull the docker image"},{"location":"installation/docker/#set-up-your-database","text":"Configure your own Postgres database according to the configuration of your choice, ensuring it satisfies the project requirements . Enable a username and password, and keep track of your connection credentials.","title":"Set up your database"},{"location":"installation/docker/#set-up-your-cache","text":"Configure your own Redis cache according to the configuration of your choice, ensuring it satisfies the project requirements . Enable a password (via Redis AUTH ) to provide additional security, and keep track of your connection credentials.","title":"Set up your cache"},{"location":"installation/docker/#configure-fides","text":"Fides configuration variables are maintained in either a fides.toml file, or environment variables. These should be replaced with the connection credentials for your Postgres and Redis instances, as well as any other information unique to your deployment. See the Configuration guide for a full list of settings, and a sample fides.toml .","title":"Configure Fides"},{"location":"installation/docker/#running-the-webserver","text":"Once configured, you can start your server: 1 docker run ethyca/fides With the Fides webserver running, the hosted UI is available at http://{server_url}/ (e.g. http://localhost:8080/ ).","title":"Running the webserver"},{"location":"installation/overview/","text":"Overview The Fides team provides up-to-date versions of both PyPI and Docker installations. For information on which method of installation might work best for your use, the requirements for each option is summarized below. Installation options PyPI Only pip / pipx installations are currently officially supported. For more information, see Installation from PyPI . For environment isolation, the Fides team recommends using pipx when possible. When to use PyPI If you are not familiar with Docker or containers, and want to install Fides on physical or virtual machines. If you are used to installing and running software using custom deployment mechanism. If you would like to use with a lightweight installation of Fides, and manage optional dependencies on your own. Intended users Users who are familiar with installing and configuring Python applications, managing Python environments and dependencies, and running software with their custom deployment mechanisms. Requirements You are expected to install Fides and any associated components on your own. You will develop and handle the deployment for all components of Fides. You are responsible for setting up the databases, configuring automated startup and recovery, and handling maintenance, cleanup, and upgrades. Additional support The Installation from PyPI guide provides installation details. Due to differences in environments and tools, this guide cannot comprehensively cover all deployment and usage errors and concerns. Docker The Fides Docker images are built by the Fides CI/CD pipeline, which generates versions on each official release, as well as commits made to the main branch. For this reason, it is highly discouraged to use the latest tag, as any non-official release versions may contain some instability. For more information, see Installation from Docker . When to use Docker If you are looking for the quickest way to get started, with minimal additional configuration. Docker will run Fides components in isolation from other software running on the same physical or virtual machines, and provides straightforward dependency maintenance. If you are familiar with the container/Docker stack. Intended users Users who are familiar with containers and Docker, and understand how to build and extend their own container images. Users who know how to create and maintain Docker deployments. Requirements You may need to Customize or extend the container or Docker images to add extra dependencies. You will build deployments out of several containers (i.e., via Docker Compose). You are responsible for setting up the databases, configuring automated startup and recovery, and handling maintenance, cleanup, and upgrades. You should choose the right deployment mechanism (a custom process, Kubernetes, Docker Compose, Helm charts, etc.) based on your experience and expectations. Troubleshooting For questions regarding either installation, visit the Community page.","title":"Overview"},{"location":"installation/overview/#overview","text":"The Fides team provides up-to-date versions of both PyPI and Docker installations. For information on which method of installation might work best for your use, the requirements for each option is summarized below.","title":"Overview"},{"location":"installation/overview/#installation-options","text":"","title":"Installation options"},{"location":"installation/overview/#pypi","text":"Only pip / pipx installations are currently officially supported. For more information, see Installation from PyPI . For environment isolation, the Fides team recommends using pipx when possible.","title":"PyPI"},{"location":"installation/overview/#when-to-use-pypi","text":"If you are not familiar with Docker or containers, and want to install Fides on physical or virtual machines. If you are used to installing and running software using custom deployment mechanism. If you would like to use with a lightweight installation of Fides, and manage optional dependencies on your own.","title":"When to use PyPI"},{"location":"installation/overview/#intended-users","text":"Users who are familiar with installing and configuring Python applications, managing Python environments and dependencies, and running software with their custom deployment mechanisms.","title":"Intended users"},{"location":"installation/overview/#requirements","text":"You are expected to install Fides and any associated components on your own. You will develop and handle the deployment for all components of Fides. You are responsible for setting up the databases, configuring automated startup and recovery, and handling maintenance, cleanup, and upgrades.","title":"Requirements"},{"location":"installation/overview/#additional-support","text":"The Installation from PyPI guide provides installation details. Due to differences in environments and tools, this guide cannot comprehensively cover all deployment and usage errors and concerns.","title":"Additional support"},{"location":"installation/overview/#docker","text":"The Fides Docker images are built by the Fides CI/CD pipeline, which generates versions on each official release, as well as commits made to the main branch. For this reason, it is highly discouraged to use the latest tag, as any non-official release versions may contain some instability. For more information, see Installation from Docker .","title":"Docker"},{"location":"installation/overview/#when-to-use-docker","text":"If you are looking for the quickest way to get started, with minimal additional configuration. Docker will run Fides components in isolation from other software running on the same physical or virtual machines, and provides straightforward dependency maintenance. If you are familiar with the container/Docker stack.","title":"When to use Docker"},{"location":"installation/overview/#intended-users_1","text":"Users who are familiar with containers and Docker, and understand how to build and extend their own container images. Users who know how to create and maintain Docker deployments.","title":"Intended users"},{"location":"installation/overview/#requirements_1","text":"You may need to Customize or extend the container or Docker images to add extra dependencies. You will build deployments out of several containers (i.e., via Docker Compose). You are responsible for setting up the databases, configuring automated startup and recovery, and handling maintenance, cleanup, and upgrades. You should choose the right deployment mechanism (a custom process, Kubernetes, Docker Compose, Helm charts, etc.) based on your experience and expectations.","title":"Requirements"},{"location":"installation/overview/#troubleshooting","text":"For questions regarding either installation, visit the Community page.","title":"Troubleshooting"},{"location":"installation/pypi/","text":"Installation from PyPI The Fides Python package is published on PyPI and maintained by the Fides team. To decide if a PyPI installation is right for your use case, see the installation overview . System requirements See the the Prerequisites and Dependencies page for more information. Basic installation The Fides team recommends using pipx over pip for environment isolation. The following documentation assumes pipx is installed, but pip commands can be substituted when needed. To install Fides, run: 1 pipx install fides Verify your installation With Fides installed, verify the installation: 1 fides --version A correct installation will print the current version of Fides to your console. Install optional dependencies Fides ships with a number of optional dependencies that extend its functionality. To install these, use the following syntax: 1 pipx install \"fides[extra_1]\" For multiple dependencies: 1 pipx install \"fides[extra_1, extra_2]\" The optional dependencies are as follows: all : includes all of the optional dependencies except for mssql due to platform-specific issues. aws : includes the boto3 package to connect to AWS. mssql : includes the MSSQL database connector. mysql : includes the MySQL database connector. postgres : includes the Postgres database connector. redshift : includes the Redshift database connector. snowflake : includes the Snowflake database connector. When installing database adapters, additional dependencies may be required (e.g. pg_hba.conf for Postgres, or the Microsoft ODBC Driver for SQL Server). Apple M1 users of MSSQL Known issues around connecting to MSSQL exist today, please reference the following issue for potential solutions: https://github.com/mkleehammer/pyodbc/issues/846 Initialize Fides Initializing the project will create a configuration file with default values, and generate a directory to house your Fides resources. Initialize Fides 1 fides init Expected Output 1 2 3 4 5 6 7 8 9 10 11 12 Initializing Fides... ---------- Created a './.fides' directory. ---------- Created a fides config file: ./.fides/fides.toml To learn more about configuring fides, see: https://ethyca.github.io/fides/installation/configuration/ ---------- For example policies and help getting started, see: https://ethyca.github.io/fides/guides/policies/ ---------- Fides initialization complete. Run standalone mode Once Fides is installed and initialized, it is possible to run the project in \"standalone mode,\" which requires zero dependencies outside of Python. This does not provide webserver connectivity, but allows you to experiment with local evaluation commands in the CLI. Use one of the following methods to enable standalone mode: CLI flag 1 fides --local <subcommand> fides.toml 1 2 [cli] local_mode = true Set up your database Configure your own Postgres database according to the configuration of your choice, ensuring it satisfies the project requirements . Enable a username and password, and keep track of your connection credentials. Set up your cache Configure your own Redis cache according to the configuration of your choice, ensuring it satisfies the project requirements . Enable a password (via Redis AUTH ) to provide additional security, and keep track of your connection credentials. Configure Fides Fides provides a fides.toml file to store your configuration settings. Initializing Fides creates this file and populates it with default values, which should be replaced with the connection credentials for your Postgres and Redis instances, as well as any other information unique to your deployment. See the Configuration guide for a full list of settings, and a sample fides.toml . Running the webserver In a shell, run the following command: 1 fides webserver With the Fides webserver running, the hosted UI is available at http://{server_url}/ (e.g. http://localhost:8080/ ).","title":"Installation from PyPI"},{"location":"installation/pypi/#installation-from-pypi","text":"The Fides Python package is published on PyPI and maintained by the Fides team. To decide if a PyPI installation is right for your use case, see the installation overview .","title":"Installation from PyPI"},{"location":"installation/pypi/#system-requirements","text":"See the the Prerequisites and Dependencies page for more information.","title":"System requirements"},{"location":"installation/pypi/#basic-installation","text":"The Fides team recommends using pipx over pip for environment isolation. The following documentation assumes pipx is installed, but pip commands can be substituted when needed. To install Fides, run: 1 pipx install fides","title":"Basic installation"},{"location":"installation/pypi/#verify-your-installation","text":"With Fides installed, verify the installation: 1 fides --version A correct installation will print the current version of Fides to your console.","title":"Verify your installation"},{"location":"installation/pypi/#install-optional-dependencies","text":"Fides ships with a number of optional dependencies that extend its functionality. To install these, use the following syntax: 1 pipx install \"fides[extra_1]\" For multiple dependencies: 1 pipx install \"fides[extra_1, extra_2]\" The optional dependencies are as follows: all : includes all of the optional dependencies except for mssql due to platform-specific issues. aws : includes the boto3 package to connect to AWS. mssql : includes the MSSQL database connector. mysql : includes the MySQL database connector. postgres : includes the Postgres database connector. redshift : includes the Redshift database connector. snowflake : includes the Snowflake database connector. When installing database adapters, additional dependencies may be required (e.g. pg_hba.conf for Postgres, or the Microsoft ODBC Driver for SQL Server). Apple M1 users of MSSQL Known issues around connecting to MSSQL exist today, please reference the following issue for potential solutions: https://github.com/mkleehammer/pyodbc/issues/846","title":"Install optional dependencies"},{"location":"installation/pypi/#initialize-fides","text":"Initializing the project will create a configuration file with default values, and generate a directory to house your Fides resources. Initialize Fides 1 fides init Expected Output 1 2 3 4 5 6 7 8 9 10 11 12 Initializing Fides... ---------- Created a './.fides' directory. ---------- Created a fides config file: ./.fides/fides.toml To learn more about configuring fides, see: https://ethyca.github.io/fides/installation/configuration/ ---------- For example policies and help getting started, see: https://ethyca.github.io/fides/guides/policies/ ---------- Fides initialization complete.","title":"Initialize Fides"},{"location":"installation/pypi/#run-standalone-mode","text":"Once Fides is installed and initialized, it is possible to run the project in \"standalone mode,\" which requires zero dependencies outside of Python. This does not provide webserver connectivity, but allows you to experiment with local evaluation commands in the CLI. Use one of the following methods to enable standalone mode: CLI flag 1 fides --local <subcommand> fides.toml 1 2 [cli] local_mode = true","title":"Run standalone mode"},{"location":"installation/pypi/#set-up-your-database","text":"Configure your own Postgres database according to the configuration of your choice, ensuring it satisfies the project requirements . Enable a username and password, and keep track of your connection credentials.","title":"Set up your database"},{"location":"installation/pypi/#set-up-your-cache","text":"Configure your own Redis cache according to the configuration of your choice, ensuring it satisfies the project requirements . Enable a password (via Redis AUTH ) to provide additional security, and keep track of your connection credentials.","title":"Set up your cache"},{"location":"installation/pypi/#configure-fides","text":"Fides provides a fides.toml file to store your configuration settings. Initializing Fides creates this file and populates it with default values, which should be replaced with the connection credentials for your Postgres and Redis instances, as well as any other information unique to your deployment. See the Configuration guide for a full list of settings, and a sample fides.toml .","title":"Configure Fides"},{"location":"installation/pypi/#running-the-webserver","text":"In a shell, run the following command: 1 fides webserver With the Fides webserver running, the hosted UI is available at http://{server_url}/ (e.g. http://localhost:8080/ ).","title":"Running the webserver"},{"location":"installation/requirements/","text":"Project Requirements Minimum requirements Fides supports the following Python versions: Python: 3.9+ The following is supported as the application database: PostgreSQL: 12 The following is supported as the application cache: Redis: 6.2.0+ All of these must be installed, either locally or via Docker, before attempting to run Fides as an application. The CLI is capable of running with only the Python dependency. Docker requirements If using Docker, the following minimum versions are required: Docker : 20.10.8+ Docker Compose : 1.29.0+","title":"Project Requirements"},{"location":"installation/requirements/#project-requirements","text":"","title":"Project Requirements"},{"location":"installation/requirements/#minimum-requirements","text":"Fides supports the following Python versions: Python: 3.9+ The following is supported as the application database: PostgreSQL: 12 The following is supported as the application cache: Redis: 6.2.0+ All of these must be installed, either locally or via Docker, before attempting to run Fides as an application. The CLI is capable of running with only the Python dependency.","title":"Minimum requirements"},{"location":"installation/requirements/#docker-requirements","text":"If using Docker, the following minimum versions are required: Docker : 20.10.8+ Docker Compose : 1.29.0+","title":"Docker requirements"},{"location":"saas_connectors/saas_config/","text":"What is a SaaS configuration schema? A SaaS connector is defined in two parts: the Dataset , and the SaaS configuration. The Dataset describes the data that is available from the connector, and the SaaS config describes how to connect to, and retrieve or update the data in the connector. When accessing data from APIs, each application (and different endpoints within the same application) can follow different patterns, making their requirements different from Database connectors . Fides provides a flexible configuration to define different access/update patterns. An example SaaS config This guide will use a SaaS configuration to connect to Mailchimp . The configuration schema defines: The domain and authentication requirements for an HTTP client to access Mailchimp A test request for verifying the connection was set up correctly Endpoints to the following resources within the Mailchimp API: GET and PUT for the members resource GET for the conversations resource GET for the messages resource The following is an example SaaS config for Mailchimp: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 saas_config : fides_key : mailchimp_connector_example name : Mailchimp SaaS Config type : mailchimp description : A sample schema representing the Mailchimp connector for fides version : 0.0.1 connector_params : - name : domain - name : username - name : api_key client_config : protocol : https host : <domain> authentication : strategy : basic configuration : username : <username> password : <api_key> test_request : method : GET path : /3.0/lists endpoints : - name : messages requests : read : method : GET path : /3.0/conversations/<conversation_id>/messages param_values : - name : conversation_id references : - dataset : mailchimp_connector_example field : conversations.id direction : from data_path : conversation_messages postprocessors : - strategy : filter configuration : field : from_email value : identity : email - name : conversations requests : read : method : GET path : /3.0/conversations query_params : - name : count value : 1000 - name : offset value : 0 param_values : - name : placeholder identity : email data_path : conversations pagination : strategy : offset configuration : incremental_param : offset increment_by : 1000 limit : 10000 - name : member requests : read : method : GET path : /3.0/search-members query_params : - name : query value : <email> param_values : - name : email identity : email data_path : exact_matches.members update : method : PUT path : /3.0/lists/<list_id>/members/<subscriber_hash> param_values : - name : list_id references : - dataset : mailchimp_connector_example field : member.list_id direction : from - name : subscriber_hash references : - dataset : mailchimp_connector_example field : member.id direction : from SaaS config metadata fields Attribute Description fides_key Used to uniquely identify the connector, and to link a SaaS config to a dataset. name A human-readable name for the connector. type Type of SaaS connector. Choose from hubspot , mailchimp , or the other available connectors , or use custom for other types. description Used to add a useful description. version Used to track different versions of the SaaS config. The above configuration also contains the following complex fields connector_params client_config test_request endpoints data_protection_request Connector params The connector_params field is used to describe a list of settings which a user must configure as part of the setup. A default_value can also be used to include values such as a standard base domain for an API or a recommended page size for pagination. Make sure to not include confidential values such as passwords or API keys, these values are added as part of the Connection secrets . When configuring a connector's secrets for the first time, the default values will be used if a value is not provided. 1 2 3 4 5 6 7 connector_params : - name : domain default_value : api.stripe.com - name : username - name : password - name : page_size default_value : 100 External references The external_references field is used to describe a list of external dataset references that a user must configure as part of the setup. These dataset references point to fields in a registered Fides dataset that are used to provide necessary values to the SaaS connector execution. The location of these fields depends on the use-case, so they cannot be determined beforehand, and therefore must be configured at the time of setting up the SaaS connector. 1 2 3 external_references : - name : doordash_delivery_id description : An external reference to a field/column in some database table that provides Doordash delivery IDs. This reference must be configured. Client config The client_config describes the necessary information to be able to create a base HTTP client. The values for host, username, and password are not defined here, only referenced in the form of a connector_param which Fides uses to insert the actual value from the stored secrets. 1 2 3 4 5 6 7 8 client_config : protocol : https host : <host> authentication : strategy : basic configuration : username : <username> password : <password> The authentication strategies are swappable. This example uses the basic authentication strategy, which takes a username and password in the configuration. An alternative to this is to use bearer authentication which looks like this: 1 2 3 4 authentication : strategy : bearer configuration : token : <api_key> Fides also supports OAuth2 authentication . Test request Once the base client is defined, use a test_request to verify the hostname and credentials. This is in the form of an idempotent request (usually a read request). The testing approach is the same for any Connection 1 2 3 test_request : method : GET path : /3.0/lists Data protection request If your third party integration supports something like a GDPR delete endpoint, that can be configured as a data_protection_request . It has similar attributes to endpoint requests, but is generally one endpoint that removes all user information in one call. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 data_protection_request : method : POST path : /v1beta/workspaces/<workspace_name>/regulations param_values : - name : workspace_name connector_param : workspace - name : user_id identity : email body : '{\"regulation_type\": \"Suppress_With_Delete\", \"attributes\": {\"name\": \"userId\", \"values\": [\"<user_id>\",]}}' client_config : protocol : https host : <config_domain> authentication : strategy : bearer configuration : username : <access_token> Endpoints The endpoints configuration defines how collections are accessed and updated. The endpoint section contains the following members: Attribute Description name This name corresponds to a collection in the corresponding Dataset. after To configure if this endpoint should run after other endpoints or collections. This should be a list of collection addresses. For example, after: [ mailchimp_connector_example.member ] would cause the current endpoint to run after the member endpoint. requests A map of read , update , and delete requests for this collection. Each collection can define a way to read and a way to update the data. The requests configuration further contains the following fields: Attribute Description method The HTTP method used for the endpoint. path A static or dynamic resource path. The dynamic portions of the path are enclosed within angle brackets <dynamic_value> and are replaced with values from param_values . headers and query_params The HTTP headers and query parameters to include in the request. headers.name , query_params.name The value to use for the header or query param name. headers.value , query_params.value This can be a static value, one or more of <dynamic_value> , or a mix of static and dynamic values (prefix <value> ) which will be replaced with the value sourced from the param_value with a matching name. body Optional. A static or dynamic request body, with dynamic portions enclosed in brackets, just like path . These dynamic values will be replaced with values from param_values . param_values.name Used as the key to reference this value from dynamic values in the path, headers, query, or body params. param_values.references These are the same as references in a Dataset . It is used to define the source of the value for the given param_value . param_values.identity Used to access the identity values passed into the privacy request such as email or phone number. param_values.connector_param Used to access the user-configured secrets for the connection. ignore_errors A boolean. If true, we will ignore non-200 status codes. data_path The expression used to access the collection information from the raw JSON response. postprocessors An optional list of response post-processing strategies. We will ignore this for the example scenarios below but an in depth-explanation can be found under SaaS Post-Processors . pagination An optional strategy used to get the next set of results from APIs with resources spanning multiple pages. Details can be found under SaaS Pagination . grouped_inputs An optional list of reference fields whose inputs are dependent upon one another. For example, an endpoint may need both an organization_id and a project_id from another endpoint. These aren't independent values, as a project_id belongs to an organization_id . You would specify this as [\"organization_id\", \"project_id\"] . client_config Specify optional embedded Client Configs if an individual request needs a different protocol, host, or authentication strategy from the base Client Config. Param_values in more detail The param_values list is what provides the values to the various placeholders in the path, headers, query params and body. Values can be identities , such as email or phone number, references to fields in other collections or to an external_reference , or connector_params which are defined as part of configuring a SaaS connector. Whenever a placeholder is encountered, the placeholder name is looked up in the list of param_values and the corresponding value is used instead. Here is an example of placeholders being used in various locations 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 messages : requests : read : method : GET path : /<version>/messages headers : - name : Content-Type value : application/json - name : On-Behalf-Of value : <email> - name : Token value : Custom <api_key> query_params : - name : count value : 100 - name : organization : value : <org_id> - name : where : value : properties[\"$email\"]==\"<email>\" param_values : - name : email identity : email - name : api_key connector_param : api_key - name : org_id connector_param : org_id - name : version connector_param : version Generating requests The following HTTP request properties are generated for each request based on the endpoint configuration: method path headers query params body Method: This is a required field since a read, update, or delete endpoint might use any of the HTTP methods to perform the given action. Path: This can be a static value or use placeholders. If the placeholders to build the path are not found at request-time, the request will fail. Headers and query params: These can also be static or use placeholders. If a placeholder is missing, the request will continue and omit the given header or query param in the request If reference values are used for the placeholders, each value will be processed independently unless the grouped_inputs field is set. The following examples use query params but this applies to headers as well. With ungrouped inputs (default) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 read : method : GET path : /v1/disputes query_params : - name : charge value : <charge_id> - name : line_item value : <line_item_id> param_values : - name : charge_id references : - dataset : connector_example field : charge.id direction : from - name : line_item_id references : - dataset : connector_example field : charge.line_item.id direction : from 1 2 3 4 5 6 GET /v1/disputes?charge=1 GET /v1/disputes?charge=2 GET /v1/disputes?charge=3 GET /v1/disputes?line_item=a GET /v1/disputes?line_item=b GET /v1/disputes?line_item=c With grouped inputs 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 read : method : GET path : /v1/disputes grouped_inputs : [ charge_id , payment_intent_id ] query_params : - name : charge value : <charge_id> - name : line_item value : <line_item_id> param_values : - name : charge_id references : - dataset : connector_example field : charge.id direction : from - name : line_item_id references : - dataset : connector_example field : charge.line_item.id direction : from 1 2 3 GET /v1/disputes?charge=1&line_item=a GET /v1/disputes?charge=2&line_item=b GET /v1/disputes?charge=3&line_item=c Body: The body can be static or use placeholders. If the placeholders to build the body are not found at request-time, the request will fail. The following placeholders can be included in the body of an update: <masked_object_fields> - any masked fields, along with their masked value <all_object_fields> - all object fields, including the masked fields and values Fides will automatically fill in the value of these placeholders with the appropriate contents. For example, an access request returned the following row 1 2 3 4 5 { \"id\" : 123 , \"name\" : \"Bobby Hill\" , \"address\" : \"Arlen TX\" } With the name field masked, the value of each placeholder would be: Placeholder Value <masked_object_fields> \"name\":\"MASKED\" <all_object_fields> \"id\":123,\"name\":\"MASKED\",\"address\":\"Arlen TX\" all_object_fields should be used if non-masked fields are required as part of the update payload. Read-Only fields: A field can be flagged as read-only in the dataset to exclude it from the value of <all_object_fields> (for example, if including the id would cause an error). 1 2 3 4 - name : id data_categories : [ system.operations ] fidesops_meta : read_only : True This would result in the following change, with id removed from the result: Placeholder Value <all_object_fields> \"name\":\"MASKED\",\"address\":\"Arlen TX\" Example scenarios Dynamic path with dataset references 1 2 3 4 5 6 7 8 9 10 11 12 endpoints : - name : messages requests : read : method : GET path : /3.0/conversations/<conversation_id>/messages param_values : - name : conversation_id references : - dataset : mailchimp_connector_example field : conversations.id direction : from In this example, /3.0/conversations/<conversation_id>/messages is defined as the resource path for messages, and the path param of conversation_id is defined as coming from the id field of the conversations collection. A separate GET HTTP request will be issued for each conversations.id value. 1 2 3 4 # For three conversations with IDs of 1,2,3 GET /3.0/conversations/1/messages GET /3.0/conversations/2/messages GET /3.0/conversations/2/messages Identity as a query param 1 2 3 4 5 6 7 8 9 10 11 12 endpoints : - name : member requests : read : method : GET path : /3.0/search-members query_params : - name : query value : <email> param_values : - name : email identity : email In this example, the placeholder in the query query param will be replaced with the value of the param_value with a name of email , which is the email identity. The result would look like this: 1 GET /3.0/search-members?query=name@email.com Data update with a dynamic path 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 endpoints : - name : member requests : update : method : PUT path : /3.0/lists/<list_id>/members/<subscriber_hash> param_values : - name : list_id references : - dataset : mailchimp_connector_example field : member.list_id direction : from - name : subscriber_hash references : - dataset : mailchimp_connector_example field : member.id direction : from This example uses two dynamic path variables, one from member.id and one from member.list_id . Since both of these are references to the member collection, first issue a data retrieval (which will happen automatically if the read request is defined). If a call to GET /3.0/search-members returned the following member object: 1 2 3 4 5 6 7 8 { \"list_id\" : \"123\" , \"id\" : \"456\" , \"merge_fields\" : { \"FNAME\" : \"First\" , \"LNAME\" : \"Last\" } } Then the update request would be: 1 2 3 4 5 6 7 8 9 10 PUT /3.0/lists/123/members/456 { \"list_id\" : \"123\" , \"id\" : \"456\" , \"merge_fields\" : { \"FNAME\" : \"MASKED\" , \"LNAME\" : \"MASKED\" } } and the contents of the body would be masked according to the configured policy . Data update with a dynamic HTTP body Sometimes, the update request needs a different body structure than what is obtained from the read request. In this example, use a custom HTTP body that contains the masked object fields. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 update : method : PUT path : /crm/v3/objects/contacts body : '{ \"properties\": { <masked_object_fields>, \"user_ref_id\": <user_ref_id> } }' param_values : - name : user_ref_id references : - dataset : dataset_test field : contacts.user_ref_id direction : from Fides will replace the <masked_object_fields> placeholder with the result of the policy-driven masking service (e.g. 'company': None, 'email': None ). Note that neither enclosing curly brackets ( { } ) nor a trailing comma ( , ) are included as part of the replacement string. This results in the following update request: 1 2 3 4 5 6 7 8 9 PUT /crm/v3/objects/contacts { \"properties\" : { \"company\" : \"None\" , \"email\" : \"None\" \"user_ref_id\" : \"p983u4ncp3q8u4r\" } } How does this relate to graph traversal? Fides uses the available Datasets to generate a graph of all reachable data and the dependencies between Datasets. For SaaS connectors, all the references and identities are stored in the param_values , and must merge both the SaaS config and Dataset to provide a complete picture for the graph traversal. Using Mailchimp as an example, the Dataset collection and SaaS config endpoints for messages looks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 collections : - name : messages fields : - name : id data_categories : [ system.operations ] - name : conversation_id data_categories : [ system.operations ] - name : from_label data_categories : [ system.operations ] - name : from_email data_categories : [ user.contact.email ] - name : subject data_categories : [ system.operations ] - name : message data_categories : [ system.operations ] - name : read data_categories : [ system.operations ] - name : timestamp data_categories : [ system.operations ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 endpoints : - name : messages requests : read : method : GET path : /3.0/conversations/<conversation_id>/messages param_values : - name : conversation_id references : - dataset : mailchimp_connector_example field : conversations.id direction : from postprocessors : - strategy : unwrap configuration : data_path : conversation_messages - strategy : filter configuration : field : from_email value : identity : email An example of the augmented Dataset with the SaaS Config references would look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 collections : - name : messages fields : - name : id data_categories : [ system.operations ] - name : conversation_id data_categories : [ system.operations ] fidesops_meta : references : - dataset : mailchimp_connector_example field : conversations.id direction : from - name : from_label data_categories : [ system.operations ] - name : from_email data_categories : [ user.contact.email ] - name : subject data_categories : [ system.operations ] - name : message data_categories : [ system.operations ] - name : read data_categories : [ system.operations ] - name : timestamp data_categories : [ system.operations ] The conversation_id field is updated with a reference from mailchimp_connector_example.conversations.id . This means that the conversations collection must be retrieved first, then forward the conversation IDs to the messages collection for further processing. What if a collection has no dependencies? In the Mailchimp example, there is a placeholder request param 1 2 3 4 5 6 7 8 9 10 11 12 13 14 endpoints : - name : conversations requests : read : method : GET path : /3.0/conversations query_params : - name : count value : 1000 - name : offset value : 0 param_values : - name : placeholder identity : email Some endpoints might not have any external dependencies on identity or Dataset reference values. The way the Fides graph traversal interprets this is as an unreachable collection. At this time, the way to mark this as reachable is to include a param_value with an identity or a reference. In the future, collections like these will still be considered reachable even without this placeholder","title":"SaaS Configuration"},{"location":"saas_connectors/saas_config/#what-is-a-saas-configuration-schema","text":"A SaaS connector is defined in two parts: the Dataset , and the SaaS configuration. The Dataset describes the data that is available from the connector, and the SaaS config describes how to connect to, and retrieve or update the data in the connector. When accessing data from APIs, each application (and different endpoints within the same application) can follow different patterns, making their requirements different from Database connectors . Fides provides a flexible configuration to define different access/update patterns.","title":"What is a SaaS configuration schema?"},{"location":"saas_connectors/saas_config/#an-example-saas-config","text":"This guide will use a SaaS configuration to connect to Mailchimp . The configuration schema defines: The domain and authentication requirements for an HTTP client to access Mailchimp A test request for verifying the connection was set up correctly Endpoints to the following resources within the Mailchimp API: GET and PUT for the members resource GET for the conversations resource GET for the messages resource The following is an example SaaS config for Mailchimp: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 saas_config : fides_key : mailchimp_connector_example name : Mailchimp SaaS Config type : mailchimp description : A sample schema representing the Mailchimp connector for fides version : 0.0.1 connector_params : - name : domain - name : username - name : api_key client_config : protocol : https host : <domain> authentication : strategy : basic configuration : username : <username> password : <api_key> test_request : method : GET path : /3.0/lists endpoints : - name : messages requests : read : method : GET path : /3.0/conversations/<conversation_id>/messages param_values : - name : conversation_id references : - dataset : mailchimp_connector_example field : conversations.id direction : from data_path : conversation_messages postprocessors : - strategy : filter configuration : field : from_email value : identity : email - name : conversations requests : read : method : GET path : /3.0/conversations query_params : - name : count value : 1000 - name : offset value : 0 param_values : - name : placeholder identity : email data_path : conversations pagination : strategy : offset configuration : incremental_param : offset increment_by : 1000 limit : 10000 - name : member requests : read : method : GET path : /3.0/search-members query_params : - name : query value : <email> param_values : - name : email identity : email data_path : exact_matches.members update : method : PUT path : /3.0/lists/<list_id>/members/<subscriber_hash> param_values : - name : list_id references : - dataset : mailchimp_connector_example field : member.list_id direction : from - name : subscriber_hash references : - dataset : mailchimp_connector_example field : member.id direction : from","title":"An example SaaS config"},{"location":"saas_connectors/saas_config/#saas-config-metadata-fields","text":"Attribute Description fides_key Used to uniquely identify the connector, and to link a SaaS config to a dataset. name A human-readable name for the connector. type Type of SaaS connector. Choose from hubspot , mailchimp , or the other available connectors , or use custom for other types. description Used to add a useful description. version Used to track different versions of the SaaS config. The above configuration also contains the following complex fields connector_params client_config test_request endpoints data_protection_request","title":"SaaS config metadata fields"},{"location":"saas_connectors/saas_config/#connector-params","text":"The connector_params field is used to describe a list of settings which a user must configure as part of the setup. A default_value can also be used to include values such as a standard base domain for an API or a recommended page size for pagination. Make sure to not include confidential values such as passwords or API keys, these values are added as part of the Connection secrets . When configuring a connector's secrets for the first time, the default values will be used if a value is not provided. 1 2 3 4 5 6 7 connector_params : - name : domain default_value : api.stripe.com - name : username - name : password - name : page_size default_value : 100","title":"Connector params"},{"location":"saas_connectors/saas_config/#external-references","text":"The external_references field is used to describe a list of external dataset references that a user must configure as part of the setup. These dataset references point to fields in a registered Fides dataset that are used to provide necessary values to the SaaS connector execution. The location of these fields depends on the use-case, so they cannot be determined beforehand, and therefore must be configured at the time of setting up the SaaS connector. 1 2 3 external_references : - name : doordash_delivery_id description : An external reference to a field/column in some database table that provides Doordash delivery IDs. This reference must be configured.","title":"External references"},{"location":"saas_connectors/saas_config/#client-config","text":"The client_config describes the necessary information to be able to create a base HTTP client. The values for host, username, and password are not defined here, only referenced in the form of a connector_param which Fides uses to insert the actual value from the stored secrets. 1 2 3 4 5 6 7 8 client_config : protocol : https host : <host> authentication : strategy : basic configuration : username : <username> password : <password> The authentication strategies are swappable. This example uses the basic authentication strategy, which takes a username and password in the configuration. An alternative to this is to use bearer authentication which looks like this: 1 2 3 4 authentication : strategy : bearer configuration : token : <api_key> Fides also supports OAuth2 authentication .","title":"Client config"},{"location":"saas_connectors/saas_config/#test-request","text":"Once the base client is defined, use a test_request to verify the hostname and credentials. This is in the form of an idempotent request (usually a read request). The testing approach is the same for any Connection 1 2 3 test_request : method : GET path : /3.0/lists","title":"Test request"},{"location":"saas_connectors/saas_config/#data-protection-request","text":"If your third party integration supports something like a GDPR delete endpoint, that can be configured as a data_protection_request . It has similar attributes to endpoint requests, but is generally one endpoint that removes all user information in one call. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 data_protection_request : method : POST path : /v1beta/workspaces/<workspace_name>/regulations param_values : - name : workspace_name connector_param : workspace - name : user_id identity : email body : '{\"regulation_type\": \"Suppress_With_Delete\", \"attributes\": {\"name\": \"userId\", \"values\": [\"<user_id>\",]}}' client_config : protocol : https host : <config_domain> authentication : strategy : bearer configuration : username : <access_token>","title":"Data protection request"},{"location":"saas_connectors/saas_config/#endpoints","text":"The endpoints configuration defines how collections are accessed and updated. The endpoint section contains the following members: Attribute Description name This name corresponds to a collection in the corresponding Dataset. after To configure if this endpoint should run after other endpoints or collections. This should be a list of collection addresses. For example, after: [ mailchimp_connector_example.member ] would cause the current endpoint to run after the member endpoint. requests A map of read , update , and delete requests for this collection. Each collection can define a way to read and a way to update the data. The requests configuration further contains the following fields: Attribute Description method The HTTP method used for the endpoint. path A static or dynamic resource path. The dynamic portions of the path are enclosed within angle brackets <dynamic_value> and are replaced with values from param_values . headers and query_params The HTTP headers and query parameters to include in the request. headers.name , query_params.name The value to use for the header or query param name. headers.value , query_params.value This can be a static value, one or more of <dynamic_value> , or a mix of static and dynamic values (prefix <value> ) which will be replaced with the value sourced from the param_value with a matching name. body Optional. A static or dynamic request body, with dynamic portions enclosed in brackets, just like path . These dynamic values will be replaced with values from param_values . param_values.name Used as the key to reference this value from dynamic values in the path, headers, query, or body params. param_values.references These are the same as references in a Dataset . It is used to define the source of the value for the given param_value . param_values.identity Used to access the identity values passed into the privacy request such as email or phone number. param_values.connector_param Used to access the user-configured secrets for the connection. ignore_errors A boolean. If true, we will ignore non-200 status codes. data_path The expression used to access the collection information from the raw JSON response. postprocessors An optional list of response post-processing strategies. We will ignore this for the example scenarios below but an in depth-explanation can be found under SaaS Post-Processors . pagination An optional strategy used to get the next set of results from APIs with resources spanning multiple pages. Details can be found under SaaS Pagination . grouped_inputs An optional list of reference fields whose inputs are dependent upon one another. For example, an endpoint may need both an organization_id and a project_id from another endpoint. These aren't independent values, as a project_id belongs to an organization_id . You would specify this as [\"organization_id\", \"project_id\"] . client_config Specify optional embedded Client Configs if an individual request needs a different protocol, host, or authentication strategy from the base Client Config.","title":"Endpoints"},{"location":"saas_connectors/saas_config/#param_values-in-more-detail","text":"The param_values list is what provides the values to the various placeholders in the path, headers, query params and body. Values can be identities , such as email or phone number, references to fields in other collections or to an external_reference , or connector_params which are defined as part of configuring a SaaS connector. Whenever a placeholder is encountered, the placeholder name is looked up in the list of param_values and the corresponding value is used instead. Here is an example of placeholders being used in various locations 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 messages : requests : read : method : GET path : /<version>/messages headers : - name : Content-Type value : application/json - name : On-Behalf-Of value : <email> - name : Token value : Custom <api_key> query_params : - name : count value : 100 - name : organization : value : <org_id> - name : where : value : properties[\"$email\"]==\"<email>\" param_values : - name : email identity : email - name : api_key connector_param : api_key - name : org_id connector_param : org_id - name : version connector_param : version","title":"Param_values in more detail"},{"location":"saas_connectors/saas_config/#generating-requests","text":"The following HTTP request properties are generated for each request based on the endpoint configuration: method path headers query params body Method: This is a required field since a read, update, or delete endpoint might use any of the HTTP methods to perform the given action. Path: This can be a static value or use placeholders. If the placeholders to build the path are not found at request-time, the request will fail. Headers and query params: These can also be static or use placeholders. If a placeholder is missing, the request will continue and omit the given header or query param in the request If reference values are used for the placeholders, each value will be processed independently unless the grouped_inputs field is set. The following examples use query params but this applies to headers as well. With ungrouped inputs (default) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 read : method : GET path : /v1/disputes query_params : - name : charge value : <charge_id> - name : line_item value : <line_item_id> param_values : - name : charge_id references : - dataset : connector_example field : charge.id direction : from - name : line_item_id references : - dataset : connector_example field : charge.line_item.id direction : from 1 2 3 4 5 6 GET /v1/disputes?charge=1 GET /v1/disputes?charge=2 GET /v1/disputes?charge=3 GET /v1/disputes?line_item=a GET /v1/disputes?line_item=b GET /v1/disputes?line_item=c With grouped inputs 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 read : method : GET path : /v1/disputes grouped_inputs : [ charge_id , payment_intent_id ] query_params : - name : charge value : <charge_id> - name : line_item value : <line_item_id> param_values : - name : charge_id references : - dataset : connector_example field : charge.id direction : from - name : line_item_id references : - dataset : connector_example field : charge.line_item.id direction : from 1 2 3 GET /v1/disputes?charge=1&line_item=a GET /v1/disputes?charge=2&line_item=b GET /v1/disputes?charge=3&line_item=c Body: The body can be static or use placeholders. If the placeholders to build the body are not found at request-time, the request will fail. The following placeholders can be included in the body of an update: <masked_object_fields> - any masked fields, along with their masked value <all_object_fields> - all object fields, including the masked fields and values Fides will automatically fill in the value of these placeholders with the appropriate contents. For example, an access request returned the following row 1 2 3 4 5 { \"id\" : 123 , \"name\" : \"Bobby Hill\" , \"address\" : \"Arlen TX\" } With the name field masked, the value of each placeholder would be: Placeholder Value <masked_object_fields> \"name\":\"MASKED\" <all_object_fields> \"id\":123,\"name\":\"MASKED\",\"address\":\"Arlen TX\" all_object_fields should be used if non-masked fields are required as part of the update payload. Read-Only fields: A field can be flagged as read-only in the dataset to exclude it from the value of <all_object_fields> (for example, if including the id would cause an error). 1 2 3 4 - name : id data_categories : [ system.operations ] fidesops_meta : read_only : True This would result in the following change, with id removed from the result: Placeholder Value <all_object_fields> \"name\":\"MASKED\",\"address\":\"Arlen TX\"","title":"Generating requests"},{"location":"saas_connectors/saas_config/#example-scenarios","text":"","title":"Example scenarios"},{"location":"saas_connectors/saas_config/#dynamic-path-with-dataset-references","text":"1 2 3 4 5 6 7 8 9 10 11 12 endpoints : - name : messages requests : read : method : GET path : /3.0/conversations/<conversation_id>/messages param_values : - name : conversation_id references : - dataset : mailchimp_connector_example field : conversations.id direction : from In this example, /3.0/conversations/<conversation_id>/messages is defined as the resource path for messages, and the path param of conversation_id is defined as coming from the id field of the conversations collection. A separate GET HTTP request will be issued for each conversations.id value. 1 2 3 4 # For three conversations with IDs of 1,2,3 GET /3.0/conversations/1/messages GET /3.0/conversations/2/messages GET /3.0/conversations/2/messages","title":"Dynamic path with dataset references"},{"location":"saas_connectors/saas_config/#identity-as-a-query-param","text":"1 2 3 4 5 6 7 8 9 10 11 12 endpoints : - name : member requests : read : method : GET path : /3.0/search-members query_params : - name : query value : <email> param_values : - name : email identity : email In this example, the placeholder in the query query param will be replaced with the value of the param_value with a name of email , which is the email identity. The result would look like this: 1 GET /3.0/search-members?query=name@email.com","title":"Identity as a query param"},{"location":"saas_connectors/saas_config/#data-update-with-a-dynamic-path","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 endpoints : - name : member requests : update : method : PUT path : /3.0/lists/<list_id>/members/<subscriber_hash> param_values : - name : list_id references : - dataset : mailchimp_connector_example field : member.list_id direction : from - name : subscriber_hash references : - dataset : mailchimp_connector_example field : member.id direction : from This example uses two dynamic path variables, one from member.id and one from member.list_id . Since both of these are references to the member collection, first issue a data retrieval (which will happen automatically if the read request is defined). If a call to GET /3.0/search-members returned the following member object: 1 2 3 4 5 6 7 8 { \"list_id\" : \"123\" , \"id\" : \"456\" , \"merge_fields\" : { \"FNAME\" : \"First\" , \"LNAME\" : \"Last\" } } Then the update request would be: 1 2 3 4 5 6 7 8 9 10 PUT /3.0/lists/123/members/456 { \"list_id\" : \"123\" , \"id\" : \"456\" , \"merge_fields\" : { \"FNAME\" : \"MASKED\" , \"LNAME\" : \"MASKED\" } } and the contents of the body would be masked according to the configured policy .","title":"Data update with a dynamic path"},{"location":"saas_connectors/saas_config/#data-update-with-a-dynamic-http-body","text":"Sometimes, the update request needs a different body structure than what is obtained from the read request. In this example, use a custom HTTP body that contains the masked object fields. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 update : method : PUT path : /crm/v3/objects/contacts body : '{ \"properties\": { <masked_object_fields>, \"user_ref_id\": <user_ref_id> } }' param_values : - name : user_ref_id references : - dataset : dataset_test field : contacts.user_ref_id direction : from Fides will replace the <masked_object_fields> placeholder with the result of the policy-driven masking service (e.g. 'company': None, 'email': None ). Note that neither enclosing curly brackets ( { } ) nor a trailing comma ( , ) are included as part of the replacement string. This results in the following update request: 1 2 3 4 5 6 7 8 9 PUT /crm/v3/objects/contacts { \"properties\" : { \"company\" : \"None\" , \"email\" : \"None\" \"user_ref_id\" : \"p983u4ncp3q8u4r\" } }","title":"Data update with a dynamic HTTP body"},{"location":"saas_connectors/saas_config/#how-does-this-relate-to-graph-traversal","text":"Fides uses the available Datasets to generate a graph of all reachable data and the dependencies between Datasets. For SaaS connectors, all the references and identities are stored in the param_values , and must merge both the SaaS config and Dataset to provide a complete picture for the graph traversal. Using Mailchimp as an example, the Dataset collection and SaaS config endpoints for messages looks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 collections : - name : messages fields : - name : id data_categories : [ system.operations ] - name : conversation_id data_categories : [ system.operations ] - name : from_label data_categories : [ system.operations ] - name : from_email data_categories : [ user.contact.email ] - name : subject data_categories : [ system.operations ] - name : message data_categories : [ system.operations ] - name : read data_categories : [ system.operations ] - name : timestamp data_categories : [ system.operations ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 endpoints : - name : messages requests : read : method : GET path : /3.0/conversations/<conversation_id>/messages param_values : - name : conversation_id references : - dataset : mailchimp_connector_example field : conversations.id direction : from postprocessors : - strategy : unwrap configuration : data_path : conversation_messages - strategy : filter configuration : field : from_email value : identity : email An example of the augmented Dataset with the SaaS Config references would look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 collections : - name : messages fields : - name : id data_categories : [ system.operations ] - name : conversation_id data_categories : [ system.operations ] fidesops_meta : references : - dataset : mailchimp_connector_example field : conversations.id direction : from - name : from_label data_categories : [ system.operations ] - name : from_email data_categories : [ user.contact.email ] - name : subject data_categories : [ system.operations ] - name : message data_categories : [ system.operations ] - name : read data_categories : [ system.operations ] - name : timestamp data_categories : [ system.operations ] The conversation_id field is updated with a reference from mailchimp_connector_example.conversations.id . This means that the conversations collection must be retrieved first, then forward the conversation IDs to the messages collection for further processing.","title":"How does this relate to graph traversal?"},{"location":"saas_connectors/saas_config/#what-if-a-collection-has-no-dependencies","text":"In the Mailchimp example, there is a placeholder request param 1 2 3 4 5 6 7 8 9 10 11 12 13 14 endpoints : - name : conversations requests : read : method : GET path : /3.0/conversations query_params : - name : count value : 1000 - name : offset value : 0 param_values : - name : placeholder identity : email Some endpoints might not have any external dependencies on identity or Dataset reference values. The way the Fides graph traversal interprets this is as an unreachable collection. At this time, the way to mark this as reachable is to include a param_value with an identity or a reference. In the future, collections like these will still be considered reachable even without this placeholder","title":"What if a collection has no dependencies?"},{"location":"saas_connectors/saas_connectors/","text":"Connect to SaaS Applications What is a SaaS connection? A Fides SaaS (Software as a Service) Connection allows a user to connect to a third-party application (e.g., Mailchimp, Stripe, Slack, etc.), and execute data access and erasure requests against that application. Fides represents your SaaS connections as a Dataset , accessed via a Connection , and configured by a SaaS config . Supported SaaS applications The current implementation of the SaaS framework can support any SaaS application that uses these features: Basic auth, bearer auth, OAuth2 (Authorization Code Flow) Data access via HTTP requests Erasure via HTTP requests Pagination based on headers and response contents The following features are planned for future releases and will allow for the configuration of broader types of connections: Custom Python functions for access and erasure requests Retry logic based on status codes and response contents For full examples of supported Connections, see the example configurations . Configure a SaaS connector A SaaS Connector Postman collection is available to execute the necessary steps to configure a SaaS connector. When running the Fides webserver, you may also navigate to the interactive API docs at http://{server_url}/docs (e.g., http://0.0.0.0:8080/docs ) to access the following endpoints. Create a Connection of type saas PATCH api/v1/connection 1 2 3 4 5 6 7 8 [ { \"name\" : \"SaaS Application\" , \"key\" : { saas_key }, \"connection_type\" : \"saas\" , \"access\" : \"read\" } ] Add a SaaS Config (in JSON format) PATCH api/v1/connection/{saas_key}/saas_config 1 2 3 4 5 6 { \"fides_key\" : \"mailchimp_connector_example\" , \"name\" : \"Mailchimp SaaS Config\" , \"type\" : \"mailchimp\" , \"description\" : \"A sample schema representing the Mailchimp connector for fides\" ... Configure your secrets PUT api/v1/connection/{saas_key}/secret 1 2 3 4 5 { \"domain\" : \"{mailchimp_domain}\" , \"username\" : \"{mailchimp_username}\" , \"api_key\" : \"{mailchimp_api_key}\" } Add a Dataset (in JSON format) PUT api/v1/connection/{saas_key}/dataset 1 2 3 4 5 6 7 8 9 [ { \"fides_key\" : \"mailchimp_connector_example\" , \"name\" : \"Mailchimp Dataset\" , \"description\" : \"A sample dataset representing the Mailchimp connector for fidesops\" , \"collections\" :[ { \"name\" : \"messages\" ... Additional considerations The following constraints are enforced by the API validation: A SaaS connector dataset cannot have any identities or references in the fidesops_meta . These relationships must be defined in the SaaS config . SaaS config references can only have a direction of from . The fides_key between the SaaS config and the Dataset must match in order to be associated. Set up a SaaS connector from a template To create all the resources necessary to set up a SaaS Connector in one request, you can create a connector from a template. This creates a saas Connection with your supplied name and description, using your supplied secrets . The example below creates a mailchimp saas connector, and would need the relevant mailchimp secrets . Your instance_key will become the identifier for the related Dataset . By default, the saas connection config is enabled with write access. POST /connection/instantiate/mailchimp 1 2 3 4 5 6 7 8 9 10 { \"name\" : \"My Mailchimp connector\" , \"description\" : \"Production Mailchimp Instance\" , \"secrets\" : { \"domain\" : \"{{mailchimp_domain}}\" , \"api_key\" : \"{{mailchimp_api_key}}\" , \"username\" : \"{{mailchimp_username}}\" }, \"instance_key\" : \"primary_mailchimp\" , }","title":"Connect to SaaS Applications"},{"location":"saas_connectors/saas_connectors/#connect-to-saas-applications","text":"","title":"Connect to SaaS Applications"},{"location":"saas_connectors/saas_connectors/#what-is-a-saas-connection","text":"A Fides SaaS (Software as a Service) Connection allows a user to connect to a third-party application (e.g., Mailchimp, Stripe, Slack, etc.), and execute data access and erasure requests against that application. Fides represents your SaaS connections as a Dataset , accessed via a Connection , and configured by a SaaS config .","title":"What is a SaaS connection?"},{"location":"saas_connectors/saas_connectors/#supported-saas-applications","text":"The current implementation of the SaaS framework can support any SaaS application that uses these features: Basic auth, bearer auth, OAuth2 (Authorization Code Flow) Data access via HTTP requests Erasure via HTTP requests Pagination based on headers and response contents The following features are planned for future releases and will allow for the configuration of broader types of connections: Custom Python functions for access and erasure requests Retry logic based on status codes and response contents For full examples of supported Connections, see the example configurations .","title":"Supported SaaS applications"},{"location":"saas_connectors/saas_connectors/#configure-a-saas-connector","text":"A SaaS Connector Postman collection is available to execute the necessary steps to configure a SaaS connector. When running the Fides webserver, you may also navigate to the interactive API docs at http://{server_url}/docs (e.g., http://0.0.0.0:8080/docs ) to access the following endpoints.","title":"Configure a SaaS connector"},{"location":"saas_connectors/saas_connectors/#create-a-connection-of-type-saas","text":"PATCH api/v1/connection 1 2 3 4 5 6 7 8 [ { \"name\" : \"SaaS Application\" , \"key\" : { saas_key }, \"connection_type\" : \"saas\" , \"access\" : \"read\" } ]","title":"Create a Connection of type saas"},{"location":"saas_connectors/saas_connectors/#add-a-saas-config-in-json-format","text":"PATCH api/v1/connection/{saas_key}/saas_config 1 2 3 4 5 6 { \"fides_key\" : \"mailchimp_connector_example\" , \"name\" : \"Mailchimp SaaS Config\" , \"type\" : \"mailchimp\" , \"description\" : \"A sample schema representing the Mailchimp connector for fides\" ...","title":"Add a SaaS Config (in JSON format)"},{"location":"saas_connectors/saas_connectors/#configure-your-secrets","text":"PUT api/v1/connection/{saas_key}/secret 1 2 3 4 5 { \"domain\" : \"{mailchimp_domain}\" , \"username\" : \"{mailchimp_username}\" , \"api_key\" : \"{mailchimp_api_key}\" }","title":"Configure your secrets"},{"location":"saas_connectors/saas_connectors/#add-a-dataset-in-json-format","text":"PUT api/v1/connection/{saas_key}/dataset 1 2 3 4 5 6 7 8 9 [ { \"fides_key\" : \"mailchimp_connector_example\" , \"name\" : \"Mailchimp Dataset\" , \"description\" : \"A sample dataset representing the Mailchimp connector for fidesops\" , \"collections\" :[ { \"name\" : \"messages\" ...","title":"Add a Dataset (in JSON format)"},{"location":"saas_connectors/saas_connectors/#additional-considerations","text":"The following constraints are enforced by the API validation: A SaaS connector dataset cannot have any identities or references in the fidesops_meta . These relationships must be defined in the SaaS config . SaaS config references can only have a direction of from . The fides_key between the SaaS config and the Dataset must match in order to be associated.","title":"Additional considerations"},{"location":"saas_connectors/saas_connectors/#set-up-a-saas-connector-from-a-template","text":"To create all the resources necessary to set up a SaaS Connector in one request, you can create a connector from a template. This creates a saas Connection with your supplied name and description, using your supplied secrets . The example below creates a mailchimp saas connector, and would need the relevant mailchimp secrets . Your instance_key will become the identifier for the related Dataset . By default, the saas connection config is enabled with write access. POST /connection/instantiate/mailchimp 1 2 3 4 5 6 7 8 9 10 { \"name\" : \"My Mailchimp connector\" , \"description\" : \"Production Mailchimp Instance\" , \"secrets\" : { \"domain\" : \"{{mailchimp_domain}}\" , \"api_key\" : \"{{mailchimp_api_key}}\" , \"username\" : \"{{mailchimp_username}}\" }, \"instance_key\" : \"primary_mailchimp\" , }","title":"Set up a SaaS connector from a template"},{"location":"saas_connectors/saas_oauth2/","text":"SaaS connectors support two OAuth2 flows: Authorization Code : oauth2_authorization_code Client Credentials : oauth2_client_credentials This Authentication Code flow has the following configuration values: authorization_request : The request to build the URL that is presented to the user to authenticate this connection. token_request : The request made to retrieve the access token after the authorization code is returned via the /oauth/callback endpoint. refresh_request ( optional ): The request to refresh an access token. expires_in ( optional ): The lifetime of an access token (in seconds). This is used if the OAuth2 workflow in use does not provide expiration information ( RFC 6749 Section 5.1 ). The Client Credential flow has all these values except for authorization_request since it is not required for this flow. Sample Configuration Each OAuth2 request is fully configurable to account for the different ways the parameters can be mapped to a request. The following examples demonstrate the requests generated from sample configuration files. OAuth2 Authorization Code example 1 2 3 4 5 6 7 8 9 authentication : strategy : oauth2_authorization_code configuration : authorization_request : ... token_request : ... refresh_request : ... Authorization Request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 authorization_request : method : GET path : /auth/authorize query_params : - name : client_id value : <client_id> - name : redirect_uri value : <redirect_uri> - name : response_type value : code - name : scope value : <scope> - name : state value : <state> The above authentication_request will generate the following: GET request 1 https://<domain>/auth/authorize?client_id=<client_id>&redirect_uri=<redirect_uri>&response_type=code&scope=<scope>&state=<state> The placeholders are sourced from the values defined in the connector_params of your SaaS config. The <state> placeholder is generated automatically with each authorization request. This authorization URL can be retrieved by calling: GET request 1 https://{{domain}}/api/v1/connection/{{connection_key}}/authorize Token Request 1 2 3 4 5 6 7 8 9 10 11 12 token_request : method : POST path : /oauth/token query_params : - name : client_id value : <client_id> - name : client_secret value : <client_secret> - name : grant_type value : authorization_code - name : code value : <code> The <code> placeholder is defined automatically by Fides. The above token_request configuration generates the following: GET Request 1 https://<domain>/oauth_token?client_id=<client_id>&client_secret=<client_secret>&grant_type=authorization_code&code=<code> This request is called automatically after Fides receives a callback response to the https://{{domain}}/api/v1/oauth/callback endpoint. Refresh Request 1 2 3 4 5 6 7 8 9 10 11 12 refresh_request : method : POST path : /oauth/token query_params : - name : client_id value : <client_id> - name : client_secret value : <client_secret> - name : grant_type value : refresh_token - name : refresh_token value : <refresh_token> The <refresh_token> placeholder is defined automatically by Fides. The above refresh_request configuration generates the following: 1 GET https://<domain>/oauth_token?client_id=<client_id>&client_secret=<client_secret>&grant_type=refresh_token&refresh_token=<refresh_token> This is called automatically when the access_token is about to expire. The expiration is usually defined in the response to the token request. If the expiration is not returned by the API, it can be specified manually by setting the expires_in field (which is defined in seconds): 1 2 3 4 5 6 7 8 9 10 authentication : strategy : oauth2_authorization_code configuration : expires_in : 3600 authorization_request : ... token_request : ... refresh_request : ... Usage Checklist To use OAuth2 as a connection strategy, the following must be configured first: For All OAuth2 Flows Per-connector Configuration Fides must be able to connect to the SaaS provider (Outreach, Salesforce, etc.). A Client ID and Client Secret must be generated within the SaaS provider\u2019s admin console. This is dependent on the individual SaaS provider. Refer to the provider's documentation. The connector using OAuth2 is configured using the steps for how to configure a SaaS connector . Additional Steps for Authentication Code Flow One-time Configuration A callback server or network rules are required to forward the callback response from the SaaS providers to an instance of Fides. This is dependent on the user environment where Fides is deployed, and is out of scope for this documentation. These incoming requests must be routed to https://{{host}}/api/v1/oauth/callback . Per-connector Configuration The Redirect URI must be registered within the SaaS provider's admin console. The OAuth2 workflow is initialized by following the URL returned from https://{{domain}}/api/v1/connection/{{connection_key}}/authorize . OAuth2 Authentication Code Flow Diagram","title":"SaaS OAuth2 Configuration"},{"location":"saas_connectors/saas_oauth2/#sample-configuration","text":"Each OAuth2 request is fully configurable to account for the different ways the parameters can be mapped to a request. The following examples demonstrate the requests generated from sample configuration files. OAuth2 Authorization Code example 1 2 3 4 5 6 7 8 9 authentication : strategy : oauth2_authorization_code configuration : authorization_request : ... token_request : ... refresh_request : ...","title":"Sample Configuration"},{"location":"saas_connectors/saas_oauth2/#authorization-request","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 authorization_request : method : GET path : /auth/authorize query_params : - name : client_id value : <client_id> - name : redirect_uri value : <redirect_uri> - name : response_type value : code - name : scope value : <scope> - name : state value : <state> The above authentication_request will generate the following: GET request 1 https://<domain>/auth/authorize?client_id=<client_id>&redirect_uri=<redirect_uri>&response_type=code&scope=<scope>&state=<state> The placeholders are sourced from the values defined in the connector_params of your SaaS config. The <state> placeholder is generated automatically with each authorization request. This authorization URL can be retrieved by calling: GET request 1 https://{{domain}}/api/v1/connection/{{connection_key}}/authorize","title":"Authorization Request"},{"location":"saas_connectors/saas_oauth2/#token-request","text":"1 2 3 4 5 6 7 8 9 10 11 12 token_request : method : POST path : /oauth/token query_params : - name : client_id value : <client_id> - name : client_secret value : <client_secret> - name : grant_type value : authorization_code - name : code value : <code> The <code> placeholder is defined automatically by Fides. The above token_request configuration generates the following: GET Request 1 https://<domain>/oauth_token?client_id=<client_id>&client_secret=<client_secret>&grant_type=authorization_code&code=<code> This request is called automatically after Fides receives a callback response to the https://{{domain}}/api/v1/oauth/callback endpoint.","title":"Token Request"},{"location":"saas_connectors/saas_oauth2/#refresh-request","text":"1 2 3 4 5 6 7 8 9 10 11 12 refresh_request : method : POST path : /oauth/token query_params : - name : client_id value : <client_id> - name : client_secret value : <client_secret> - name : grant_type value : refresh_token - name : refresh_token value : <refresh_token> The <refresh_token> placeholder is defined automatically by Fides. The above refresh_request configuration generates the following: 1 GET https://<domain>/oauth_token?client_id=<client_id>&client_secret=<client_secret>&grant_type=refresh_token&refresh_token=<refresh_token> This is called automatically when the access_token is about to expire. The expiration is usually defined in the response to the token request. If the expiration is not returned by the API, it can be specified manually by setting the expires_in field (which is defined in seconds): 1 2 3 4 5 6 7 8 9 10 authentication : strategy : oauth2_authorization_code configuration : expires_in : 3600 authorization_request : ... token_request : ... refresh_request : ...","title":"Refresh Request"},{"location":"saas_connectors/saas_oauth2/#usage-checklist","text":"To use OAuth2 as a connection strategy, the following must be configured first:","title":"Usage Checklist"},{"location":"saas_connectors/saas_oauth2/#for-all-oauth2-flows","text":"","title":"For All OAuth2 Flows"},{"location":"saas_connectors/saas_oauth2/#per-connector-configuration","text":"Fides must be able to connect to the SaaS provider (Outreach, Salesforce, etc.). A Client ID and Client Secret must be generated within the SaaS provider\u2019s admin console. This is dependent on the individual SaaS provider. Refer to the provider's documentation. The connector using OAuth2 is configured using the steps for how to configure a SaaS connector .","title":"Per-connector Configuration"},{"location":"saas_connectors/saas_oauth2/#additional-steps-for-authentication-code-flow","text":"","title":"Additional Steps for Authentication Code Flow"},{"location":"saas_connectors/saas_oauth2/#one-time-configuration","text":"A callback server or network rules are required to forward the callback response from the SaaS providers to an instance of Fides. This is dependent on the user environment where Fides is deployed, and is out of scope for this documentation. These incoming requests must be routed to https://{{host}}/api/v1/oauth/callback .","title":"One-time Configuration"},{"location":"saas_connectors/saas_oauth2/#per-connector-configuration_1","text":"The Redirect URI must be registered within the SaaS provider's admin console. The OAuth2 workflow is initialized by following the URL returned from https://{{domain}}/api/v1/connection/{{connection_key}}/authorize .","title":"Per-connector Configuration"},{"location":"saas_connectors/saas_oauth2/#oauth2-authentication-code-flow-diagram","text":"","title":"OAuth2 Authentication Code Flow Diagram"},{"location":"saas_connectors/saas_pagination/","text":"SaaS Pagination These pagination strategies allow Fides to incrementally retrieve content from SaaS APIs. APIs can vary in the way subsequent pages are accessed so these configurable options aim to cover a majority of common use cases. Supported strategies offset : Iterates through the available pages by incrementing the value of a query param. link : Uses links returned in the headers or the body to get to the next page. cursor : Uses a value from the last-retrieved object to use as a query param pointing to the next set of results. Offset This strategy can be used to iterate through pages, or to define the offset for a batch of results. In either case, this strategy increments the specified query param by the increment_by value until no more results are returned or the limit is reached. Configuration details incremental_param ( str ): The query param to increment the value for. increment_by ( int ): The value to increment the incremental_param after each set of results. limit ( str ): The max value the incremental_param can reach. Example This example would take the page query param and increment it by 1 until the limit of 10 is reached or no more results are returned (whichever comes first). 1 2 3 4 5 6 pagination : strategy : offset configuration : incremental_param : page increment_by : 1 limit : 10 Link This strategy is used when the link to the next page is provided as part of the API response. The link is read from the headers or the body and used to get the next page of results. Configuration details source ( str ): The location to get the link from, can be either headers or body . path ( str ): The expression used to refer to the location of the link within the headers or the body. Examples The source value of headers is meant to be used with responses following RFC 5988 . 1 2 Link: <https://api.host.com/conversations?page_ref=ad6f38r3>; rel=\"next\", <https://api.host.com/conversations?page_ref=gss8ap4g>; rel=\"prev\" Given this Link header, we can specify a rel of next (case-insensitive). This indicates that we are looking in the Link header with a rel of next. 1 2 3 4 5 pagination : strategy : link configuration : source : headers rel : next We can also access links returned in the body. If we receive this value in the body: 1 2 3 4 5 6 7 { ... \"next_page\" : { \"url\" : \"https://api.host.com/conversations?page_ref=ad6f38r3\" } ... } We can use the path value of next_page.url as the expression to access the url. 1 2 3 4 5 pagination : strategy : link configuration : source : body path : next_page.url Cursor This strategy is used when a specific value from a response object is used as a cursor to determine the starting point for the next set of results. Configuration Details cursor_param ( str ): The name of the query param to assign the cursor value to. field ( str ): The field to read from the most recently retrieved object to use as the cursor value. Examples If an API request returns the following: 1 2 3 4 5 6 7 { \"messages\" : [ { \"id\" : 1 , \"msg\" : \"this is\" }, { \"id\" : 2 , \"msg\" : \"a\" } { \"id\" : 3 , \"msg\" : \"test\" } ] } This strategy will take the field id from the last item returned and generate a new request with a query param of after=3 1 2 3 4 5 pagination : strategy : cursor configuration : cursor_param : after field : id","title":"SaaS Pagination"},{"location":"saas_connectors/saas_pagination/#saas-pagination","text":"These pagination strategies allow Fides to incrementally retrieve content from SaaS APIs. APIs can vary in the way subsequent pages are accessed so these configurable options aim to cover a majority of common use cases.","title":"SaaS Pagination"},{"location":"saas_connectors/saas_pagination/#supported-strategies","text":"offset : Iterates through the available pages by incrementing the value of a query param. link : Uses links returned in the headers or the body to get to the next page. cursor : Uses a value from the last-retrieved object to use as a query param pointing to the next set of results.","title":"Supported strategies"},{"location":"saas_connectors/saas_pagination/#offset","text":"This strategy can be used to iterate through pages, or to define the offset for a batch of results. In either case, this strategy increments the specified query param by the increment_by value until no more results are returned or the limit is reached.","title":"Offset"},{"location":"saas_connectors/saas_pagination/#configuration-details","text":"incremental_param ( str ): The query param to increment the value for. increment_by ( int ): The value to increment the incremental_param after each set of results. limit ( str ): The max value the incremental_param can reach.","title":"Configuration details"},{"location":"saas_connectors/saas_pagination/#example","text":"This example would take the page query param and increment it by 1 until the limit of 10 is reached or no more results are returned (whichever comes first). 1 2 3 4 5 6 pagination : strategy : offset configuration : incremental_param : page increment_by : 1 limit : 10","title":"Example"},{"location":"saas_connectors/saas_pagination/#link","text":"This strategy is used when the link to the next page is provided as part of the API response. The link is read from the headers or the body and used to get the next page of results.","title":"Link"},{"location":"saas_connectors/saas_pagination/#configuration-details_1","text":"source ( str ): The location to get the link from, can be either headers or body . path ( str ): The expression used to refer to the location of the link within the headers or the body.","title":"Configuration details"},{"location":"saas_connectors/saas_pagination/#examples","text":"The source value of headers is meant to be used with responses following RFC 5988 . 1 2 Link: <https://api.host.com/conversations?page_ref=ad6f38r3>; rel=\"next\", <https://api.host.com/conversations?page_ref=gss8ap4g>; rel=\"prev\" Given this Link header, we can specify a rel of next (case-insensitive). This indicates that we are looking in the Link header with a rel of next. 1 2 3 4 5 pagination : strategy : link configuration : source : headers rel : next We can also access links returned in the body. If we receive this value in the body: 1 2 3 4 5 6 7 { ... \"next_page\" : { \"url\" : \"https://api.host.com/conversations?page_ref=ad6f38r3\" } ... } We can use the path value of next_page.url as the expression to access the url. 1 2 3 4 5 pagination : strategy : link configuration : source : body path : next_page.url","title":"Examples"},{"location":"saas_connectors/saas_pagination/#cursor","text":"This strategy is used when a specific value from a response object is used as a cursor to determine the starting point for the next set of results.","title":"Cursor"},{"location":"saas_connectors/saas_pagination/#configuration-details_2","text":"cursor_param ( str ): The name of the query param to assign the cursor value to. field ( str ): The field to read from the most recently retrieved object to use as the cursor value.","title":"Configuration Details"},{"location":"saas_connectors/saas_pagination/#examples_1","text":"If an API request returns the following: 1 2 3 4 5 6 7 { \"messages\" : [ { \"id\" : 1 , \"msg\" : \"this is\" }, { \"id\" : 2 , \"msg\" : \"a\" } { \"id\" : 3 , \"msg\" : \"test\" } ] } This strategy will take the field id from the last item returned and generate a new request with a query param of after=3 1 2 3 4 5 pagination : strategy : cursor configuration : cursor_param : after field : id","title":"Examples"},{"location":"saas_connectors/saas_postprocessors/","text":"SaaS Post-Processors Post-processors are, in essence, data transformers. Given data from an endpoint, we can add specific processors to transform the data into a format we need for subject requests. Configuration Post-processors are configured within the endpoints section of a saas_config : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 endpoints : - name : messages requests : read : method : GET path : /conversations/<id>/messages param_values : ... postprocessors : - strategy : unwrap configuration : data_path : conversation_messages - strategy : filter configuration : field : from_email value : identity : email Note: Order matters as it's defined in the config. In the above example, unwrap will be run first, then the output of unwrap will be used in the filter strategy. Format subsequent requests Post-processors can format the results of your access requests for use in subsequent update or delete statements. For example, if we need to return the following in an access request: 1 2 3 4 5 { \"recipient\" : \"test@email.com\" , \"subscriptions\" : [{ \"id\" : \"123\" , \"subscribed\" : \"TRUE\" }]} And we needed to perform an update request for each item within subscriptions , where subscribed = TRUE , then we'd need the following config for our update request: 1 2 3 4 5 6 7 8 update : ... data_path : subscriptionStatuses postprocessors : - strategy : filter configuration : field : subscribed value : TRUE Supported Strategies unwrap : Gets object at given data path. filter : Removes data that does not match a given field and value. Filter Filters object or array given field name and value. Value can reference a dynamic identity passed in through the request OR be a hard-coded value. Configuration details strategy : filter configuration : field ( str ): Corresponds to the field on which to filter. For example, we wish to filter where email_contact == \"bob@mail.com\" , then field will be email_contact . value ( str ): Value to search for when filtering (e.g. hard-coded bob@mail.com ) or Dict of identity path: identity ( str ): Identity object from subject request (e.g. email or phone_number ) exact (optional bool defaults to True): value and field value must be the same length (no extra characters). case_sensitive (optional bool defaults to True): Cases must match between value and field value. Examples Post-Processor Config: 1 2 3 4 5 - strategy : filter configuration : field : email_contact value : identity : email Identity data passed in through request: 1 2 3 { \"email\" : \"somebody@email.com\" } Data to be processed: 1 2 3 4 5 6 7 8 9 10 11 12 [ { \"id\" : 1397429347 , \"email_contact\" : \"somebody@email.com\" , \"name\" : \"Somebody Awesome\" }, { \"id\" : 238475234 , \"email_contact\" : \"somebody-else@email.com\" , \"name\" : \"Somebody Cool\" } ] Result: 1 2 3 4 5 6 7 [ { \"id\" : 1397429347 , \"email_contact\" : \"somebody@email.com\" , \"name\" : \"Somebody Awesome\" } ] By default, this filter is exact and case-sensitive. Post-Processor Config: 1 2 3 4 5 6 7 - strategy : filter configuration : field : email_contact value : identity : email exact : False case_sensitive : False Identity data passed in through request: 1 2 3 { \"email\" : \"somebody@email.com\" } Data to be processed: 1 2 3 4 5 6 7 8 9 10 11 12 [ { \"id\" : 1397429347 , \"email_contact\" : \"[Somebody Awesome] SOMEBODY@email.com\" , \"name\" : \"Somebody Awesome\" }, { \"id\" : 1397429348 , \"email_contact\" : \"somebody@email.com\" , \"name\" : \"Somebody Awesome\" } ] Result: 1 2 3 4 5 6 7 8 9 10 11 12 [ { \"id\" : 1397429347 , \"email_contact\" : \"[Somebody Awesome] SOMEBODY@email.com\" , \"name\" : \"Somebody Awesome\" }, { \"id\" : 1397429348 , \"email_contact\" : \"somebody@email.com\" , \"name\" : \"Somebody Awesome\" } ] We can configure how strict the filter is by setting exact and case_sensitive both to False. This allows our value to be a substring of a longer string, and to ignore case (upper vs lower case). Note: Type casting is not supported at this time. We currently only support filtering by string values. e.g. bob@mail.com and not 12344245 . Unwrap Given a path to a dict/list, returns the dict/list at that location. Configuration details strategy : unwrap configuration : data_path ( str ): Gives the path to desired object. E.g. exact_matches.members will attempt to get the members object on the exact_matches object. Example Post-Processor Config: 1 2 3 - strategy : unwrap configuration : data_path : exact_matches.members Data to be processed: 1 2 3 4 5 6 7 8 { \"exact_matches\" : { \"members\" : [ { \"howdy\" : 123 }, { \"meow\" : 841 } ] } } Result: 1 2 3 4 [ { \"howdy\" : 123 }, { \"meow\" : 841 } ]","title":"SaaS Post-Processors"},{"location":"saas_connectors/saas_postprocessors/#saas-post-processors","text":"Post-processors are, in essence, data transformers. Given data from an endpoint, we can add specific processors to transform the data into a format we need for subject requests.","title":"SaaS Post-Processors"},{"location":"saas_connectors/saas_postprocessors/#configuration","text":"Post-processors are configured within the endpoints section of a saas_config : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 endpoints : - name : messages requests : read : method : GET path : /conversations/<id>/messages param_values : ... postprocessors : - strategy : unwrap configuration : data_path : conversation_messages - strategy : filter configuration : field : from_email value : identity : email Note: Order matters as it's defined in the config. In the above example, unwrap will be run first, then the output of unwrap will be used in the filter strategy.","title":"Configuration"},{"location":"saas_connectors/saas_postprocessors/#format-subsequent-requests","text":"Post-processors can format the results of your access requests for use in subsequent update or delete statements. For example, if we need to return the following in an access request: 1 2 3 4 5 { \"recipient\" : \"test@email.com\" , \"subscriptions\" : [{ \"id\" : \"123\" , \"subscribed\" : \"TRUE\" }]} And we needed to perform an update request for each item within subscriptions , where subscribed = TRUE , then we'd need the following config for our update request: 1 2 3 4 5 6 7 8 update : ... data_path : subscriptionStatuses postprocessors : - strategy : filter configuration : field : subscribed value : TRUE","title":"Format subsequent requests"},{"location":"saas_connectors/saas_postprocessors/#supported-strategies","text":"unwrap : Gets object at given data path. filter : Removes data that does not match a given field and value.","title":"Supported Strategies"},{"location":"saas_connectors/saas_postprocessors/#filter","text":"Filters object or array given field name and value. Value can reference a dynamic identity passed in through the request OR be a hard-coded value.","title":"Filter"},{"location":"saas_connectors/saas_postprocessors/#configuration-details","text":"strategy : filter configuration : field ( str ): Corresponds to the field on which to filter. For example, we wish to filter where email_contact == \"bob@mail.com\" , then field will be email_contact . value ( str ): Value to search for when filtering (e.g. hard-coded bob@mail.com ) or Dict of identity path: identity ( str ): Identity object from subject request (e.g. email or phone_number ) exact (optional bool defaults to True): value and field value must be the same length (no extra characters). case_sensitive (optional bool defaults to True): Cases must match between value and field value.","title":"Configuration details"},{"location":"saas_connectors/saas_postprocessors/#examples","text":"Post-Processor Config: 1 2 3 4 5 - strategy : filter configuration : field : email_contact value : identity : email Identity data passed in through request: 1 2 3 { \"email\" : \"somebody@email.com\" } Data to be processed: 1 2 3 4 5 6 7 8 9 10 11 12 [ { \"id\" : 1397429347 , \"email_contact\" : \"somebody@email.com\" , \"name\" : \"Somebody Awesome\" }, { \"id\" : 238475234 , \"email_contact\" : \"somebody-else@email.com\" , \"name\" : \"Somebody Cool\" } ] Result: 1 2 3 4 5 6 7 [ { \"id\" : 1397429347 , \"email_contact\" : \"somebody@email.com\" , \"name\" : \"Somebody Awesome\" } ] By default, this filter is exact and case-sensitive. Post-Processor Config: 1 2 3 4 5 6 7 - strategy : filter configuration : field : email_contact value : identity : email exact : False case_sensitive : False Identity data passed in through request: 1 2 3 { \"email\" : \"somebody@email.com\" } Data to be processed: 1 2 3 4 5 6 7 8 9 10 11 12 [ { \"id\" : 1397429347 , \"email_contact\" : \"[Somebody Awesome] SOMEBODY@email.com\" , \"name\" : \"Somebody Awesome\" }, { \"id\" : 1397429348 , \"email_contact\" : \"somebody@email.com\" , \"name\" : \"Somebody Awesome\" } ] Result: 1 2 3 4 5 6 7 8 9 10 11 12 [ { \"id\" : 1397429347 , \"email_contact\" : \"[Somebody Awesome] SOMEBODY@email.com\" , \"name\" : \"Somebody Awesome\" }, { \"id\" : 1397429348 , \"email_contact\" : \"somebody@email.com\" , \"name\" : \"Somebody Awesome\" } ] We can configure how strict the filter is by setting exact and case_sensitive both to False. This allows our value to be a substring of a longer string, and to ignore case (upper vs lower case). Note: Type casting is not supported at this time. We currently only support filtering by string values. e.g. bob@mail.com and not 12344245 .","title":"Examples"},{"location":"saas_connectors/saas_postprocessors/#unwrap","text":"Given a path to a dict/list, returns the dict/list at that location.","title":"Unwrap"},{"location":"saas_connectors/saas_postprocessors/#configuration-details_1","text":"strategy : unwrap configuration : data_path ( str ): Gives the path to desired object. E.g. exact_matches.members will attempt to get the members object on the exact_matches object.","title":"Configuration details"},{"location":"saas_connectors/saas_postprocessors/#example","text":"Post-Processor Config: 1 2 3 - strategy : unwrap configuration : data_path : exact_matches.members Data to be processed: 1 2 3 4 5 6 7 8 { \"exact_matches\" : { \"members\" : [ { \"howdy\" : 123 }, { \"meow\" : 841 } ] } } Result: 1 2 3 4 [ { \"howdy\" : 123 }, { \"meow\" : 841 } ]","title":"Example"},{"location":"saas_connectors/example_configs/adobe/","text":"Adobe Campaign Implementation Summary Fides uses the following Adobe Campaign endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Profile Yes Yes History Yes Yes Privacy Tool Yes Yes Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false . Example Adobe Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 saas_config : fides_key : adobe_campaign_connector_example name : Adobe Campaign SaaS Config type : adobe_campaign description : A schema representing the Adobe Campaign connector for Fides version : 0.0.1 connector_params : - name : domain default_value : mc.adobe.io - name : organization_id - name : namespace default_value : defaultNamespace1 description : The namespace to use for data protections requests - name : regulation description : The regulation to follow for data protection requests - name : client_id - name : access_token client_config : protocol : https host : <domain>/<organization_id> authentication : strategy : bearer configuration : token : <access_token> test_request : method : GET path : /campaign/profileAndServices/profile/PKey headers : - name : X-Api-Key value : <client_id> query_params : - name : _lineCount value : 1 param_values : - name : client_id connector_param : client_id endpoints : - name : profile requests : read : method : GET path : /campaign/profileAndServices/profile/byEmail headers : - name : X-Api-Key value : <client_id> query_params : - name : email value : <email> param_values : - name : client_id connector_param : client_id - name : email identity : email data_path : content - name : marketing_history requests : read : method : GET path : /campaign/profileAndServices/history/byEmail headers : - name : X-Api-Key value : <client_id> query_params : - name : email value : <email> param_values : - name : client_id connector_param : client_id - name : email identity : email data_path : content data_protection_request : method : POST path : /campaign/privacy/privacyTool headers : - name : X-Api-Key value : <client_id> param_values : - name : client_id connector_param : client_id - name : regulation connector_param : regulation - name : namespace connector_param : namespace - name : reconciliation_value identity : email body : | { \"name\": \"<privacy_request_id>\", \"namespaceName\": \"<namespace>\", \"reconciliationValue\": \"<reconciliation_value>\", \"regulation\": \"<regulation>\", \"label\": \"Erasure Request\", \"type\": \"delete\" }","title":"Adobe Campaign"},{"location":"saas_connectors/example_configs/adobe/#adobe-campaign","text":"","title":"Adobe Campaign"},{"location":"saas_connectors/example_configs/adobe/#implementation-summary","text":"Fides uses the following Adobe Campaign endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Profile Yes Yes History Yes Yes Privacy Tool Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/adobe/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/adobe/#example-adobe-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 saas_config : fides_key : adobe_campaign_connector_example name : Adobe Campaign SaaS Config type : adobe_campaign description : A schema representing the Adobe Campaign connector for Fides version : 0.0.1 connector_params : - name : domain default_value : mc.adobe.io - name : organization_id - name : namespace default_value : defaultNamespace1 description : The namespace to use for data protections requests - name : regulation description : The regulation to follow for data protection requests - name : client_id - name : access_token client_config : protocol : https host : <domain>/<organization_id> authentication : strategy : bearer configuration : token : <access_token> test_request : method : GET path : /campaign/profileAndServices/profile/PKey headers : - name : X-Api-Key value : <client_id> query_params : - name : _lineCount value : 1 param_values : - name : client_id connector_param : client_id endpoints : - name : profile requests : read : method : GET path : /campaign/profileAndServices/profile/byEmail headers : - name : X-Api-Key value : <client_id> query_params : - name : email value : <email> param_values : - name : client_id connector_param : client_id - name : email identity : email data_path : content - name : marketing_history requests : read : method : GET path : /campaign/profileAndServices/history/byEmail headers : - name : X-Api-Key value : <client_id> query_params : - name : email value : <email> param_values : - name : client_id connector_param : client_id - name : email identity : email data_path : content data_protection_request : method : POST path : /campaign/privacy/privacyTool headers : - name : X-Api-Key value : <client_id> param_values : - name : client_id connector_param : client_id - name : regulation connector_param : regulation - name : namespace connector_param : namespace - name : reconciliation_value identity : email body : | { \"name\": \"<privacy_request_id>\", \"namespaceName\": \"<namespace>\", \"reconciliationValue\": \"<reconciliation_value>\", \"regulation\": \"<regulation>\", \"label\": \"Erasure Request\", \"type\": \"delete\" }","title":"Example Adobe Configuration"},{"location":"saas_connectors/example_configs/hubspot/","text":"Hubspot Implementation Summary Fides uses the following Hubspot endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Search Yes No Contacts Yes Yes Owners Yes No Communication Preferences Yes Yes Users Yes Yes Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false . Example Hubspot Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 saas_config : fides_key : hubspot_connector_example name : Hubspot SaaS Config type : hubspot description : A sample schema representing the Hubspot connector for Fides version : 0.0.1 connector_params : - name : domain default_value : api.hubapi.com - name : private_app_token client_config : protocol : https host : <domain> authentication : strategy : bearer configuration : token : <private_app_token> test_request : method : GET path : /companies/v2/companies/paged endpoints : - name : contacts requests : read : path : /crm/v3/objects/contacts/search method : POST body : | { \"filterGroups\": [{ \"filters\": [{ \"value\": \"<email>\", \"propertyName\": \"email\", \"operator\": \"EQ\" }] }] } query_params : - name : limit value : 100 param_values : - name : email identity : email data_path : results pagination : strategy : link configuration : source : body path : paging.next.link update : path : /crm/v3/objects/contacts/<contactId> method : PATCH body : | { <masked_object_fields> } param_values : - name : contactId references : - dataset : hubspot_connector_example field : contacts.id direction : from - name : owners requests : read : path : /crm/v3/owners method : GET query_params : - name : limit value : 100 param_values : - name : placeholder identity : email postprocessors : - strategy : unwrap configuration : data_path : results - strategy : filter configuration : field : email value : identity : email pagination : strategy : link configuration : source : body path : paging.next.link - name : subscription_preferences requests : read : path : /communication-preferences/v3/status/email/<email> method : GET param_values : - name : email identity : email update : path : /communication-preferences/v3/unsubscribe method : POST body : | { \"emailAddress\": \"<email>\", \"subscriptionId\": \"<subscriptionId>\", \"legalBasis\": \"LEGITIMATE_INTEREST_CLIENT\", \"legalBasisExplanation\": \"At users request, we opted them out\" } data_path : subscriptionStatuses param_values : - name : email identity : email - name : subscriptionId references : - dataset : hubspot_connector_example field : subscription_preferences.id direction : from postprocessors : - strategy : filter configuration : field : status value : SUBSCRIBED - name : users requests : read : path : /settings/v3/users/ method : GET query_params : - name : limit value : 100 param_values : - name : placeholder identity : email postprocessors : - strategy : unwrap configuration : data_path : results - strategy : filter configuration : field : email value : identity : email pagination : strategy : link configuration : source : body path : paging.next.link delete : path : /settings/v3/users/<userId> method : DELETE param_values : - name : userId references : - dataset : hubspot_connector_example field : users.id direction : from","title":"Hubspot"},{"location":"saas_connectors/example_configs/hubspot/#hubspot","text":"","title":"Hubspot"},{"location":"saas_connectors/example_configs/hubspot/#implementation-summary","text":"Fides uses the following Hubspot endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Search Yes No Contacts Yes Yes Owners Yes No Communication Preferences Yes Yes Users Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/hubspot/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/hubspot/#example-hubspot-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 saas_config : fides_key : hubspot_connector_example name : Hubspot SaaS Config type : hubspot description : A sample schema representing the Hubspot connector for Fides version : 0.0.1 connector_params : - name : domain default_value : api.hubapi.com - name : private_app_token client_config : protocol : https host : <domain> authentication : strategy : bearer configuration : token : <private_app_token> test_request : method : GET path : /companies/v2/companies/paged endpoints : - name : contacts requests : read : path : /crm/v3/objects/contacts/search method : POST body : | { \"filterGroups\": [{ \"filters\": [{ \"value\": \"<email>\", \"propertyName\": \"email\", \"operator\": \"EQ\" }] }] } query_params : - name : limit value : 100 param_values : - name : email identity : email data_path : results pagination : strategy : link configuration : source : body path : paging.next.link update : path : /crm/v3/objects/contacts/<contactId> method : PATCH body : | { <masked_object_fields> } param_values : - name : contactId references : - dataset : hubspot_connector_example field : contacts.id direction : from - name : owners requests : read : path : /crm/v3/owners method : GET query_params : - name : limit value : 100 param_values : - name : placeholder identity : email postprocessors : - strategy : unwrap configuration : data_path : results - strategy : filter configuration : field : email value : identity : email pagination : strategy : link configuration : source : body path : paging.next.link - name : subscription_preferences requests : read : path : /communication-preferences/v3/status/email/<email> method : GET param_values : - name : email identity : email update : path : /communication-preferences/v3/unsubscribe method : POST body : | { \"emailAddress\": \"<email>\", \"subscriptionId\": \"<subscriptionId>\", \"legalBasis\": \"LEGITIMATE_INTEREST_CLIENT\", \"legalBasisExplanation\": \"At users request, we opted them out\" } data_path : subscriptionStatuses param_values : - name : email identity : email - name : subscriptionId references : - dataset : hubspot_connector_example field : subscription_preferences.id direction : from postprocessors : - strategy : filter configuration : field : status value : SUBSCRIBED - name : users requests : read : path : /settings/v3/users/ method : GET query_params : - name : limit value : 100 param_values : - name : placeholder identity : email postprocessors : - strategy : unwrap configuration : data_path : results - strategy : filter configuration : field : email value : identity : email pagination : strategy : link configuration : source : body path : paging.next.link delete : path : /settings/v3/users/<userId> method : DELETE param_values : - name : userId references : - dataset : hubspot_connector_example field : users.id direction : from","title":"Example Hubspot Configuration"},{"location":"saas_connectors/example_configs/mailchimp/","text":"Mailchimp Implementation Summary Fides uses the following Mailchimp endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Messages Yes No Conversations Yes No Members Yes Yes Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false . Example Mailchimp Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 saas_config : fides_key : mailchimp_connector_example name : Mailchimp SaaS Config description : A sample schema representing the Mailchimp connector for Fides version : 0.0.1 connector_params : - name : domain - name : username - name : api_key client_config : protocol : https host : <domain> authentication : strategy : basic configuration : username : <username> password : <api_key> test_request : method : GET path : /3.0/lists endpoints : - name : messages requests : read : method : GET path : /3.0/conversations/<conversation_id>/messages param_values : - name : conversation_id references : - dataset : mailchimp_connector_example field : conversations.id direction : from data_path : conversation_messages postprocessors : - strategy : filter configuration : field : from_email value : identity : email - name : conversations requests : read : method : GET path : /3.0/conversations query_params : - name : count value : 1000 - name : offset value : 0 param_values : - name : placeholder identity : email data_path : conversations pagination : strategy : offset configuration : incremental_param : offset increment_by : 1000 limit : 10000 - name : member requests : read : method : GET path : /3.0/search-members query_params : - name : query value : <email> param_values : - name : email identity : email data_path : exact_matches.members update : method : PUT path : /3.0/lists/<list_id>/members/<subscriber_hash> param_values : - name : list_id references : - dataset : mailchimp_connector_example field : member.list_id direction : from - name : subscriber_hash references : - dataset : mailchimp_connector_example field : member.id direction : from","title":"Mailchimp"},{"location":"saas_connectors/example_configs/mailchimp/#mailchimp","text":"","title":"Mailchimp"},{"location":"saas_connectors/example_configs/mailchimp/#implementation-summary","text":"Fides uses the following Mailchimp endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Messages Yes No Conversations Yes No Members Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/mailchimp/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/mailchimp/#example-mailchimp-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 saas_config : fides_key : mailchimp_connector_example name : Mailchimp SaaS Config description : A sample schema representing the Mailchimp connector for Fides version : 0.0.1 connector_params : - name : domain - name : username - name : api_key client_config : protocol : https host : <domain> authentication : strategy : basic configuration : username : <username> password : <api_key> test_request : method : GET path : /3.0/lists endpoints : - name : messages requests : read : method : GET path : /3.0/conversations/<conversation_id>/messages param_values : - name : conversation_id references : - dataset : mailchimp_connector_example field : conversations.id direction : from data_path : conversation_messages postprocessors : - strategy : filter configuration : field : from_email value : identity : email - name : conversations requests : read : method : GET path : /3.0/conversations query_params : - name : count value : 1000 - name : offset value : 0 param_values : - name : placeholder identity : email data_path : conversations pagination : strategy : offset configuration : incremental_param : offset increment_by : 1000 limit : 10000 - name : member requests : read : method : GET path : /3.0/search-members query_params : - name : query value : <email> param_values : - name : email identity : email data_path : exact_matches.members update : method : PUT path : /3.0/lists/<list_id>/members/<subscriber_hash> param_values : - name : list_id references : - dataset : mailchimp_connector_example field : member.list_id direction : from - name : subscriber_hash references : - dataset : mailchimp_connector_example field : member.id direction : from","title":"Example Mailchimp Configuration"},{"location":"saas_connectors/example_configs/outreach/","text":"Outreach Implementation Summary Fides uses the following Outreach endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Prospects Yes Yes Recipients Yes Yes Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false . Example Outreach Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 saas_config : fides_key : outreach_connector_example name : Outreach Example Config type : outreach description : A sample schema representing the Outreach connector for Fides version : 0.0.1 connector_params : - name : domain default_value : platform.segmentapis.com - name : requester_email description : The email of the Outreach user to associate with each automated compliance request (data_protection_request) - name : client_id - name : client_secret - name : redirect_uri - name : page_size description : The number of entries to return per page client_config : protocol : https host : <domain> authentication : strategy : oauth2_authorization_code configuration : authorization_request : method : GET path : /auth/authorize query_params : - name : client_id value : <client_id> - name : redirect_uri value : <redirect_uri> - name : response_type value : code - name : scope value : prospects.all recipients.all teams.all roles.all accounts.all audits.all callDispositions.all callPurposes.all calls.all complianceRequests.all contentCategories.all contentCategoryMemberships.all contentCategoryOwnerships.all duties.all emailAddresses.all events.all favorites.all mailAliases.all mailboxes.all mailings.all opportunities.all opportunityProspectRoles.all opportunityStages.all personas.all phoneNumbers.all profiles.all rulesets.all sequenceStates.all sequenceSteps.all sequenceTemplates.all sequences.all snippets.all stages.all taskPriorities.all tasks.all templates.all users.all webhooks.all - name : state value : <state> token_request : method : POST path : /oauth/token headers : - name : Content-Type value : application/x-www-form-urlencoded query_params : - name : client_id value : <client_id> - name : client_secret value : <client_secret> - name : grant_type value : authorization_code - name : code value : <code> - name : redirect_uri value : <redirect_uri> refresh_request : method : POST path : /oauth/token headers : - name : Content-Type value : application/x-www-form-urlencoded query_params : - name : client_id value : <client_id> - name : client_secret value : <client_secret> - name : redirect_uri value : <redirect_uri> - name : grant_type value : refresh_token - name : refresh_token value : <refresh_token> test_request : method : GET path : /api/v2/roles endpoints : - name : prospects requests : read : method : GET path : /api/v2/prospects query_params : - name : filter[emails] value : <email> param_values : - name : email identity : email data_path : data delete : method : POST path : /api/v2/complianceRequests param_values : - name : requester_email connector_param : requester_email - name : email identity : email body : | { \"data\": { \"type\": \"complianceRequest\", \"attributes\": { \"requester_email\": \"<requester_email>\", \"request_type\": \"Delete\", \"object_type\": \"Prospect\", \"request_object_email\": \"<email>\" } } } - name : recipients requests : read : method : GET path : /api/v2/recipients query_params : - name : page[size] value : <page_size> param_values : - name : page_size connector_param : page_size - name : placeholder identity : email data_path : data pagination : strategy : link configuration : source : body path : links.next postprocessors : - strategy : filter configuration : field : attributes.value value : identity : email exact : False case_sensitive : False delete : method : POST path : /api/v2/complianceRequests param_values : - name : requester_email connector_param : requester_email - name : email identity : email body : | { \"data\": { \"type\": \"complianceRequest\", \"attributes\": { \"requester_email\": \"<requester_email>\", \"request_type\": \"Delete\", \"object_type\": \"Recipient\", \"request_object_email\": \"<email>\" } } }","title":"Outreach"},{"location":"saas_connectors/example_configs/outreach/#outreach","text":"","title":"Outreach"},{"location":"saas_connectors/example_configs/outreach/#implementation-summary","text":"Fides uses the following Outreach endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Prospects Yes Yes Recipients Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/outreach/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/outreach/#example-outreach-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 saas_config : fides_key : outreach_connector_example name : Outreach Example Config type : outreach description : A sample schema representing the Outreach connector for Fides version : 0.0.1 connector_params : - name : domain default_value : platform.segmentapis.com - name : requester_email description : The email of the Outreach user to associate with each automated compliance request (data_protection_request) - name : client_id - name : client_secret - name : redirect_uri - name : page_size description : The number of entries to return per page client_config : protocol : https host : <domain> authentication : strategy : oauth2_authorization_code configuration : authorization_request : method : GET path : /auth/authorize query_params : - name : client_id value : <client_id> - name : redirect_uri value : <redirect_uri> - name : response_type value : code - name : scope value : prospects.all recipients.all teams.all roles.all accounts.all audits.all callDispositions.all callPurposes.all calls.all complianceRequests.all contentCategories.all contentCategoryMemberships.all contentCategoryOwnerships.all duties.all emailAddresses.all events.all favorites.all mailAliases.all mailboxes.all mailings.all opportunities.all opportunityProspectRoles.all opportunityStages.all personas.all phoneNumbers.all profiles.all rulesets.all sequenceStates.all sequenceSteps.all sequenceTemplates.all sequences.all snippets.all stages.all taskPriorities.all tasks.all templates.all users.all webhooks.all - name : state value : <state> token_request : method : POST path : /oauth/token headers : - name : Content-Type value : application/x-www-form-urlencoded query_params : - name : client_id value : <client_id> - name : client_secret value : <client_secret> - name : grant_type value : authorization_code - name : code value : <code> - name : redirect_uri value : <redirect_uri> refresh_request : method : POST path : /oauth/token headers : - name : Content-Type value : application/x-www-form-urlencoded query_params : - name : client_id value : <client_id> - name : client_secret value : <client_secret> - name : redirect_uri value : <redirect_uri> - name : grant_type value : refresh_token - name : refresh_token value : <refresh_token> test_request : method : GET path : /api/v2/roles endpoints : - name : prospects requests : read : method : GET path : /api/v2/prospects query_params : - name : filter[emails] value : <email> param_values : - name : email identity : email data_path : data delete : method : POST path : /api/v2/complianceRequests param_values : - name : requester_email connector_param : requester_email - name : email identity : email body : | { \"data\": { \"type\": \"complianceRequest\", \"attributes\": { \"requester_email\": \"<requester_email>\", \"request_type\": \"Delete\", \"object_type\": \"Prospect\", \"request_object_email\": \"<email>\" } } } - name : recipients requests : read : method : GET path : /api/v2/recipients query_params : - name : page[size] value : <page_size> param_values : - name : page_size connector_param : page_size - name : placeholder identity : email data_path : data pagination : strategy : link configuration : source : body path : links.next postprocessors : - strategy : filter configuration : field : attributes.value value : identity : email exact : False case_sensitive : False delete : method : POST path : /api/v2/complianceRequests param_values : - name : requester_email connector_param : requester_email - name : email identity : email body : | { \"data\": { \"type\": \"complianceRequest\", \"attributes\": { \"requester_email\": \"<requester_email>\", \"request_type\": \"Delete\", \"object_type\": \"Recipient\", \"request_object_email\": \"<email>\" } } }","title":"Example Outreach Configuration"},{"location":"saas_connectors/example_configs/salesforce/","text":"Salesforce Implementation Summary Fides uses the following Salesforce endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. For more information, see the Salesforce sObject API reference . Endpoint Right to Access Right to Delete Query Yes No Contact Yes Yes Case Yes Yes Lead Yes Yes Account Yes Yes CampaignMember Yes Yes Connection Settings Fidesops provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give fidesops permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fidesops.toml file is set to false . Example Salesforce Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 saas_config : fides_key : salesforce_connector_example name : Salesforce SaaS Config type : salesforce description : A sample schema representing the Salesforce connector for Fidesops version : 0.0.1 connector_params : - name : domain - name : username - name : password - name : client_id - name : client_secret - name : access_token client_config : protocol : https host : <domain> authentication : strategy : bearer configuration : token : <access_token> test_request : method : GET path : /services/data/v54.0/sobjects endpoints : - name : contact_list requests : read : method : GET path : /services/data/v54.0/query query_params : - name : q value : SELECT Id FROM Contact WHERE Email='<email>' param_values : - name : email identity : email data_path : records - name : contacts requests : read : method : GET path : /services/data/v54.0/sobjects/Contact/<contact_id> param_values : - name : contact_id references : - dataset : salesforce_connector_example field : contact_list.Id direction : from update : method : PATCH path : /services/data/v54.0/sobjects/Contact/<contact_id> body : | { <masked_object_fields> } param_values : - name : contact_id references : - dataset : salesforce_connector_example field : contacts.Id direction : from - name : case_list requests : read : method : GET path : /services/data/v54.0/query query_params : - name : q value : SELECT Id FROM Case WHERE ContactId='<contact_id>' param_values : - name : contact_id references : - dataset : salesforce_connector_example field : contact_list.Id direction : from data_path : records - name : cases requests : read : method : GET path : /services/data/v54.0/sobjects/Case/<case_id> param_values : - name : case_id references : - dataset : salesforce_connector_example field : case_list.Id direction : from update : method : PATCH path : /services/data/v54.0/sobjects/Case/<case_id> body : | { <masked_object_fields> } param_values : - name : case_id references : - dataset : salesforce_connector_example field : cases.Id direction : from - name : lead_list requests : read : method : GET path : /services/data/v54.0/query query_params : - name : q value : SELECT Id FROM Lead WHERE Email='<email>' param_values : - name : email identity : email data_path : records - name : leads requests : read : method : GET path : /services/data/v54.0/sobjects/Lead/<lead_id> param_values : - name : lead_id references : - dataset : salesforce_connector_example field : lead_list.Id direction : from update : method : PATCH path : /services/data/v54.0/sobjects/Lead/<lead_id> body : | { <masked_object_fields> } param_values : - name : lead_id references : - dataset : salesforce_connector_example field : leads.Id direction : from - name : accounts requests : read : method : GET path : /services/data/v54.0/sobjects/Account/<account_id> param_values : - name : account_id references : - dataset : salesforce_connector_example field : contacts.AccountId update : method : PATCH path : /services/data/v54.0/sobjects/Account/<account_id> body : | { <masked_object_fields> } param_values : - name : account_id references : - dataset : salesforce_connector_example field : accounts.Id direction : from - name : campaign_member_list requests : read : method : GET path : /services/data/v54.0/query query_params : - name : q value : SELECT Id FROM CampaignMember WHERE Email='<email>' param_values : - name : email identity : email data_path : records - name : campaign_members requests : read : method : GET path : /services/data/v54.0/sobjects/CampaignMember/<campaign_member_id> param_values : - name : campaign_member_id references : - dataset : salesforce_connector_example field : campaign_member_list.Id direction : from update : method : PATCH path : /services/data/v54.0/sobjects/CampaignMember/<campaign_member_id> body : | { <masked_object_fields> } param_values : - name : campaign_member_id references : - dataset : salesforce_connector_example field : campaign_members.Id direction : from","title":"Salesforce"},{"location":"saas_connectors/example_configs/salesforce/#salesforce","text":"","title":"Salesforce"},{"location":"saas_connectors/example_configs/salesforce/#implementation-summary","text":"Fides uses the following Salesforce endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. For more information, see the Salesforce sObject API reference . Endpoint Right to Access Right to Delete Query Yes No Contact Yes Yes Case Yes Yes Lead Yes Yes Account Yes Yes CampaignMember Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/salesforce/#connection-settings","text":"Fidesops provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give fidesops permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fidesops.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/salesforce/#example-salesforce-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 saas_config : fides_key : salesforce_connector_example name : Salesforce SaaS Config type : salesforce description : A sample schema representing the Salesforce connector for Fidesops version : 0.0.1 connector_params : - name : domain - name : username - name : password - name : client_id - name : client_secret - name : access_token client_config : protocol : https host : <domain> authentication : strategy : bearer configuration : token : <access_token> test_request : method : GET path : /services/data/v54.0/sobjects endpoints : - name : contact_list requests : read : method : GET path : /services/data/v54.0/query query_params : - name : q value : SELECT Id FROM Contact WHERE Email='<email>' param_values : - name : email identity : email data_path : records - name : contacts requests : read : method : GET path : /services/data/v54.0/sobjects/Contact/<contact_id> param_values : - name : contact_id references : - dataset : salesforce_connector_example field : contact_list.Id direction : from update : method : PATCH path : /services/data/v54.0/sobjects/Contact/<contact_id> body : | { <masked_object_fields> } param_values : - name : contact_id references : - dataset : salesforce_connector_example field : contacts.Id direction : from - name : case_list requests : read : method : GET path : /services/data/v54.0/query query_params : - name : q value : SELECT Id FROM Case WHERE ContactId='<contact_id>' param_values : - name : contact_id references : - dataset : salesforce_connector_example field : contact_list.Id direction : from data_path : records - name : cases requests : read : method : GET path : /services/data/v54.0/sobjects/Case/<case_id> param_values : - name : case_id references : - dataset : salesforce_connector_example field : case_list.Id direction : from update : method : PATCH path : /services/data/v54.0/sobjects/Case/<case_id> body : | { <masked_object_fields> } param_values : - name : case_id references : - dataset : salesforce_connector_example field : cases.Id direction : from - name : lead_list requests : read : method : GET path : /services/data/v54.0/query query_params : - name : q value : SELECT Id FROM Lead WHERE Email='<email>' param_values : - name : email identity : email data_path : records - name : leads requests : read : method : GET path : /services/data/v54.0/sobjects/Lead/<lead_id> param_values : - name : lead_id references : - dataset : salesforce_connector_example field : lead_list.Id direction : from update : method : PATCH path : /services/data/v54.0/sobjects/Lead/<lead_id> body : | { <masked_object_fields> } param_values : - name : lead_id references : - dataset : salesforce_connector_example field : leads.Id direction : from - name : accounts requests : read : method : GET path : /services/data/v54.0/sobjects/Account/<account_id> param_values : - name : account_id references : - dataset : salesforce_connector_example field : contacts.AccountId update : method : PATCH path : /services/data/v54.0/sobjects/Account/<account_id> body : | { <masked_object_fields> } param_values : - name : account_id references : - dataset : salesforce_connector_example field : accounts.Id direction : from - name : campaign_member_list requests : read : method : GET path : /services/data/v54.0/query query_params : - name : q value : SELECT Id FROM CampaignMember WHERE Email='<email>' param_values : - name : email identity : email data_path : records - name : campaign_members requests : read : method : GET path : /services/data/v54.0/sobjects/CampaignMember/<campaign_member_id> param_values : - name : campaign_member_id references : - dataset : salesforce_connector_example field : campaign_member_list.Id direction : from update : method : PATCH path : /services/data/v54.0/sobjects/CampaignMember/<campaign_member_id> body : | { <masked_object_fields> } param_values : - name : campaign_member_id references : - dataset : salesforce_connector_example field : campaign_members.Id direction : from","title":"Example Salesforce Configuration"},{"location":"saas_connectors/example_configs/segment/","text":"Segment Implementation Summary Fides uses the following Segment endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Users Yes No Events Yes No Traits Yes No External IDs Yes No Regulations Yes Yes Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false . Example Segment Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 saas_config : fides_key : segment_connector_example name : Segment SaaS Config description : A sample schema representing the Segment connector for Fides version : 0.0.1 connector_params : - name : domain - name : personas_domain - name : workspace - name : access_token - name : namespace_id - name : access_secret client_config : protocol : https host : connector_param : domain authentication : strategy : bearer_authentication configuration : token : connector_param : access_token test_request : method : GET path : /v1beta/workspaces/ endpoints : - name : segment_user requests : read : method : GET path : /v1/spaces/<namespace_id>/collections/users/profiles/user_id:<user_id>/metadata param_values : - name : namespace_id connector_param : namespace_id - name : user_id identity : email client_config : protocol : https host : connector_param : personas_domain authentication : strategy : basic_authentication configuration : username : connector_param : access_secret - name : track_events requests : read : method : GET path : /v1/spaces/<namespace_id>/collections/users/profiles/<segment_id>/events param_values : - name : namespace_id connector_param : namespace_id - name : segment_id references : - dataset : segment_connector_example field : segment_user.segment_id direction : from data_path : data pagination : strategy : link configuration : source : body path : cursor.url client_config : protocol : https host : connector_param : personas_domain authentication : strategy : basic_authentication configuration : username : connector_param : access_secret - name : traits requests : read : method : GET path : /v1/spaces/<namespace_id>/collections/users/profiles/<segment_id>/traits query_params : - name : limit value : 17 param_values : - name : namespace_id connector_param : namespace_id - name : segment_id references : - dataset : segment_connector_example field : segment_user.segment_id direction : from data_path : traits pagination : strategy : link configuration : source : body path : cursor.url client_config : protocol : https host : connector_param : personas_domain authentication : strategy : basic_authentication configuration : username : connector_param : access_secret - name : external_ids requests : read : method : GET path : /v1/spaces/<namespace_id>/collections/users/profiles/<segment_id>/external_ids param_values : - name : namespace_id connector_param : namespace_id - name : segment_id references : - dataset : segment_connector_example field : segment_user.segment_id direction : from data_path : data pagination : strategy : link configuration : source : body path : cursor.url client_config : protocol : https host : connector_param : personas_domain authentication : strategy : basic_authentication configuration : username : connector_param : access_secret data_protection_request : method : POST path : /v1beta/workspaces/<workspace_name>/regulations headers : - name : Content-Type value : application/json param_values : - name : workspace_name connector_param : workspace - name : user_id identity : email body : '{\"regulation_type\": \"Suppress_With_Delete\", \"attributes\": {\"name\": \"userId\", \"values\": [\"<user_id>\"]}}' client_config : protocol : https host : connector_param : domain authentication : strategy : bearer_authentication configuration : token : connector_param : access_token","title":"Segment"},{"location":"saas_connectors/example_configs/segment/#segment","text":"","title":"Segment"},{"location":"saas_connectors/example_configs/segment/#implementation-summary","text":"Fides uses the following Segment endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Users Yes No Events Yes No Traits Yes No External IDs Yes No Regulations Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/segment/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/segment/#example-segment-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 saas_config : fides_key : segment_connector_example name : Segment SaaS Config description : A sample schema representing the Segment connector for Fides version : 0.0.1 connector_params : - name : domain - name : personas_domain - name : workspace - name : access_token - name : namespace_id - name : access_secret client_config : protocol : https host : connector_param : domain authentication : strategy : bearer_authentication configuration : token : connector_param : access_token test_request : method : GET path : /v1beta/workspaces/ endpoints : - name : segment_user requests : read : method : GET path : /v1/spaces/<namespace_id>/collections/users/profiles/user_id:<user_id>/metadata param_values : - name : namespace_id connector_param : namespace_id - name : user_id identity : email client_config : protocol : https host : connector_param : personas_domain authentication : strategy : basic_authentication configuration : username : connector_param : access_secret - name : track_events requests : read : method : GET path : /v1/spaces/<namespace_id>/collections/users/profiles/<segment_id>/events param_values : - name : namespace_id connector_param : namespace_id - name : segment_id references : - dataset : segment_connector_example field : segment_user.segment_id direction : from data_path : data pagination : strategy : link configuration : source : body path : cursor.url client_config : protocol : https host : connector_param : personas_domain authentication : strategy : basic_authentication configuration : username : connector_param : access_secret - name : traits requests : read : method : GET path : /v1/spaces/<namespace_id>/collections/users/profiles/<segment_id>/traits query_params : - name : limit value : 17 param_values : - name : namespace_id connector_param : namespace_id - name : segment_id references : - dataset : segment_connector_example field : segment_user.segment_id direction : from data_path : traits pagination : strategy : link configuration : source : body path : cursor.url client_config : protocol : https host : connector_param : personas_domain authentication : strategy : basic_authentication configuration : username : connector_param : access_secret - name : external_ids requests : read : method : GET path : /v1/spaces/<namespace_id>/collections/users/profiles/<segment_id>/external_ids param_values : - name : namespace_id connector_param : namespace_id - name : segment_id references : - dataset : segment_connector_example field : segment_user.segment_id direction : from data_path : data pagination : strategy : link configuration : source : body path : cursor.url client_config : protocol : https host : connector_param : personas_domain authentication : strategy : basic_authentication configuration : username : connector_param : access_secret data_protection_request : method : POST path : /v1beta/workspaces/<workspace_name>/regulations headers : - name : Content-Type value : application/json param_values : - name : workspace_name connector_param : workspace - name : user_id identity : email body : '{\"regulation_type\": \"Suppress_With_Delete\", \"attributes\": {\"name\": \"userId\", \"values\": [\"<user_id>\"]}}' client_config : protocol : https host : connector_param : domain authentication : strategy : bearer_authentication configuration : token : connector_param : access_token","title":"Example Segment Configuration"},{"location":"saas_connectors/example_configs/sendgrid/","text":"Sendgrid Implementation Summary Fides uses the following Sendgrid endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Contacts Yes Yes Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to fALSE . Example Sendgrid Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 saas_config : fides_key : sendgrid_connector_example name : Sendgrid SaaS Config type : sendgrid description : A sample schema representing the Sendgrid connector for Fides version : 0.0.1 connector_params : - name : domain - name : api_key client_config : protocol : https host : <domain> authentication : strategy : bearer configuration : token : <api_key> test_request : method : GET path : /v3/marketing/contacts endpoints : - name : contacts requests : read : method : POST path : /v3/marketing/contacts/search body : | { \"query\": \"email = '<email>'\" } param_values : - name : email identity : email data_path : result delete : method : DELETE path : /v3/marketing/contacts?ids=<contact_id> param_values : - name : contact_id references : - dataset : sendgrid_connector_example field : contacts.id direction : from","title":"Sendgrid"},{"location":"saas_connectors/example_configs/sendgrid/#sendgrid","text":"","title":"Sendgrid"},{"location":"saas_connectors/example_configs/sendgrid/#implementation-summary","text":"Fides uses the following Sendgrid endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Contacts Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/sendgrid/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to fALSE .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/sendgrid/#example-sendgrid-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 saas_config : fides_key : sendgrid_connector_example name : Sendgrid SaaS Config type : sendgrid description : A sample schema representing the Sendgrid connector for Fides version : 0.0.1 connector_params : - name : domain - name : api_key client_config : protocol : https host : <domain> authentication : strategy : bearer configuration : token : <api_key> test_request : method : GET path : /v3/marketing/contacts endpoints : - name : contacts requests : read : method : POST path : /v3/marketing/contacts/search body : | { \"query\": \"email = '<email>'\" } param_values : - name : email identity : email data_path : result delete : method : DELETE path : /v3/marketing/contacts?ids=<contact_id> param_values : - name : contact_id references : - dataset : sendgrid_connector_example field : contacts.id direction : from","title":"Example Sendgrid Configuration"},{"location":"saas_connectors/example_configs/sentry/","text":"Sentry Implementation Summary Fides uses the following Sentry endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Organizations Yes No Users Yes No Projects Yes Yes Issues Yes No User Feedback Yes No Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false . Example Sentry Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 saas_config : fides_key : sentry_connector name : Sentry SaaS Config description : A sample schema representing the Sentry connector for Fides version : 0.0.1 connector_params : - name : host - name : access_token client_config : protocol : https host : connector_param : host authentication : strategy : bearer_authentication configuration : token : connector_param : access_token test_request : method : GET path : /api/0/organizations/ endpoints : - name : organizations requests : read : method : GET path : /api/0/organizations/ param_values : - name : placeholder identity : email pagination : strategy : link configuration : source : headers rel : next - name : employees requests : read : method : GET path : /api/0/organizations/<organization_slug>/users/ param_values : - name : organization_slug references : - dataset : sentry_connector field : organizations.slug direction : from postprocessors : - strategy : filter configuration : field : email value : identity : email - name : projects requests : read : method : GET path : /api/0/projects/ param_values : - name : placeholder identity : email pagination : strategy : link configuration : source : headers rel : next - name : issues requests : update : method : PUT path : /api/0/issues/<issue_id>/ headers : - name : Content-Type value : application/json param_values : - name : issue_id references : - dataset : sentry_connector field : issues.id direction : from body : '{\"assignedTo\": \"\"}' read : method : GET path : /api/0/projects/<organization_slug>/<project_slug>/issues/ grouped_inputs : [ organization_slug , project_slug , query ] query_params : - name : query value : assigned:<query> param_values : - name : organization_slug references : - dataset : sentry_connector field : projects.organization.slug direction : from - name : project_slug references : - dataset : sentry_connector field : projects.slug direction : from - name : query identity : email pagination : strategy : link configuration : source : headers rel : next - name : user_feedback requests : read : method : GET path : /api/0/projects/<organization_slug>/<project_slug>/user-feedback/ grouped_inputs : [ organization_slug , project_slug ] param_values : - name : organization_slug references : - dataset : sentry_connector field : projects.organization.slug direction : from - name : project_slug references : - dataset : sentry_connector field : projects.slug direction : from postprocessors : - strategy : filter configuration : field : email value : identity : email pagination : strategy : link configuration : source : headers rel : next - name : person after : [ sentry_connector.projects ] requests : read : method : GET ignore_errors : true path : /api/0/projects/<organization_slug>/<project_slug>/users/ grouped_inputs : [ organization_slug , project_slug , query ] query_params : - name : query value : email:<query> param_values : - name : organization_slug references : - dataset : sentry_connector field : projects.organization.slug direction : from - name : project_slug references : - dataset : sentry_connector field : projects.slug direction : from - name : query identity : email pagination : strategy : link configuration : source : headers rel : next","title":"Sentry"},{"location":"saas_connectors/example_configs/sentry/#sentry","text":"","title":"Sentry"},{"location":"saas_connectors/example_configs/sentry/#implementation-summary","text":"Fides uses the following Sentry endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Organizations Yes No Users Yes No Projects Yes Yes Issues Yes No User Feedback Yes No","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/sentry/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/sentry/#example-sentry-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 saas_config : fides_key : sentry_connector name : Sentry SaaS Config description : A sample schema representing the Sentry connector for Fides version : 0.0.1 connector_params : - name : host - name : access_token client_config : protocol : https host : connector_param : host authentication : strategy : bearer_authentication configuration : token : connector_param : access_token test_request : method : GET path : /api/0/organizations/ endpoints : - name : organizations requests : read : method : GET path : /api/0/organizations/ param_values : - name : placeholder identity : email pagination : strategy : link configuration : source : headers rel : next - name : employees requests : read : method : GET path : /api/0/organizations/<organization_slug>/users/ param_values : - name : organization_slug references : - dataset : sentry_connector field : organizations.slug direction : from postprocessors : - strategy : filter configuration : field : email value : identity : email - name : projects requests : read : method : GET path : /api/0/projects/ param_values : - name : placeholder identity : email pagination : strategy : link configuration : source : headers rel : next - name : issues requests : update : method : PUT path : /api/0/issues/<issue_id>/ headers : - name : Content-Type value : application/json param_values : - name : issue_id references : - dataset : sentry_connector field : issues.id direction : from body : '{\"assignedTo\": \"\"}' read : method : GET path : /api/0/projects/<organization_slug>/<project_slug>/issues/ grouped_inputs : [ organization_slug , project_slug , query ] query_params : - name : query value : assigned:<query> param_values : - name : organization_slug references : - dataset : sentry_connector field : projects.organization.slug direction : from - name : project_slug references : - dataset : sentry_connector field : projects.slug direction : from - name : query identity : email pagination : strategy : link configuration : source : headers rel : next - name : user_feedback requests : read : method : GET path : /api/0/projects/<organization_slug>/<project_slug>/user-feedback/ grouped_inputs : [ organization_slug , project_slug ] param_values : - name : organization_slug references : - dataset : sentry_connector field : projects.organization.slug direction : from - name : project_slug references : - dataset : sentry_connector field : projects.slug direction : from postprocessors : - strategy : filter configuration : field : email value : identity : email pagination : strategy : link configuration : source : headers rel : next - name : person after : [ sentry_connector.projects ] requests : read : method : GET ignore_errors : true path : /api/0/projects/<organization_slug>/<project_slug>/users/ grouped_inputs : [ organization_slug , project_slug , query ] query_params : - name : query value : email:<query> param_values : - name : organization_slug references : - dataset : sentry_connector field : projects.organization.slug direction : from - name : project_slug references : - dataset : sentry_connector field : projects.slug direction : from - name : query identity : email pagination : strategy : link configuration : source : headers rel : next","title":"Example Sentry Configuration"},{"location":"saas_connectors/example_configs/stripe/","text":"Stripe Implementation Summary Fides uses the following Stripe endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Customers Yes Yes Charges Yes No Disputes Yes No Payment Intents Yes Yes Payment Methods Yes No Bank Accounts Yes Yes Cards Yes Yes Credit Notes Yes No Customer Balance Transactions Yes No Tax IDs Yes Yes Invoices Yes Yes Invoice Items Yes Yes Subscriptions Yes Yes Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false . Example Stripe Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 saas_config : fides_key : stripe_connector_example name : Stripe SaaS Config description : A sample schema representing the Stripe connector for Fides version : 0.0.1 connector_params : - name : host - name : api_key - name : payment_types - name : items_per_page client_config : protocol : https host : connector_param : host authentication : strategy : bearer_authentication configuration : token : connector_param : api_key test_request : method : GET path : /v1/customers endpoints : - name : customer requests : read : method : GET path : /v1/customers query_params : - name : email value : <email> param_values : - name : email identity : email data_path : data update : method : POST path : /v1/customers/<customer_id> headers : - name : Content-Type value : application/x-www-form-urlencoded param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from body : '{<all_object_fields>}' - name : charge requests : read : method : GET path : /v1/charges query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : dispute requests : read : method : GET path : /v1/disputes query_params : - name : charge value : <charge_id> - name : payment_intent value : <payment_intent_id> - name : limit value : <limit> param_values : - name : charge_id references : - dataset : stripe_connector_example field : charge.id direction : from - name : payment_intent_id references : - dataset : stripe_connector_example field : payment_intent.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : payment_intent requests : read : method : GET path : /v1/payment_intents query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : payment_method requests : read : method : GET path : /v1/customers/<customer_id>/payment_methods query_params : - name : type value : <type> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : type connector_param : payment_types - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id update : method : POST path : /v1/payment_methods/<payment_method_id> headers : - name : Content-Type value : application/x-www-form-urlencoded param_values : - name : payment_method_id references : - dataset : stripe_connector_example field : payment_method.id direction : from body : '{<masked_object_fields>}' - name : bank_account requests : read : method : GET path : /v1/customers/<customer_id>/sources query_params : - name : object value : bank_account - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id update : method : POST path : /v1/customers/<customer_id>/sources/<bank_account_id> headers : - name : Content-Type value : application/x-www-form-urlencoded param_values : - name : customer_id references : - dataset : stripe_connector_example field : bank_account.customer direction : from - name : bank_account_id references : - dataset : stripe_connector_example field : bank_account.id direction : from body : '{<masked_object_fields>}' - name : card requests : read : method : GET path : /v1/customers/<customer_id>/sources query_params : - name : object value : card - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id update : method : POST path : /v1/customers/<customer_id>/sources/<card_id> headers : - name : Content-Type value : application/x-www-form-urlencoded param_values : - name : customer_id references : - dataset : stripe_connector_example field : card.customer direction : from - name : card_id references : - dataset : stripe_connector_example field : card.id direction : from body : '{<masked_object_fields>}' - name : credit_note requests : read : method : GET path : /v1/credit_notes query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : customer_balance_transaction requests : read : method : GET path : /v1/customers/<customer_id>/balance_transactions query_params : - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : tax_id requests : read : method : GET path : /v1/customers/<customer_id>/tax_ids query_params : - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id delete : method : DELETE path : /v1/customers/<customer_id>/tax_ids/<tax_id> param_values : - name : customer_id references : - dataset : stripe_connector_example field : tax_id.customer direction : from - name : tax_id references : - dataset : stripe_connector_example field : tax_id.id direction : from - name : invoice requests : read : method : GET path : /v1/invoices query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id delete : method : DELETE ignore_errors : true # You can only delete draft invoices. You can't delete invoices created by subscriptions. path : /v1/invoices/<invoice_id> param_values : - name : invoice_id references : - dataset : stripe_connector_example field : invoice.id direction : from - name : invoice_item requests : read : method : GET path : /v1/invoiceitems query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id delete : method : DELETE ignore_errors : true # Can't delete an invoice item that is attached to an invoice that is no longer editable path : /v1/invoiceitems/<invoice_item_id> param_values : - name : invoice_item_id references : - dataset : stripe_connector_example field : invoice_item.id direction : from - name : subscription requests : read : method : GET path : /v1/subscriptions query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id delete : method : DELETE path : /v1/subscriptions/<subscription_id> param_values : - name : subscription_id references : - dataset : stripe_connector_example field : subscription.id direction : from","title":"Stripe"},{"location":"saas_connectors/example_configs/stripe/#stripe","text":"","title":"Stripe"},{"location":"saas_connectors/example_configs/stripe/#implementation-summary","text":"Fides uses the following Stripe endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Customers Yes Yes Charges Yes No Disputes Yes No Payment Intents Yes Yes Payment Methods Yes No Bank Accounts Yes Yes Cards Yes Yes Credit Notes Yes No Customer Balance Transactions Yes No Tax IDs Yes Yes Invoices Yes Yes Invoice Items Yes Yes Subscriptions Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/stripe/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/stripe/#example-stripe-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 saas_config : fides_key : stripe_connector_example name : Stripe SaaS Config description : A sample schema representing the Stripe connector for Fides version : 0.0.1 connector_params : - name : host - name : api_key - name : payment_types - name : items_per_page client_config : protocol : https host : connector_param : host authentication : strategy : bearer_authentication configuration : token : connector_param : api_key test_request : method : GET path : /v1/customers endpoints : - name : customer requests : read : method : GET path : /v1/customers query_params : - name : email value : <email> param_values : - name : email identity : email data_path : data update : method : POST path : /v1/customers/<customer_id> headers : - name : Content-Type value : application/x-www-form-urlencoded param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from body : '{<all_object_fields>}' - name : charge requests : read : method : GET path : /v1/charges query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : dispute requests : read : method : GET path : /v1/disputes query_params : - name : charge value : <charge_id> - name : payment_intent value : <payment_intent_id> - name : limit value : <limit> param_values : - name : charge_id references : - dataset : stripe_connector_example field : charge.id direction : from - name : payment_intent_id references : - dataset : stripe_connector_example field : payment_intent.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : payment_intent requests : read : method : GET path : /v1/payment_intents query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : payment_method requests : read : method : GET path : /v1/customers/<customer_id>/payment_methods query_params : - name : type value : <type> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : type connector_param : payment_types - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id update : method : POST path : /v1/payment_methods/<payment_method_id> headers : - name : Content-Type value : application/x-www-form-urlencoded param_values : - name : payment_method_id references : - dataset : stripe_connector_example field : payment_method.id direction : from body : '{<masked_object_fields>}' - name : bank_account requests : read : method : GET path : /v1/customers/<customer_id>/sources query_params : - name : object value : bank_account - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id update : method : POST path : /v1/customers/<customer_id>/sources/<bank_account_id> headers : - name : Content-Type value : application/x-www-form-urlencoded param_values : - name : customer_id references : - dataset : stripe_connector_example field : bank_account.customer direction : from - name : bank_account_id references : - dataset : stripe_connector_example field : bank_account.id direction : from body : '{<masked_object_fields>}' - name : card requests : read : method : GET path : /v1/customers/<customer_id>/sources query_params : - name : object value : card - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id update : method : POST path : /v1/customers/<customer_id>/sources/<card_id> headers : - name : Content-Type value : application/x-www-form-urlencoded param_values : - name : customer_id references : - dataset : stripe_connector_example field : card.customer direction : from - name : card_id references : - dataset : stripe_connector_example field : card.id direction : from body : '{<masked_object_fields>}' - name : credit_note requests : read : method : GET path : /v1/credit_notes query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : customer_balance_transaction requests : read : method : GET path : /v1/customers/<customer_id>/balance_transactions query_params : - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id - name : tax_id requests : read : method : GET path : /v1/customers/<customer_id>/tax_ids query_params : - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id delete : method : DELETE path : /v1/customers/<customer_id>/tax_ids/<tax_id> param_values : - name : customer_id references : - dataset : stripe_connector_example field : tax_id.customer direction : from - name : tax_id references : - dataset : stripe_connector_example field : tax_id.id direction : from - name : invoice requests : read : method : GET path : /v1/invoices query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id delete : method : DELETE ignore_errors : true # You can only delete draft invoices. You can't delete invoices created by subscriptions. path : /v1/invoices/<invoice_id> param_values : - name : invoice_id references : - dataset : stripe_connector_example field : invoice.id direction : from - name : invoice_item requests : read : method : GET path : /v1/invoiceitems query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id delete : method : DELETE ignore_errors : true # Can't delete an invoice item that is attached to an invoice that is no longer editable path : /v1/invoiceitems/<invoice_item_id> param_values : - name : invoice_item_id references : - dataset : stripe_connector_example field : invoice_item.id direction : from - name : subscription requests : read : method : GET path : /v1/subscriptions query_params : - name : customer value : <customer_id> - name : limit value : <limit> param_values : - name : customer_id references : - dataset : stripe_connector_example field : customer.id direction : from - name : limit connector_param : items_per_page data_path : data pagination : strategy : cursor configuration : cursor_param : starting_after field : id delete : method : DELETE path : /v1/subscriptions/<subscription_id> param_values : - name : subscription_id references : - dataset : stripe_connector_example field : subscription.id direction : from","title":"Example Stripe Configuration"},{"location":"saas_connectors/example_configs/zendesk/","text":"Zendesk Implementation Summary Fides uses the following Zendesk endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Search Yes No Identities Yes No Tickets Yes Yes Ticket Comments Yes Yes Connection Settings Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false . Example Zendesk Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 saas_config : fides_key : zendesk_connector_example name : Zendesk SaaS Config type : zendesk description : A sample schema representing the Zendesk connector for Fides version : 0.0.1 connector_params : - name : domain - name : username - name : api_key - name : page_size client_config : protocol : https host : <domain> authentication : strategy : basic configuration : username : <username> password : <api_key> test_request : method : GET path : /api/v2/users/search.json query_params : - name : query value : test@ethyca endpoints : - name : users requests : read : method : GET path : /api/v2/users/search.json query_params : - name : query value : <email> param_values : - name : email identity : email data_path : users delete : method : DELETE path : /api/v2/users/<user_id>.json param_values : - name : user_id references : - dataset : zendesk_connector_example field : users.id direction : from - name : user_identities requests : read : method : GET path : /api/v2/users/<user_id>/identities.json query_params : - name : page[size] value : <page_size> param_values : - name : user_id references : - dataset : zendesk_connector_example field : users.id direction : from - name : page_size connector_param : page_size data_path : identities pagination : strategy : link configuration : source : body path : links.next - name : tickets requests : read : method : GET path : /api/v2/users/<user_id>/tickets/requested.json query_params : - name : page[size] value : <page_size> param_values : - name : user_id references : - dataset : zendesk_connector_example field : users.id direction : from - name : page_size connector_param : page_size data_path : tickets pagination : strategy : link configuration : source : body path : links.next delete : method : DELETE path : /api/v2/tickets/<ticket_id>.json param_values : - name : ticket_id references : - dataset : zendesk_connector_example field : tickets.id direction : from - name : ticket_comments requests : read : method : GET path : /api/v2/tickets/<ticket_id>/comments.json query_params : - name : page[size] value : <page_size> param_values : - name : ticket_id references : - dataset : zendesk_connector_example field : tickets.id direction : from - name : page_size connector_param : page_size data_path : comments pagination : strategy : link configuration : source : body path : links.next","title":"Zendesk"},{"location":"saas_connectors/example_configs/zendesk/#zendesk","text":"","title":"Zendesk"},{"location":"saas_connectors/example_configs/zendesk/#implementation-summary","text":"Fides uses the following Zendesk endpoints to retrieve and delete Personally Identifiable Information (PII) when processing a Data Subject Request (DSR). Right to Access and Right to Delete (Right to Forget) support for each endpoint is noted below. Endpoint Right to Access Right to Delete Search Yes No Identities Yes No Tickets Yes Yes Ticket Comments Yes Yes","title":"Implementation Summary"},{"location":"saas_connectors/example_configs/zendesk/#connection-settings","text":"Fides provides a Postman collection for easily establishing connections to your third party applications. Additional connection instructions may be found in the configuration guide . Deletion requests are fulfilled by masking PII via UPDATE endpoints. To give Fides permission to remove PII using DELETE endpoints, ensure the masking_strict variable in your fides.toml file is set to false .","title":"Connection Settings"},{"location":"saas_connectors/example_configs/zendesk/#example-zendesk-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 saas_config : fides_key : zendesk_connector_example name : Zendesk SaaS Config type : zendesk description : A sample schema representing the Zendesk connector for Fides version : 0.0.1 connector_params : - name : domain - name : username - name : api_key - name : page_size client_config : protocol : https host : <domain> authentication : strategy : basic configuration : username : <username> password : <api_key> test_request : method : GET path : /api/v2/users/search.json query_params : - name : query value : test@ethyca endpoints : - name : users requests : read : method : GET path : /api/v2/users/search.json query_params : - name : query value : <email> param_values : - name : email identity : email data_path : users delete : method : DELETE path : /api/v2/users/<user_id>.json param_values : - name : user_id references : - dataset : zendesk_connector_example field : users.id direction : from - name : user_identities requests : read : method : GET path : /api/v2/users/<user_id>/identities.json query_params : - name : page[size] value : <page_size> param_values : - name : user_id references : - dataset : zendesk_connector_example field : users.id direction : from - name : page_size connector_param : page_size data_path : identities pagination : strategy : link configuration : source : body path : links.next - name : tickets requests : read : method : GET path : /api/v2/users/<user_id>/tickets/requested.json query_params : - name : page[size] value : <page_size> param_values : - name : user_id references : - dataset : zendesk_connector_example field : users.id direction : from - name : page_size connector_param : page_size data_path : tickets pagination : strategy : link configuration : source : body path : links.next delete : method : DELETE path : /api/v2/tickets/<ticket_id>.json param_values : - name : ticket_id references : - dataset : zendesk_connector_example field : tickets.id direction : from - name : ticket_comments requests : read : method : GET path : /api/v2/tickets/<ticket_id>/comments.json query_params : - name : page[size] value : <page_size> param_values : - name : ticket_id references : - dataset : zendesk_connector_example field : tickets.id direction : from - name : page_size connector_param : page_size data_path : comments pagination : strategy : link configuration : source : body path : links.next","title":"Example Zendesk Configuration"},{"location":"tutorial/","text":"Tutorial Overview In this tutorial you will learn how to use fidesctl to solve a real-world data privacy problem. These steps closely follow the example found in the ethyca/fidesdemo repository here . You will run a local instance of a basic web app to demonstrate the use of Fidesctl as part of a \"real\" project that uses: Flask to run a web server simulating a basic e-commerce application PostgreSQL as the application's database SQLAlchemy to connect to the database fidesctl to declare privacy manifests and evaluate policies The app itself is the Flask tutorial app , but modified to simulate an e-commerce marketplace. This helps to highlight some basic examples of data categories that might be stored in a \"real\" user-facing application. Setup Instructions System Requirements Before beginning, ensure you have the following software installed and configured to your liking: Docker (v12+) Python (v3.9+) pg_config (required for the Python project. Installed via Homebrew with brew install libpq or brew install postgres .) Installation Clone the ethyca/fidesdemo repository to your machine. Checkout the repository's tutorial-start tag : 1 git checkout tutorial-start Each step in this tutorial will explain the changes made in each commit of the fidesdemo repository. You can follow along by checking out each one, or by building everything yourself and comparing your work to each commit's changeset. Navigate to the repository directory in your command line, and run: 1 make install This will create the project's virtual environment, and set up all required containers, databases, and dependencies. If you prefer, you may execute the project's test suite by running: 1 make test About the Example Application (\"Flaskr\") This example application is meant to simulate a basic e-commerce marketplace where users can create accounts and purchase products from one another. Using the web app you can: Register a new user Login as a user Post a \"product\" for sale Delete/update products you've posted Purchase a product (no products are actually for sale) The schema itself is designed to highlight a few very simple examples of how identifiable data might get stored in a web application like this one. The sample data below shows what this looks like: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) flaskr = # SELECT * FROM products; id | created_at | seller_id | name | description | price ----+---------------------+-----------+-------------------+--------------------------------------+------- 1 | 2020 -01-01 12 :00:00 | 1 | Example Product 1 | A description for example product #1 | 10 2 | 2020 -01-02 12 :00:00 | 1 | Example Product 2 | A description for example product #2 | 20 3 | 2020 -01-03 12 :00:00 | 2 | Example Product 3 | A description for example product #3 | 50 ( 3 rows ) flaskr = # SELECT * FROM purchases; id | created_at | product_id | buyer_id | street_1 | street_2 | city | state | zip ----+---------------------+------------+----------+----------------+----------+-------------+-------+------- 1 | 2020 -01-04 12 :00:00 | 1 | 2 | 123 Example St | Apt 123 | Exampletown | NY | 12345 ( 1 row ) Check Your Progress After running the commands outlined in the Installation section, your app should resemble the state of the ethyca/fidesdemo repository at the tutorial-start tag. Next: Add Fidesctl to the App Work within the sample app prior to the installation and configuration of the Fides developer tools to add fidesctl .","title":"Overview"},{"location":"tutorial/#tutorial-overview","text":"In this tutorial you will learn how to use fidesctl to solve a real-world data privacy problem. These steps closely follow the example found in the ethyca/fidesdemo repository here . You will run a local instance of a basic web app to demonstrate the use of Fidesctl as part of a \"real\" project that uses: Flask to run a web server simulating a basic e-commerce application PostgreSQL as the application's database SQLAlchemy to connect to the database fidesctl to declare privacy manifests and evaluate policies The app itself is the Flask tutorial app , but modified to simulate an e-commerce marketplace. This helps to highlight some basic examples of data categories that might be stored in a \"real\" user-facing application.","title":"Tutorial Overview"},{"location":"tutorial/#setup-instructions","text":"","title":"Setup Instructions"},{"location":"tutorial/#system-requirements","text":"Before beginning, ensure you have the following software installed and configured to your liking: Docker (v12+) Python (v3.9+) pg_config (required for the Python project. Installed via Homebrew with brew install libpq or brew install postgres .)","title":"System Requirements"},{"location":"tutorial/#installation","text":"Clone the ethyca/fidesdemo repository to your machine. Checkout the repository's tutorial-start tag : 1 git checkout tutorial-start Each step in this tutorial will explain the changes made in each commit of the fidesdemo repository. You can follow along by checking out each one, or by building everything yourself and comparing your work to each commit's changeset. Navigate to the repository directory in your command line, and run: 1 make install This will create the project's virtual environment, and set up all required containers, databases, and dependencies. If you prefer, you may execute the project's test suite by running: 1 make test","title":"Installation"},{"location":"tutorial/#about-the-example-application-flaskr","text":"This example application is meant to simulate a basic e-commerce marketplace where users can create accounts and purchase products from one another. Using the web app you can: Register a new user Login as a user Post a \"product\" for sale Delete/update products you've posted Purchase a product (no products are actually for sale) The schema itself is designed to highlight a few very simple examples of how identifiable data might get stored in a web application like this one. The sample data below shows what this looks like: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) flaskr = # SELECT * FROM products; id | created_at | seller_id | name | description | price ----+---------------------+-----------+-------------------+--------------------------------------+------- 1 | 2020 -01-01 12 :00:00 | 1 | Example Product 1 | A description for example product #1 | 10 2 | 2020 -01-02 12 :00:00 | 1 | Example Product 2 | A description for example product #2 | 20 3 | 2020 -01-03 12 :00:00 | 2 | Example Product 3 | A description for example product #3 | 50 ( 3 rows ) flaskr = # SELECT * FROM purchases; id | created_at | product_id | buyer_id | street_1 | street_2 | city | state | zip ----+---------------------+------------+----------+----------------+----------+-------------+-------+------- 1 | 2020 -01-04 12 :00:00 | 1 | 2 | 123 Example St | Apt 123 | Exampletown | NY | 12345 ( 1 row )","title":"About the Example Application (\"Flaskr\")"},{"location":"tutorial/#check-your-progress","text":"After running the commands outlined in the Installation section, your app should resemble the state of the ethyca/fidesdemo repository at the tutorial-start tag.","title":"Check Your Progress"},{"location":"tutorial/#next-add-fidesctl-to-the-app","text":"Work within the sample app prior to the installation and configuration of the Fides developer tools to add fidesctl .","title":"Next: Add Fidesctl to the App"},{"location":"tutorial/add/","text":"Add Fidesctl to the App In this step you will incorporate fidesctl , which will enable you to declare your system , dataset , and policy resources as manifest YAML files. Add the fidesctl Dependency Open the requirements.txt file and add the fidesctl dependency by including the following line: 1 fidesctl>=1.0.0 Then, install the dependencies by running: 1 pipx install -r requirements.txt Initializing Fidesctl With fidesctl installed, it's time to initialize the project so we have some place to start adding resource manifests and tweaking our configuration. Run the following command and follow the prompts to get your local fidesctl instance initialized. Initialize Fidesctl 1 fidesctl init Expected Output 1 2 3 4 5 6 7 8 9 10 11 12 Initializing Fidesctl... ---------- Created a './.fides' directory. ---------- Created a fidesctl config file: ./.fides/fidesctl.toml To learn more about configuring fidesctl, see: https://ethyca.github.io/fides/installation/configuration/ ---------- For example policies and help getting started, see: https://ethyca.github.io/fides/guides/policies/ ---------- Fidesctl initialization complete. Configuring Fidesctl See our Configuration guide for more information on how to configure fidesctl. Run Fidesctl via Docker Now that the dependency is included in the project and the configuration is in place, the fidesctl server needs to be told to run. The app uses docker-compose to orchestrate resources, so include fidesctl as a service by adding the following configuration after the database service: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fidesctl : image : ethyca/fidesctl:latest depends_on : - db command : fidesctl webserver expose : - 8080 ports : - \"8080:8080\" environment : FIDESCTL__DATABASE__DB : \"fidesctl\" FIDESCTL__DATABASE__PASSWORD : \"postgres\" FIDESCTL__DATABASE__PORT : 5432 FIDESCTL__DATABASE__SERVER : \"db\" FIDESCTL__DATABASE__USER : \"postgres\" See the fidesctl installation guide for a more detailed fidesctl server setup walkthrough, and the docker-compose documentation for an explanation of the above configuration options. Check Your Progress After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesops-start tag. Next: Annotate the Resources Now that the fidesctl tools are available to use within the app's virtual environment, the next step is to configure fidesctl to work with the specifics of this app. This can be done by creating manifest files to annotate the resources .","title":"Add Fides to the App"},{"location":"tutorial/add/#add-fidesctl-to-the-app","text":"In this step you will incorporate fidesctl , which will enable you to declare your system , dataset , and policy resources as manifest YAML files.","title":"Add Fidesctl to the App"},{"location":"tutorial/add/#add-the-fidesctl-dependency","text":"Open the requirements.txt file and add the fidesctl dependency by including the following line: 1 fidesctl>=1.0.0 Then, install the dependencies by running: 1 pipx install -r requirements.txt","title":"Add the fidesctl Dependency"},{"location":"tutorial/add/#initializing-fidesctl","text":"With fidesctl installed, it's time to initialize the project so we have some place to start adding resource manifests and tweaking our configuration. Run the following command and follow the prompts to get your local fidesctl instance initialized. Initialize Fidesctl 1 fidesctl init Expected Output 1 2 3 4 5 6 7 8 9 10 11 12 Initializing Fidesctl... ---------- Created a './.fides' directory. ---------- Created a fidesctl config file: ./.fides/fidesctl.toml To learn more about configuring fidesctl, see: https://ethyca.github.io/fides/installation/configuration/ ---------- For example policies and help getting started, see: https://ethyca.github.io/fides/guides/policies/ ---------- Fidesctl initialization complete.","title":"Initializing Fidesctl"},{"location":"tutorial/add/#configuring-fidesctl","text":"See our Configuration guide for more information on how to configure fidesctl.","title":"Configuring Fidesctl"},{"location":"tutorial/add/#run-fidesctl-via-docker","text":"Now that the dependency is included in the project and the configuration is in place, the fidesctl server needs to be told to run. The app uses docker-compose to orchestrate resources, so include fidesctl as a service by adding the following configuration after the database service: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fidesctl : image : ethyca/fidesctl:latest depends_on : - db command : fidesctl webserver expose : - 8080 ports : - \"8080:8080\" environment : FIDESCTL__DATABASE__DB : \"fidesctl\" FIDESCTL__DATABASE__PASSWORD : \"postgres\" FIDESCTL__DATABASE__PORT : 5432 FIDESCTL__DATABASE__SERVER : \"db\" FIDESCTL__DATABASE__USER : \"postgres\" See the fidesctl installation guide for a more detailed fidesctl server setup walkthrough, and the docker-compose documentation for an explanation of the above configuration options.","title":"Run Fidesctl via Docker"},{"location":"tutorial/add/#check-your-progress","text":"After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesops-start tag.","title":"Check Your Progress"},{"location":"tutorial/add/#next-annotate-the-resources","text":"Now that the fidesctl tools are available to use within the app's virtual environment, the next step is to configure fidesctl to work with the specifics of this app. This can be done by creating manifest files to annotate the resources .","title":"Next: Annotate the Resources"},{"location":"tutorial/dataset/","text":"Annotate the Dataset Making the fidesctl tools available within the app's virtual environment is just the beginning. Next, configure fidesctl for this app by annotating its resources using manifest files. First, create a fides_resources directory at the project root. This is where the manifest files will be stored. Note: In a production app this directory can have any name, but it's a best practice to create a specific directory to house the fidesctl manifest files. Fundamentally, the data ecosystem is built on data that is stored somewhere . In fidesctl, Datasets are used for granular, field-level annotations of exactly what data your systems are storing and where that data is stored. For example, an app might declare one dataset for a Postgres application database, a second dataset for a Mongo orders collection, and a third dataset for some CSV files in cloud storage. The Dataset resource provides a database-agnostic way to annotate the fields stored in these systems with Data Categories, providing a metadata layer consumable by other tooling. This app contains a single PostgreSQL dataset. Create a dataset resource to annotate it by adding a flaskr_postgres_dataset.yml file to the fides_resources directory. To annotate this dataset correctly, go through each column of each table and answer the question: \"What data categories are stored here?\" For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 dataset : - fides_key : flaskr_postgres_dataset name : Flaskr Example PostgreSQL Database description : Application database for Flaskr example app collections : - name : products fields : - name : created_at data_categories : [ system.operations ] - name : description data_categories : [ user.provided.identifiable ] - name : id data_categories : [ system.operations ] - name : name data_categories : [ user.provided.identifiable ] - name : price data_categories : [ user.provided.identifiable ] - name : seller_id data_categories : [ user.derived.identifiable.unique_id ] - name : purchases fields : - name : buyer_id data_categories : [ user.derived.identifiable.unique_id ] - name : city data_categories : [ user.provided.identifiable.contact.city ] - name : created_at data_categories : [ system.operations ] - name : id data_categories : [ system.operations ] - name : product_id data_categories : [ system.operations ] - name : state data_categories : [ user.provided.identifiable.contact.state ] - name : street_1 data_categories : [ user.provided.identifiable.contact.street ] - name : street_2 data_categories : [ user.provided.identifiable.contact.street ] - name : zip data_categories : [ user.provided.identifiable.contact.postal_code ] - name : users fields : - name : created_at data_categories : [ system.operations ] - name : email data_categories : [ user.provided.identifiable.contact.email ] - name : first_name data_categories : [ user.provided.identifiable.name ] - name : id data_categories : [ user.derived.identifiable.unique_id ] - name : last_name data_categories : [ user.provided.identifiable.name ] - name : password data_categories : [ user.provided.identifiable.credentials.password ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized As an alternative to manually authoring the resource file, you can also use the generate CLI command. The CLI will connect to the database and automatically generate a non-annotated resource YAML file in the specified location, based on the database schema. For this project, the command is: 1 2 3 ./venv/bin/fidesctl generate dataset db \\ fides_resources/flaskr_postgres_dataset.yml \\ --connection-string postgresql://postgres:postgres@localhost:5432/flaskr Understanding the Dataset Resource This YAML serves as the foundation of fideslang , the Fides language; it answers \" What data and kinds of data do we have? \" and \" How is our data organized? \". The language is built on declaring the types of data found in storage for your organization. In traditional SQL, fidesctl defines the following: \"datasets\" as database schemas \"collections\" as database tables \"fields\" as database columns For NoSQL datasets, fidesctl defines the following: \"dataset\" \"collection\" as a logical grouping of data fields (ie: in MongoDB, this is called a \"Collection\") \"fields\" as a reference to an individual data element (ie: in MongoDB, this is called a \"field\") Additionally, fideslang has attributes that describe what kind of data is contained in this dataset. We use the following attributes to describe the data: Name Type Description name String The name of this field description String A description of what this field contains data_categories List[FidesKey] The types of sensitive data, as defined by the taxonomy, that can be found in this field data_qualifier FidesKey The level of deidentification for the dataset For more detail on Dataset resources, see the full Dataset resource documentation . PRO TIP As you're progressing with the tutorial, we recommend installing our fidesctl VS Code extension , which will validate the syntax in real-time as you're writing your resource files! Maintaining a Dataset Resource As apps add more databases and other services to store potentially sensitive data, it is recommended that updating this resource file becomes a part of the development process when building a new feature. Next: Annotate the System Resource With the underlying database resource declared, you must now include the database in an application-level System resource annotation .","title":"Annotate the Dataset"},{"location":"tutorial/dataset/#annotate-the-dataset","text":"Making the fidesctl tools available within the app's virtual environment is just the beginning. Next, configure fidesctl for this app by annotating its resources using manifest files. First, create a fides_resources directory at the project root. This is where the manifest files will be stored. Note: In a production app this directory can have any name, but it's a best practice to create a specific directory to house the fidesctl manifest files. Fundamentally, the data ecosystem is built on data that is stored somewhere . In fidesctl, Datasets are used for granular, field-level annotations of exactly what data your systems are storing and where that data is stored. For example, an app might declare one dataset for a Postgres application database, a second dataset for a Mongo orders collection, and a third dataset for some CSV files in cloud storage. The Dataset resource provides a database-agnostic way to annotate the fields stored in these systems with Data Categories, providing a metadata layer consumable by other tooling. This app contains a single PostgreSQL dataset. Create a dataset resource to annotate it by adding a flaskr_postgres_dataset.yml file to the fides_resources directory. To annotate this dataset correctly, go through each column of each table and answer the question: \"What data categories are stored here?\" For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 dataset : - fides_key : flaskr_postgres_dataset name : Flaskr Example PostgreSQL Database description : Application database for Flaskr example app collections : - name : products fields : - name : created_at data_categories : [ system.operations ] - name : description data_categories : [ user.provided.identifiable ] - name : id data_categories : [ system.operations ] - name : name data_categories : [ user.provided.identifiable ] - name : price data_categories : [ user.provided.identifiable ] - name : seller_id data_categories : [ user.derived.identifiable.unique_id ] - name : purchases fields : - name : buyer_id data_categories : [ user.derived.identifiable.unique_id ] - name : city data_categories : [ user.provided.identifiable.contact.city ] - name : created_at data_categories : [ system.operations ] - name : id data_categories : [ system.operations ] - name : product_id data_categories : [ system.operations ] - name : state data_categories : [ user.provided.identifiable.contact.state ] - name : street_1 data_categories : [ user.provided.identifiable.contact.street ] - name : street_2 data_categories : [ user.provided.identifiable.contact.street ] - name : zip data_categories : [ user.provided.identifiable.contact.postal_code ] - name : users fields : - name : created_at data_categories : [ system.operations ] - name : email data_categories : [ user.provided.identifiable.contact.email ] - name : first_name data_categories : [ user.provided.identifiable.name ] - name : id data_categories : [ user.derived.identifiable.unique_id ] - name : last_name data_categories : [ user.provided.identifiable.name ] - name : password data_categories : [ user.provided.identifiable.credentials.password ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized As an alternative to manually authoring the resource file, you can also use the generate CLI command. The CLI will connect to the database and automatically generate a non-annotated resource YAML file in the specified location, based on the database schema. For this project, the command is: 1 2 3 ./venv/bin/fidesctl generate dataset db \\ fides_resources/flaskr_postgres_dataset.yml \\ --connection-string postgresql://postgres:postgres@localhost:5432/flaskr","title":"Annotate the Dataset"},{"location":"tutorial/dataset/#understanding-the-dataset-resource","text":"This YAML serves as the foundation of fideslang , the Fides language; it answers \" What data and kinds of data do we have? \" and \" How is our data organized? \". The language is built on declaring the types of data found in storage for your organization. In traditional SQL, fidesctl defines the following: \"datasets\" as database schemas \"collections\" as database tables \"fields\" as database columns For NoSQL datasets, fidesctl defines the following: \"dataset\" \"collection\" as a logical grouping of data fields (ie: in MongoDB, this is called a \"Collection\") \"fields\" as a reference to an individual data element (ie: in MongoDB, this is called a \"field\") Additionally, fideslang has attributes that describe what kind of data is contained in this dataset. We use the following attributes to describe the data: Name Type Description name String The name of this field description String A description of what this field contains data_categories List[FidesKey] The types of sensitive data, as defined by the taxonomy, that can be found in this field data_qualifier FidesKey The level of deidentification for the dataset For more detail on Dataset resources, see the full Dataset resource documentation .","title":"Understanding the Dataset Resource"},{"location":"tutorial/dataset/#pro-tip","text":"As you're progressing with the tutorial, we recommend installing our fidesctl VS Code extension , which will validate the syntax in real-time as you're writing your resource files!","title":"PRO TIP"},{"location":"tutorial/dataset/#maintaining-a-dataset-resource","text":"As apps add more databases and other services to store potentially sensitive data, it is recommended that updating this resource file becomes a part of the development process when building a new feature.","title":"Maintaining a Dataset Resource"},{"location":"tutorial/dataset/#next-annotate-the-system-resource","text":"With the underlying database resource declared, you must now include the database in an application-level System resource annotation .","title":"Next: Annotate the System Resource"},{"location":"tutorial/google/","text":"Add Google Analytics To better understand the behavior of the app's users, add Google Analytics to the app and a fidesctl System resource to annotate it. Define the App's Google Analytics Identifier Open the flaskr/__init__.py file in your favorite editor, and define the GOOGLE_ANALYTICS_ID constant below line 7: 1 GOOGLE_ANALYTICS_ID = \"UA-xxxxxxxxx-y\" In the create_app function defined on line 11, include the Google Analytics ID value in the application's configuration by adding the following line below line 17: 1 GOOGLE_ANALYTICS_ID = GOOGLE_ANALYTICS_ID , Add the Google Analytics Script Open the flaskr/templates/base.html file in your favorite editor, and include the following at the beginning of the <head> tag: 1 2 3 4 5 6 7 8 9 10 {% if config['GOOGLE_ANALYTICS_ID'] %} <!-- Global site tag (gtag.js) - Google Analytics --> < script async src = \"https://www.googletagmanager.com/gtag/js?id={{ config['GOOGLE_ANALYTICS_ID'] }}\" ></ script > < script > window . dataLayer = window . dataLayer || []; function gtag (){ dataLayer . push ( arguments );} gtag ( \"js\" , new Date ()); gtag ( \"config\" , \"{{ config['GOOGLE_ANALYTICS_ID'] }}\" ); </ script > {% endif %} Annotate a Fidesctl System Resource To ensure that the app's policies can account for the data collected by Google Analytics, define a new fidesctl System resource by adding a google_analytics_system.yml file to the fides_resources directory. This System resource annotation should reflect the uses of the Google Analytics features configured in this app's implementation. Some things to think about might be: What fields are being tracked? (See the field reference documentation for a list of all possible fields) What data_use value would be appropriate for this app? ( provide vs. improve ) For this System resource, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 system : - fides_key : google_analytics_system name : Google Analytics description : Hosted third party analytics to track and analyze user behaviour system_type : Third Party privacy_declarations : # See the Google Analytics documentation for a description of the possible # fields collected by the tracker, including page URL, referrer, cookie ID, etc. # https://developers.google.com/analytics/devguides/collection/analyticsjs/field-reference - name : Track & report on page views data_categories : - user.derived.identifiable.browsing_history - user.derived.identifiable.device.cookie_id - user.derived.identifiable.telemetry - user.derived.identifiable.location - user.derived.nonidentifiable data_use : improve data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized # Google Analytics collects the user's IP address and derives geographic dimensions server-side. # See https://developers.google.com/analytics/devguides/reporting/realtime/dimsmets/geonetwork - name : Derive user geographic location data_categories : - user.derived.identifiable.device.ip_address - user.derived.identifiable.location - user.derived.identifiable data_use : improve data_subjects : - customer # With \"IP Anonymization\" disabled, IP Addresses will remain identifiable. # See https://developers.google.com/analytics/devguides/collection/gtagjs/ip-anonymization data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified There are two privacy_declaration s defined: The use of pseudonymized behavioral data to analyze app usage The use of user IP addresses to derive their geographic location The two declarations reflect the separate purposes for which data is collected and used by Google Analytics here. They are meant to align with the app's actual usage of its specific Google Analytics implementation; there are many other data uses for Google Analytics, but this app does not leverage them. Check Your Progress After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-add-google-analytics tag . Next: Manage Google Analytics with Fidesctl Google Analytics is implemented and working correctly, but - oh no! - executing nox -s fidesctl shows a failure: 1 2 3 4 5 6 7 8 { \"fides_key\" : \"4e739b1b_732e_43b1_8747_e833905dfc4c_1635789050\" , \"status\" : \"FAIL\" , \"details\" : [ \"Declaration (Derive user geographic location) of System (google_analytics_system) failed Rule (Minimize User Identifiable Data) from Policy (flaskr_policy)\" ], \"message\" : null } In the final step, enable the fidesctl policy already in place to pass by updating Google Analytics .","title":"Add Google Analytics"},{"location":"tutorial/google/#add-google-analytics","text":"To better understand the behavior of the app's users, add Google Analytics to the app and a fidesctl System resource to annotate it.","title":"Add Google Analytics"},{"location":"tutorial/google/#define-the-apps-google-analytics-identifier","text":"Open the flaskr/__init__.py file in your favorite editor, and define the GOOGLE_ANALYTICS_ID constant below line 7: 1 GOOGLE_ANALYTICS_ID = \"UA-xxxxxxxxx-y\" In the create_app function defined on line 11, include the Google Analytics ID value in the application's configuration by adding the following line below line 17: 1 GOOGLE_ANALYTICS_ID = GOOGLE_ANALYTICS_ID ,","title":"Define the App's Google Analytics Identifier"},{"location":"tutorial/google/#add-the-google-analytics-script","text":"Open the flaskr/templates/base.html file in your favorite editor, and include the following at the beginning of the <head> tag: 1 2 3 4 5 6 7 8 9 10 {% if config['GOOGLE_ANALYTICS_ID'] %} <!-- Global site tag (gtag.js) - Google Analytics --> < script async src = \"https://www.googletagmanager.com/gtag/js?id={{ config['GOOGLE_ANALYTICS_ID'] }}\" ></ script > < script > window . dataLayer = window . dataLayer || []; function gtag (){ dataLayer . push ( arguments );} gtag ( \"js\" , new Date ()); gtag ( \"config\" , \"{{ config['GOOGLE_ANALYTICS_ID'] }}\" ); </ script > {% endif %}","title":"Add the Google Analytics Script"},{"location":"tutorial/google/#annotate-a-fidesctl-system-resource","text":"To ensure that the app's policies can account for the data collected by Google Analytics, define a new fidesctl System resource by adding a google_analytics_system.yml file to the fides_resources directory. This System resource annotation should reflect the uses of the Google Analytics features configured in this app's implementation. Some things to think about might be: What fields are being tracked? (See the field reference documentation for a list of all possible fields) What data_use value would be appropriate for this app? ( provide vs. improve ) For this System resource, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 system : - fides_key : google_analytics_system name : Google Analytics description : Hosted third party analytics to track and analyze user behaviour system_type : Third Party privacy_declarations : # See the Google Analytics documentation for a description of the possible # fields collected by the tracker, including page URL, referrer, cookie ID, etc. # https://developers.google.com/analytics/devguides/collection/analyticsjs/field-reference - name : Track & report on page views data_categories : - user.derived.identifiable.browsing_history - user.derived.identifiable.device.cookie_id - user.derived.identifiable.telemetry - user.derived.identifiable.location - user.derived.nonidentifiable data_use : improve data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized # Google Analytics collects the user's IP address and derives geographic dimensions server-side. # See https://developers.google.com/analytics/devguides/reporting/realtime/dimsmets/geonetwork - name : Derive user geographic location data_categories : - user.derived.identifiable.device.ip_address - user.derived.identifiable.location - user.derived.identifiable data_use : improve data_subjects : - customer # With \"IP Anonymization\" disabled, IP Addresses will remain identifiable. # See https://developers.google.com/analytics/devguides/collection/gtagjs/ip-anonymization data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified There are two privacy_declaration s defined: The use of pseudonymized behavioral data to analyze app usage The use of user IP addresses to derive their geographic location The two declarations reflect the separate purposes for which data is collected and used by Google Analytics here. They are meant to align with the app's actual usage of its specific Google Analytics implementation; there are many other data uses for Google Analytics, but this app does not leverage them.","title":"Annotate a Fidesctl System Resource"},{"location":"tutorial/google/#check-your-progress","text":"After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-add-google-analytics tag .","title":"Check Your Progress"},{"location":"tutorial/google/#next-manage-google-analytics-with-fidesctl","text":"Google Analytics is implemented and working correctly, but - oh no! - executing nox -s fidesctl shows a failure: 1 2 3 4 5 6 7 8 { \"fides_key\" : \"4e739b1b_732e_43b1_8747_e833905dfc4c_1635789050\" , \"status\" : \"FAIL\" , \"details\" : [ \"Declaration (Derive user geographic location) of System (google_analytics_system) failed Rule (Minimize User Identifiable Data) from Policy (flaskr_policy)\" ], \"message\" : null } In the final step, enable the fidesctl policy already in place to pass by updating Google Analytics .","title":"Next: Manage Google Analytics with Fidesctl"},{"location":"tutorial/pass/","text":"Manage Google Analytics with Fidesctl By default, Google Analytics disables \"IP Anonymization\" (see the documentation for more information). The \"Minimize User Identifiable Data\" fidesctl Policy resource created earlier in this tutorial is configured to reject data collection of this nature. POP QUIZ There are two options to remedy this situation, and to get the nox -s fidesctl command to pass. Which option is best? Modify the \"Minimize User Identifiable Data\" policy resource to accept data collection of this nature Modify the Google Analytics implementation such that it becomes compliant with the \"Minimize User Identifiable Data\" policy Click to see the correct answer Option 2 is the best path forward: the Google Analytics implementation should be modified, not the \"Minimize User Identifiable Data\" policy resource. The policy resource's configuration is dictated by the app's Privacy Policy, and changes could lead to larger compliance issues throughout the system. Enable IP Anonymization Open the flaskr/templates/base.html file in your favorite editor, and add the following line just above the closing <script> tag in the Google Analytics script: 1 2 3 4 5 6 7 8 9 10 11 {% if config['GOOGLE_ANALYTICS_ID'] %} <!-- Global site tag (gtag.js) - Google Analytics --> <script async src=\"https://www.googletagmanager.com/gtag/js?id={{ config['GOOGLE_ANALYTICS_ID'] }}\"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\"js\", new Date()); gtag(\"config\", \"{{ config['GOOGLE_ANALYTICS_ID'] }}\"); + gtag(\"config\", \"{{ config['GOOGLE_ANALYTICS_ID'] }}\", { 'anonymize_ip': true }); </script> {% endif %} Update the Google Analytics System Resource Now that the data collection practices in the Google Analytics script have changed, the associated fidesctl System resource should be updated accordingly. Open the fides_resources/google_analytics_system.yml file in your favorite editor, and modify the last line (the data_qualifier configuration) so that it reads: 1 data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized By removing the final identified key of the Fides taxonomy, the updated nature of the data collection practices used in this System resource now aligns with the actual behavior of the updated Google Analytics script. Evaluate the Fidesctl Policies Execute the nox -s fidesctl command one final time. You should see the following output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Evaluating policy with fidesctl... ./venv/bin/fidesctl evaluate --dry fides_resources Loading resource manifests from: fides_resources Taxonomy successfully created. ---------- Processing dataset resources... WOULD CREATE 0 dataset resources. WOULD UPDATE 0 dataset resources. WOULD SKIP 1 dataset resources. ---------- Processing system resources... WOULD CREATE 0 system resources. WOULD UPDATE 1 system resources. WOULD SKIP 1 system resources. ---------- Processing policy resources... WOULD CREATE 0 policy resources. WOULD UPDATE 0 policy resources. WOULD SKIP 1 policy resources. ---------- Loading resource manifests from: fides_resources Taxonomy successfully created. Evaluating the following policies: flaskr_policy ---------- Checking for missing resources... Executing evaluations... Evaluation passed! The fidesctl policy evaluation passes! Check Your Progress After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-demo tag.","title":"Manage Google Analytics with Fides"},{"location":"tutorial/pass/#manage-google-analytics-with-fidesctl","text":"By default, Google Analytics disables \"IP Anonymization\" (see the documentation for more information). The \"Minimize User Identifiable Data\" fidesctl Policy resource created earlier in this tutorial is configured to reject data collection of this nature.","title":"Manage Google Analytics with Fidesctl"},{"location":"tutorial/pass/#pop-quiz","text":"There are two options to remedy this situation, and to get the nox -s fidesctl command to pass. Which option is best? Modify the \"Minimize User Identifiable Data\" policy resource to accept data collection of this nature Modify the Google Analytics implementation such that it becomes compliant with the \"Minimize User Identifiable Data\" policy Click to see the correct answer Option 2 is the best path forward: the Google Analytics implementation should be modified, not the \"Minimize User Identifiable Data\" policy resource. The policy resource's configuration is dictated by the app's Privacy Policy, and changes could lead to larger compliance issues throughout the system.","title":"POP QUIZ"},{"location":"tutorial/pass/#enable-ip-anonymization","text":"Open the flaskr/templates/base.html file in your favorite editor, and add the following line just above the closing <script> tag in the Google Analytics script: 1 2 3 4 5 6 7 8 9 10 11 {% if config['GOOGLE_ANALYTICS_ID'] %} <!-- Global site tag (gtag.js) - Google Analytics --> <script async src=\"https://www.googletagmanager.com/gtag/js?id={{ config['GOOGLE_ANALYTICS_ID'] }}\"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\"js\", new Date()); gtag(\"config\", \"{{ config['GOOGLE_ANALYTICS_ID'] }}\"); + gtag(\"config\", \"{{ config['GOOGLE_ANALYTICS_ID'] }}\", { 'anonymize_ip': true }); </script> {% endif %}","title":"Enable IP Anonymization"},{"location":"tutorial/pass/#update-the-google-analytics-system-resource","text":"Now that the data collection practices in the Google Analytics script have changed, the associated fidesctl System resource should be updated accordingly. Open the fides_resources/google_analytics_system.yml file in your favorite editor, and modify the last line (the data_qualifier configuration) so that it reads: 1 data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized By removing the final identified key of the Fides taxonomy, the updated nature of the data collection practices used in this System resource now aligns with the actual behavior of the updated Google Analytics script.","title":"Update the Google Analytics System Resource"},{"location":"tutorial/pass/#evaluate-the-fidesctl-policies","text":"Execute the nox -s fidesctl command one final time. You should see the following output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Evaluating policy with fidesctl... ./venv/bin/fidesctl evaluate --dry fides_resources Loading resource manifests from: fides_resources Taxonomy successfully created. ---------- Processing dataset resources... WOULD CREATE 0 dataset resources. WOULD UPDATE 0 dataset resources. WOULD SKIP 1 dataset resources. ---------- Processing system resources... WOULD CREATE 0 system resources. WOULD UPDATE 1 system resources. WOULD SKIP 1 system resources. ---------- Processing policy resources... WOULD CREATE 0 policy resources. WOULD UPDATE 0 policy resources. WOULD SKIP 1 policy resources. ---------- Loading resource manifests from: fides_resources Taxonomy successfully created. Evaluating the following policies: flaskr_policy ---------- Checking for missing resources... Executing evaluations... Evaluation passed! The fidesctl policy evaluation passes!","title":"Evaluate the Fidesctl Policies"},{"location":"tutorial/pass/#check-your-progress","text":"After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-demo tag.","title":"Check Your Progress"},{"location":"tutorial/policy/","text":"Write a Policy Fidesctl's privacy declarations provide rich metadata about systems, the data categories they process, and the uses of that data. Policies allow you to enforce constraints on these declarations and decide what combinations to allow or reject at your company, thus providing a layer of automation to control data privacy at the source. Define a single Policy by creating a flaskr_policy.yml file in the fides_resources directory. For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 policy : - fides_key : flaskr_policy name : Flaskr Privacy Policy description : A privacy policy for the example Flask app rules : - fides_key : minimize_user_identifiable_data name : Minimize User Identifiable Data description : Reject collecting any user identifiable data for uses other than system operations data_categories : matches : ANY values : - user.provided.identifiable - user.derived.identifiable data_uses : matches : ANY values : - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - fides_key : reject_sensitive_data name : Reject Sensitive Data description : Reject collecting sensitive user data for any use data_categories : matches : ANY values : - user.provided.identifiable.biometric - user.provided.identifiable.childrens - user.provided.identifiable.genetic - user.provided.identifiable.health_and_medical - user.provided.identifiable.political_opinion - user.provided.identifiable.race - user.provided.identifiable.religious_belief - user.provided.identifiable.sexual_orientation data_uses : matches : ANY values : - provide - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated This demo application is built without any real controls on user data, so the Fides policy is relatively restrictive. The two rules can be interpreted respectfully as: Do not use identifiable data for anything other than the app's primary functions (after all, it's just a demo app!). Do not collect any sensitive data at all. As a safe default, this is the type of policy you might add to all projects. Later, you can make exceptions (if you are working on a project that requires these categories). Understanding the Policy The purpose of a privacy policy is to state what types of data are allowed for certain means of use. In fidesctl, a Policy is comprised of rules against which the system's privacy declarations are evaluated. Policies will evaluate the data subjects, data category, and data qualifier values against data use cases. This generates a boolean output to either allow or reject the process from proceeding. Policies use the following attributes: Name Type Description fides_key FidesKey An identifier label that must be unique within your organization. A fides_key can only contain alphanumeric characters and _ . data_categories List[DataRule] The types of sensitive data as defined by the taxonomy data_uses List[DataRule] The various categories of data processing and operations within your organization data_subjects List[DataRule] The individual persons to whom you data rule pertains data_qualifier String The acceptable or non-acceptable level of deidentification For more detail on Policy resources, see the full Policy resource documentation . Maintaining a Policy As global privacy laws change and businesses scale, a company's policies will evolve with them. We recommend that updating this resource file becomes a regular part of the development planning process when building a new feature. Check Your Progress After making the above changes and the changes in the previous two steps, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-manifests tag . Next: Add Google Analytics Improve usage telemetry for this project by adding the nefarious tracker, Google Analytics .","title":"Write a Policy"},{"location":"tutorial/policy/#write-a-policy","text":"Fidesctl's privacy declarations provide rich metadata about systems, the data categories they process, and the uses of that data. Policies allow you to enforce constraints on these declarations and decide what combinations to allow or reject at your company, thus providing a layer of automation to control data privacy at the source. Define a single Policy by creating a flaskr_policy.yml file in the fides_resources directory. For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 policy : - fides_key : flaskr_policy name : Flaskr Privacy Policy description : A privacy policy for the example Flask app rules : - fides_key : minimize_user_identifiable_data name : Minimize User Identifiable Data description : Reject collecting any user identifiable data for uses other than system operations data_categories : matches : ANY values : - user.provided.identifiable - user.derived.identifiable data_uses : matches : ANY values : - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - fides_key : reject_sensitive_data name : Reject Sensitive Data description : Reject collecting sensitive user data for any use data_categories : matches : ANY values : - user.provided.identifiable.biometric - user.provided.identifiable.childrens - user.provided.identifiable.genetic - user.provided.identifiable.health_and_medical - user.provided.identifiable.political_opinion - user.provided.identifiable.race - user.provided.identifiable.religious_belief - user.provided.identifiable.sexual_orientation data_uses : matches : ANY values : - provide - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated This demo application is built without any real controls on user data, so the Fides policy is relatively restrictive. The two rules can be interpreted respectfully as: Do not use identifiable data for anything other than the app's primary functions (after all, it's just a demo app!). Do not collect any sensitive data at all. As a safe default, this is the type of policy you might add to all projects. Later, you can make exceptions (if you are working on a project that requires these categories).","title":"Write a Policy"},{"location":"tutorial/policy/#understanding-the-policy","text":"The purpose of a privacy policy is to state what types of data are allowed for certain means of use. In fidesctl, a Policy is comprised of rules against which the system's privacy declarations are evaluated. Policies will evaluate the data subjects, data category, and data qualifier values against data use cases. This generates a boolean output to either allow or reject the process from proceeding. Policies use the following attributes: Name Type Description fides_key FidesKey An identifier label that must be unique within your organization. A fides_key can only contain alphanumeric characters and _ . data_categories List[DataRule] The types of sensitive data as defined by the taxonomy data_uses List[DataRule] The various categories of data processing and operations within your organization data_subjects List[DataRule] The individual persons to whom you data rule pertains data_qualifier String The acceptable or non-acceptable level of deidentification For more detail on Policy resources, see the full Policy resource documentation .","title":"Understanding the Policy"},{"location":"tutorial/policy/#maintaining-a-policy","text":"As global privacy laws change and businesses scale, a company's policies will evolve with them. We recommend that updating this resource file becomes a regular part of the development planning process when building a new feature.","title":"Maintaining a Policy"},{"location":"tutorial/policy/#check-your-progress","text":"After making the above changes and the changes in the previous two steps, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-manifests tag .","title":"Check Your Progress"},{"location":"tutorial/policy/#next-add-google-analytics","text":"Improve usage telemetry for this project by adding the nefarious tracker, Google Analytics .","title":"Next: Add Google Analytics"},{"location":"tutorial/system/","text":"Annotate the System Now that you've built out the underlying database that describes how and what type of data is stored, include the database in application-level \"systems\", another critical fidesctl resource. This app contains a single Flaskr Web Application system resource. Create a system resource to annotate it by adding a flaskr_system.yml file to the fides_resources directory. Writing a Fides privacy declaration requires answering the questions: \"What data is this system processing?\" , \"Why is the system processing this data?\" , \"Whose data is involved?\" , and \"How is the data protected?\" Fides answers these questions with a privacy_declaration that describes the data categories, use, subjects, and qualifier. This application is quite simple, so it only has a single use: to provide the service to users. In order to do so, it requires some identifiable data (name, email, contact, etc.) and it derives some data as well (unique IDs). For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 system : - fides_key : flaskr_system name : Flaskr Web Application description : An example Flask web app that simulates an e-commerce application system_type : Application privacy_declarations : - name : Provide e-commerce operations to example customers data_categories : - user.provided.identifiable - user.derived.identifiable - system.operations data_use : provide.service.operations data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified dataset_references : - flaskr_postgres_dataset Privacy Declarations can be read colloquially as \"This system uses sensitive data types of data_categories for data_subjects with the purpose of data_use at a deidentification level of data_qualifier \". In a production app, create as many systems as are necessary to cover all relevant business applications. Understanding Systems In fidesctl, Systems are used to model things that process data for organizations (applications, services, 3rd party APIs, etc.) and describe how these datasets are used for business functions. These groupings are not mutually exclusive; they answer \" How and why are these datasets being used? \" The System resource groups the lowest level of data (your datasets) with your business use cases, and associates qualitative attributes describing the type of data being used. Systems use the following attributes: Name Type Description data_categories List[FidesKey] The types of sensitive data as defined by the taxonomy data_subjects List[FidesKey] The individual persons whose data resides in your datasets data_use List[FidesKey] The various categories of data processing and operations within your organization data_qualifier List[FidesKey] The level of deidentification for the dataset dataset_refereneces List[FidesKey] The fides_key (s) of the dataset fields used in this Privacy Declaration For more detail on System resources, see the full System resource documentation . Maintaining a System Resource As use cases evolve, your systems' data subjects, data categories, and data uses will change as well. We recommend that updating this resource file becomes a regular part of the development planning process when building a new feature. PRO TIP As more systems are added to a data ecosystem, consider grouping systems into another Fides resource type, called a Registry . Next: Write a Policy With database and system resources declared, you must now enforce your data constraints by writing a Policy .","title":"Annotate the System"},{"location":"tutorial/system/#annotate-the-system","text":"Now that you've built out the underlying database that describes how and what type of data is stored, include the database in application-level \"systems\", another critical fidesctl resource. This app contains a single Flaskr Web Application system resource. Create a system resource to annotate it by adding a flaskr_system.yml file to the fides_resources directory. Writing a Fides privacy declaration requires answering the questions: \"What data is this system processing?\" , \"Why is the system processing this data?\" , \"Whose data is involved?\" , and \"How is the data protected?\" Fides answers these questions with a privacy_declaration that describes the data categories, use, subjects, and qualifier. This application is quite simple, so it only has a single use: to provide the service to users. In order to do so, it requires some identifiable data (name, email, contact, etc.) and it derives some data as well (unique IDs). For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 system : - fides_key : flaskr_system name : Flaskr Web Application description : An example Flask web app that simulates an e-commerce application system_type : Application privacy_declarations : - name : Provide e-commerce operations to example customers data_categories : - user.provided.identifiable - user.derived.identifiable - system.operations data_use : provide.service.operations data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified dataset_references : - flaskr_postgres_dataset Privacy Declarations can be read colloquially as \"This system uses sensitive data types of data_categories for data_subjects with the purpose of data_use at a deidentification level of data_qualifier \". In a production app, create as many systems as are necessary to cover all relevant business applications.","title":"Annotate the System"},{"location":"tutorial/system/#understanding-systems","text":"In fidesctl, Systems are used to model things that process data for organizations (applications, services, 3rd party APIs, etc.) and describe how these datasets are used for business functions. These groupings are not mutually exclusive; they answer \" How and why are these datasets being used? \" The System resource groups the lowest level of data (your datasets) with your business use cases, and associates qualitative attributes describing the type of data being used. Systems use the following attributes: Name Type Description data_categories List[FidesKey] The types of sensitive data as defined by the taxonomy data_subjects List[FidesKey] The individual persons whose data resides in your datasets data_use List[FidesKey] The various categories of data processing and operations within your organization data_qualifier List[FidesKey] The level of deidentification for the dataset dataset_refereneces List[FidesKey] The fides_key (s) of the dataset fields used in this Privacy Declaration For more detail on System resources, see the full System resource documentation .","title":"Understanding Systems"},{"location":"tutorial/system/#maintaining-a-system-resource","text":"As use cases evolve, your systems' data subjects, data categories, and data uses will change as well. We recommend that updating this resource file becomes a regular part of the development planning process when building a new feature. PRO TIP As more systems are added to a data ecosystem, consider grouping systems into another Fides resource type, called a Registry .","title":"Maintaining a System Resource"},{"location":"tutorial/system/#next-write-a-policy","text":"With database and system resources declared, you must now enforce your data constraints by writing a Policy .","title":"Next: Write a Policy"},{"location":"ui/datasets/","text":"Managing Datasets The Datasets panel allows you to easily view, add, edit, and configure your existing datasets and their connections. Adding a dataset Datasets can be added to the Fides UI by connecting to your databases, or by uploading a pre-configured dataset YAML. An empty state label on the Datasets panel shows no datasets have been configured. To add a new dataset, select Create new dataset from the Datasets panel. You will then be given a list of options for creating your new dataset: Fides provides two options for creating new datasets: uploading a YAML file , or connecting to a database , each of which are outlined below. Upload a dataset YAML Preexisting dataset configurations can be easily uploaded using the built-in uploader. These YAML configuration files might have come from a previous Fides installation , or a support engineer. To upload a new dataset, select the Upload a new dataset YAML option. Paste the context of your YAML file into the provided text box, and select Create dataset. Fides will upload and store your file for use with the rest of the Fides UI. Connect to a database To generate a dataset by connecting directly to a database, select Connect a database using a connection URL . You will need to provide your database type from the dropdown, as well as the database URL string. Once the required information is entered, select Create database . Fides will display a success notification when the process is completed. Load a dataset To view the details of an existing dataset, highlight the row of the dataset you would like to view, and select Load dataset. Viewing a dataset gives you access to additional information and details: Datasets may be modified and deleted from this window. Modifying a dataset Datasets can be modified at both the collection (top-level) and field levels, allowing you to edit and customize your labels, descriptions, and data categories. Modifying fields Selecting any field will bring up a side panel where that field's information may be edited. You may edit the field's description, identifiability, and modify the data categories it belongs to. To save your changes, select Save , and Fides will apply them. Modifying a collection The Modify collection button allows you to change the collection's description, identifiability, and any top-level data categories that pertain to the data it contains. To save your changes, select Save , and Fides will apply them. Delete a dataset or field A dataset may be deleted by selecting Modify collection , and finding the trash bin icon beside the dataset's name. You will need to provide and confirm the dataset's name in order to delete it. Deleting a dataset cannot be undone. To delete a field, find the trash bin icon beside the field's name when modifying it . Enter and confirm the field's name to delete it. Deleting a field cannot be undone.","title":"Manage Datasets"},{"location":"ui/datasets/#managing-datasets","text":"The Datasets panel allows you to easily view, add, edit, and configure your existing datasets and their connections.","title":"Managing Datasets"},{"location":"ui/datasets/#adding-a-dataset","text":"Datasets can be added to the Fides UI by connecting to your databases, or by uploading a pre-configured dataset YAML. An empty state label on the Datasets panel shows no datasets have been configured. To add a new dataset, select Create new dataset from the Datasets panel. You will then be given a list of options for creating your new dataset: Fides provides two options for creating new datasets: uploading a YAML file , or connecting to a database , each of which are outlined below.","title":"Adding a dataset"},{"location":"ui/datasets/#upload-a-dataset-yaml","text":"Preexisting dataset configurations can be easily uploaded using the built-in uploader. These YAML configuration files might have come from a previous Fides installation , or a support engineer. To upload a new dataset, select the Upload a new dataset YAML option. Paste the context of your YAML file into the provided text box, and select Create dataset. Fides will upload and store your file for use with the rest of the Fides UI.","title":"Upload a dataset YAML"},{"location":"ui/datasets/#connect-to-a-database","text":"To generate a dataset by connecting directly to a database, select Connect a database using a connection URL . You will need to provide your database type from the dropdown, as well as the database URL string. Once the required information is entered, select Create database . Fides will display a success notification when the process is completed.","title":"Connect to a database"},{"location":"ui/datasets/#load-a-dataset","text":"To view the details of an existing dataset, highlight the row of the dataset you would like to view, and select Load dataset. Viewing a dataset gives you access to additional information and details: Datasets may be modified and deleted from this window.","title":"Load a dataset"},{"location":"ui/datasets/#modifying-a-dataset","text":"Datasets can be modified at both the collection (top-level) and field levels, allowing you to edit and customize your labels, descriptions, and data categories.","title":"Modifying a dataset"},{"location":"ui/datasets/#modifying-fields","text":"Selecting any field will bring up a side panel where that field's information may be edited. You may edit the field's description, identifiability, and modify the data categories it belongs to. To save your changes, select Save , and Fides will apply them.","title":"Modifying fields"},{"location":"ui/datasets/#modifying-a-collection","text":"The Modify collection button allows you to change the collection's description, identifiability, and any top-level data categories that pertain to the data it contains. To save your changes, select Save , and Fides will apply them.","title":"Modifying a collection"},{"location":"ui/datasets/#delete-a-dataset-or-field","text":"A dataset may be deleted by selecting Modify collection , and finding the trash bin icon beside the dataset's name. You will need to provide and confirm the dataset's name in order to delete it. Deleting a dataset cannot be undone. To delete a field, find the trash bin icon beside the field's name when modifying it . Enter and confirm the field's name to delete it. Deleting a field cannot be undone.","title":"Delete a dataset or field"},{"location":"ui/datastores/","text":"Managing Datastores Datastores represent connections to third party applications, databases and datasets, or manual storage locations. Viewing Datastores All currently configured datastores will appear in the paginated Datastore Connections panel. Search options are available to filter the datastore list. Active datastores are included when fulfilling privacy requests. Disabled datastores have their connection information saved, but are not included when privacy requests are executed. Panel Options Option Description Search Retrieve a datastore by name. Datastore Type Filter datastores by type: SaaS, Postgres, Mongo, etc. System Type Filter datastores by system: SaaS, Database, or Manual. Testing Status Filter stores by the result of their last test: Passed, Failed, or Untested. Status Filter datastores by status: Active or Disabled. Testing datastores Each configured datastore includes an option to Test its connection. Fidesops will record the last tested time to the datastore's card, and update the current connection status. Green connections have passed their most recent test. Red connections have failed. Grey connections have not been tested. Disabling and deleting datastores Selecting the three dots menu [...] beside a datastore's connection status will bring up Disable and Delete options for that datastore. Selecting either Disable or Delete will display a warning to confirm the action. Deleted datastores will have their connection information removed entirely from fides.api, while Disabled datastores may be enabled again from the same menu at a later date.","title":"Manage Datastores"},{"location":"ui/datastores/#managing-datastores","text":"Datastores represent connections to third party applications, databases and datasets, or manual storage locations.","title":"Managing Datastores"},{"location":"ui/datastores/#viewing-datastores","text":"All currently configured datastores will appear in the paginated Datastore Connections panel. Search options are available to filter the datastore list. Active datastores are included when fulfilling privacy requests. Disabled datastores have their connection information saved, but are not included when privacy requests are executed.","title":"Viewing Datastores"},{"location":"ui/datastores/#panel-options","text":"Option Description Search Retrieve a datastore by name. Datastore Type Filter datastores by type: SaaS, Postgres, Mongo, etc. System Type Filter datastores by system: SaaS, Database, or Manual. Testing Status Filter stores by the result of their last test: Passed, Failed, or Untested. Status Filter datastores by status: Active or Disabled.","title":"Panel Options"},{"location":"ui/datastores/#testing-datastores","text":"Each configured datastore includes an option to Test its connection. Fidesops will record the last tested time to the datastore's card, and update the current connection status. Green connections have passed their most recent test. Red connections have failed. Grey connections have not been tested.","title":"Testing datastores"},{"location":"ui/datastores/#disabling-and-deleting-datastores","text":"Selecting the three dots menu [...] beside a datastore's connection status will bring up Disable and Delete options for that datastore. Selecting either Disable or Delete will display a warning to confirm the action. Deleted datastores will have their connection information removed entirely from fides.api, while Disabled datastores may be enabled again from the same menu at a later date.","title":"Disabling and deleting datastores"},{"location":"ui/deployment/","text":"Deployment","title":"Deployment"},{"location":"ui/deployment/#deployment","text":"","title":"Deployment"},{"location":"ui/overview/","text":"Fides UI Fides provides several user interfaces to assist in receiving and reviewing privacy requests, including options for managing your systems, datasets, and configuration settings. The Privacy Center and Admin UI work together to allow users to submit data subject requests (DSRs), which can then be fulfilled either automatically, or by privacy administrators. Admin UI The Admin UI organizes processes like fulfilling data subject requests , creating Fides resources, and managing user access into a single control panel. Once configured, the Admin UI allows authorized users to manage policies, update datasets , and customize your Fides taxonomy . Privacy Center The Fides Privacy Center is a configurable webpage that allows your users to submit data access or deletion requests. Requests submitted through the Privacy Center are available for review in the Admin UI, and are processed according to your policy execution rules. Configuration Wizard The Fides Configuration Wizard provides a guided walkthrough for configuring Fides, connecting your infrastructure, and building your first data map. The Configuration Wizard covers an introduction to understanding privacy engineering fundamentals, as well as explaining Fides' terminology and resources. Access the UI With Fides deployed, the hosted UI is available at http://{server_url}/ (e.g. http://localhost:8080/ ) automatically. Review your root user configuration to verify your access credentials.","title":"Overview"},{"location":"ui/overview/#fides-ui","text":"Fides provides several user interfaces to assist in receiving and reviewing privacy requests, including options for managing your systems, datasets, and configuration settings. The Privacy Center and Admin UI work together to allow users to submit data subject requests (DSRs), which can then be fulfilled either automatically, or by privacy administrators.","title":"Fides UI"},{"location":"ui/overview/#admin-ui","text":"The Admin UI organizes processes like fulfilling data subject requests , creating Fides resources, and managing user access into a single control panel. Once configured, the Admin UI allows authorized users to manage policies, update datasets , and customize your Fides taxonomy .","title":"Admin UI"},{"location":"ui/overview/#privacy-center","text":"The Fides Privacy Center is a configurable webpage that allows your users to submit data access or deletion requests. Requests submitted through the Privacy Center are available for review in the Admin UI, and are processed according to your policy execution rules.","title":"Privacy Center"},{"location":"ui/overview/#configuration-wizard","text":"The Fides Configuration Wizard provides a guided walkthrough for configuring Fides, connecting your infrastructure, and building your first data map. The Configuration Wizard covers an introduction to understanding privacy engineering fundamentals, as well as explaining Fides' terminology and resources.","title":"Configuration Wizard"},{"location":"ui/overview/#access-the-ui","text":"With Fides deployed, the hosted UI is available at http://{server_url}/ (e.g. http://localhost:8080/ ) automatically. Review your root user configuration to verify your access credentials.","title":"Access the UI"},{"location":"ui/privacy_center/","text":"Privacy Center The fidesops Privacy Center is a configurable webpage where users can request to download or delete their data. Configuration The fidesops Privacy Center's text and actions are managed by a config.json file in the fidesops /privacy-center/config directory. config.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 { \"title\" : \"Take control of your data\" , \"description\" : \"When you use our services, you\u2019re trusting us with your information. We understand this is a big responsibility and work hard to protect your information and put you in control.\" , \"server_url_development\" : \"http://localhost:8080/api/v1\" , \"server_url_production\" : \"https://<$YOUR_SERVER_URL>/api/v1\" , \"logo_path\" : \"/logo.svg\" , \"actions\" : [ { \"policy_key\" : \"download\" , \"icon_path\" : \"/download.svg\" , \"title\" : \"Download your data\" , \"description\" : \"We will email you a report of the data related to your account.\" , \"identity_inputs\" : { \"name\" : \"optional\" , \"email\" : \"required\" , \"phone\" : \"optional\" } }, { \"policy_key\" : \"delete\" , \"icon_path\" : \"/delete.svg\" , \"title\" : \"Delete your data\" , \"description\" : \"We will delete all of your account data. This action cannot be undone.\" , \"identity_inputs\" : { \"name\" : \"optional\" , \"email\" : \"required\" , \"phone\" : \"optional\" } } ] } Key Description title and dscription Text fields to override the default text of either the main portal, or the associated action. server_url_development The Fides server URL to use for development deployments. server_url_production The Fides server URL to use for production deployments. logo_path The relative path to a brand or site logo to replace the default. actions A list of action objects , each of which represent a new tile available in the portal, and are associated to a single fidesops policy. policy_key The key of the policy to use for this action. icon_path The relative path of an icon to replace the defaults. identity_inputs The list of personally identifiable information required by an action. Actions Actions represent available privacy rights executable from the Privacy Center. The provided config.json includes Download and Delete default, representing common requests to access or remove data under most privacy regulations. Each action is associated with a fidesops policy key , which defines the policy executed when the DSR is approved. Additional actions can be added to this list, and removed at any time. Styling Any overrides for CSS styling can be included in a config.css file in the /privacy-center/config directory.","title":"Privacy Center"},{"location":"ui/privacy_center/#privacy-center","text":"The fidesops Privacy Center is a configurable webpage where users can request to download or delete their data.","title":"Privacy Center"},{"location":"ui/privacy_center/#configuration","text":"The fidesops Privacy Center's text and actions are managed by a config.json file in the fidesops /privacy-center/config directory. config.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 { \"title\" : \"Take control of your data\" , \"description\" : \"When you use our services, you\u2019re trusting us with your information. We understand this is a big responsibility and work hard to protect your information and put you in control.\" , \"server_url_development\" : \"http://localhost:8080/api/v1\" , \"server_url_production\" : \"https://<$YOUR_SERVER_URL>/api/v1\" , \"logo_path\" : \"/logo.svg\" , \"actions\" : [ { \"policy_key\" : \"download\" , \"icon_path\" : \"/download.svg\" , \"title\" : \"Download your data\" , \"description\" : \"We will email you a report of the data related to your account.\" , \"identity_inputs\" : { \"name\" : \"optional\" , \"email\" : \"required\" , \"phone\" : \"optional\" } }, { \"policy_key\" : \"delete\" , \"icon_path\" : \"/delete.svg\" , \"title\" : \"Delete your data\" , \"description\" : \"We will delete all of your account data. This action cannot be undone.\" , \"identity_inputs\" : { \"name\" : \"optional\" , \"email\" : \"required\" , \"phone\" : \"optional\" } } ] } Key Description title and dscription Text fields to override the default text of either the main portal, or the associated action. server_url_development The Fides server URL to use for development deployments. server_url_production The Fides server URL to use for production deployments. logo_path The relative path to a brand or site logo to replace the default. actions A list of action objects , each of which represent a new tile available in the portal, and are associated to a single fidesops policy. policy_key The key of the policy to use for this action. icon_path The relative path of an icon to replace the defaults. identity_inputs The list of personally identifiable information required by an action.","title":"Configuration"},{"location":"ui/privacy_center/#actions","text":"Actions represent available privacy rights executable from the Privacy Center. The provided config.json includes Download and Delete default, representing common requests to access or remove data under most privacy regulations. Each action is associated with a fidesops policy key , which defines the policy executed when the DSR is approved. Additional actions can be added to this list, and removed at any time.","title":"Actions"},{"location":"ui/privacy_center/#styling","text":"Any overrides for CSS styling can be included in a config.css file in the /privacy-center/config directory.","title":"Styling"},{"location":"ui/subject_requests/","text":"Subject Requests The Fides Admin UI is designed to provide at-a-glance access to submitted subject requests. The Subject Request panel provides search and sort capabilities, quick approve and deny functions, and in-depth details on individual request histories and statuses. Panel options Option Description Status Requests can be filtered by their current status: Error , Denied , In Progress , New , Canceled , and Complete . Search The search bar filters on a given field: status, reviewer, etc. Date Filter Retrieve requests received within a certain date window. Reveal PII Toggling Reveal PII will display all personal information for the shown requests. Download Download a .csv of the shown requests. Clear Remove all search options and filters. Approve or deny requests Hovering over a request row will provide access to the approve and deny options for that request. Approving a request will log the action, the approver's account, and begin the process of executing the request based on the associated policy . Denying a request allows the user to input a denial reason before confirming the action. View request details Double-clicking a request row will display the request detail page, which allows access to additional information about the request, including the request ID, request type, and current status. Requests with a status of Error can also be retried from this panel by selecting the Retry button. The bottom of the Request Details panel displays the selected request's full event history. Selecting View Details on any event displays a summary of the event. View Log displays a detailed event log, which includes Fides' traversal through third-party connections and collections.","title":"Subject Requests"},{"location":"ui/subject_requests/#subject-requests","text":"The Fides Admin UI is designed to provide at-a-glance access to submitted subject requests. The Subject Request panel provides search and sort capabilities, quick approve and deny functions, and in-depth details on individual request histories and statuses.","title":"Subject Requests"},{"location":"ui/subject_requests/#panel-options","text":"Option Description Status Requests can be filtered by their current status: Error , Denied , In Progress , New , Canceled , and Complete . Search The search bar filters on a given field: status, reviewer, etc. Date Filter Retrieve requests received within a certain date window. Reveal PII Toggling Reveal PII will display all personal information for the shown requests. Download Download a .csv of the shown requests. Clear Remove all search options and filters.","title":"Panel options"},{"location":"ui/subject_requests/#approve-or-deny-requests","text":"Hovering over a request row will provide access to the approve and deny options for that request. Approving a request will log the action, the approver's account, and begin the process of executing the request based on the associated policy . Denying a request allows the user to input a denial reason before confirming the action.","title":"Approve or deny requests"},{"location":"ui/subject_requests/#view-request-details","text":"Double-clicking a request row will display the request detail page, which allows access to additional information about the request, including the request ID, request type, and current status. Requests with a status of Error can also be retried from this panel by selecting the Retry button. The bottom of the Request Details panel displays the selected request's full event history. Selecting View Details on any event displays a summary of the event. View Log displays a detailed event log, which includes Fides' traversal through third-party connections and collections.","title":"View request details"},{"location":"ui/user_management/","text":"User Management Fides users can be managed from the built-in control panel to create new accounts, and organize individual account access and permissions.. Managing Users from the UI The User Management panel displays a view of all users within the system, and provides a search bar for retrieving users by username. Creating New Users The Add New User button will walk through creating a new user. Managing User Privileges New users can be created with a series of privileges, or permissions, to allow or restrict their access to individual parts of your Fides configuration. Privileges Privileges represent individual user permissions. Ensure each user is created with the permissions applicable for their role. Privilege Description View datastore connections Allows the user to view, but not edit, any existing connections to your datastores. Create or Update datastore connections Allows the user to create new datastore connections, and update existing connections. Delete datastore connections Allows the user to delete existing datastore connections, removing them entirely from Fides. View policies Allows the user to view existing Fides policies. Create policies Allows the user to create new Fides policies. View users Allows the user to view the User Management panel. Create users Allows the user to create new users from the User Management panel. View roles Allows the user to view, but not edit, existing roles. Create roles Allows the user to create new roles. Editing Existing Users Existing users can be edited by selecting the \"Edit\" button from the side of the user row. Users may also be deleted from this drop-down menu. Note that an individual's username may not be changed.","title":"Manage Users"},{"location":"ui/user_management/#user-management","text":"Fides users can be managed from the built-in control panel to create new accounts, and organize individual account access and permissions..","title":"User Management"},{"location":"ui/user_management/#managing-users-from-the-ui","text":"The User Management panel displays a view of all users within the system, and provides a search bar for retrieving users by username.","title":"Managing Users from the UI"},{"location":"ui/user_management/#creating-new-users","text":"The Add New User button will walk through creating a new user.","title":"Creating New Users"},{"location":"ui/user_management/#managing-user-privileges","text":"New users can be created with a series of privileges, or permissions, to allow or restrict their access to individual parts of your Fides configuration.","title":"Managing User Privileges"},{"location":"ui/user_management/#privileges","text":"Privileges represent individual user permissions. Ensure each user is created with the permissions applicable for their role. Privilege Description View datastore connections Allows the user to view, but not edit, any existing connections to your datastores. Create or Update datastore connections Allows the user to create new datastore connections, and update existing connections. Delete datastore connections Allows the user to delete existing datastore connections, removing them entirely from Fides. View policies Allows the user to view existing Fides policies. Create policies Allows the user to create new Fides policies. View users Allows the user to view the User Management panel. Create users Allows the user to create new users from the User Management panel. View roles Allows the user to view, but not edit, existing roles. Create roles Allows the user to create new roles.","title":"Privileges"},{"location":"ui/user_management/#editing-existing-users","text":"Existing users can be edited by selecting the \"Edit\" button from the side of the user row. Users may also be deleted from this drop-down menu. Note that an individual's username may not be changed.","title":"Editing Existing Users"},{"location":"ui/wizard/","text":"Configuration Wizard The Configuration Wizard is designed to simplify Fides setup. Along with building your first data map, using the Config Wizard will provide you with a step-by-step introduction to both privacy engineering fundamentals and Fides terminology. To get started, select Config Wizard from the Admin UI navigation bar. Step 1: Add your business or organization Organization or business information is used to build your data map for reporting purposes. Your organization name must be provided, along with a description of the company. Step 2: Add a system Systems are anything that might store or process data in your information, and represent the building blocks of your data map. These might include web applications, databases, and data warehouses. Systems can be added with automated scanning tools, or manually. Automatic scans Scanning allows you to connect to either your AWS cloud infrastructure or your Okta instance and automatically identify systems that should be on your data map. Support for additional systems (e.g. Google, Microsoft Azure, Digital Ocean) is planned shortly. Add a system manually Systems can be added manually by entering information about them directly. Manual system creation allows you to include information not easily scannable by Fides in your data map. Step 3: Scan your resources Authentication credentials must be provided for Fides to connect to your cloud infrastructure or sign-on provider. These credentials will be used to create a list of all systems that may contain personal data. Authenticate with AWS To authenticate with AWS, you must provide an Access Key ID, associated secret, and the AWS region your infrastructure is located in. Fides should be granted enough permissions to scan your AWS resources via an appropriate IAM policy. Authenticate with Okta Fides requires a token to authenticate with Okta. You can find instructions here on how to retrieve a suitable token from your Okta administration panel. Step 4: View your results Once your systems have been scanned and your resources added, you will be provided with a list of all the systems found which might contain personal data. Individual systems can be kept and registered by selecting their associated check box. To register all systems, select the checkbox at the top of the list. Step 5: Describe your systems Describing your systems involves declaring their privacy characteristics. This description includes what data is being stored, how the data is being processed, and for what purpose the data is being kept. You can add multiple declarations, and will have the opportunity to review the information you've provided before registering the system with Fides. Step 6: View your data map Congratulations! You have now provided everything Fides needs to build a data map of your systems and resources. From here, you can extend this map by scanning and adding additional systems.","title":"Configuration Wizard"},{"location":"ui/wizard/#configuration-wizard","text":"The Configuration Wizard is designed to simplify Fides setup. Along with building your first data map, using the Config Wizard will provide you with a step-by-step introduction to both privacy engineering fundamentals and Fides terminology. To get started, select Config Wizard from the Admin UI navigation bar.","title":"Configuration Wizard"},{"location":"ui/wizard/#step-1-add-your-business-or-organization","text":"Organization or business information is used to build your data map for reporting purposes. Your organization name must be provided, along with a description of the company.","title":"Step 1: Add your business or organization"},{"location":"ui/wizard/#step-2-add-a-system","text":"Systems are anything that might store or process data in your information, and represent the building blocks of your data map. These might include web applications, databases, and data warehouses. Systems can be added with automated scanning tools, or manually.","title":"Step 2: Add a system"},{"location":"ui/wizard/#automatic-scans","text":"Scanning allows you to connect to either your AWS cloud infrastructure or your Okta instance and automatically identify systems that should be on your data map. Support for additional systems (e.g. Google, Microsoft Azure, Digital Ocean) is planned shortly.","title":"Automatic scans"},{"location":"ui/wizard/#add-a-system-manually","text":"Systems can be added manually by entering information about them directly. Manual system creation allows you to include information not easily scannable by Fides in your data map.","title":"Add a system manually"},{"location":"ui/wizard/#step-3-scan-your-resources","text":"Authentication credentials must be provided for Fides to connect to your cloud infrastructure or sign-on provider. These credentials will be used to create a list of all systems that may contain personal data.","title":"Step 3: Scan your resources"},{"location":"ui/wizard/#authenticate-with-aws","text":"To authenticate with AWS, you must provide an Access Key ID, associated secret, and the AWS region your infrastructure is located in. Fides should be granted enough permissions to scan your AWS resources via an appropriate IAM policy.","title":"Authenticate with AWS"},{"location":"ui/wizard/#authenticate-with-okta","text":"Fides requires a token to authenticate with Okta. You can find instructions here on how to retrieve a suitable token from your Okta administration panel.","title":"Authenticate with Okta"},{"location":"ui/wizard/#step-4-view-your-results","text":"Once your systems have been scanned and your resources added, you will be provided with a list of all the systems found which might contain personal data. Individual systems can be kept and registered by selecting their associated check box. To register all systems, select the checkbox at the top of the list.","title":"Step 4: View your results"},{"location":"ui/wizard/#step-5-describe-your-systems","text":"Describing your systems involves declaring their privacy characteristics. This description includes what data is being stored, how the data is being processed, and for what purpose the data is being kept. You can add multiple declarations, and will have the opportunity to review the information you've provided before registering the system with Fides.","title":"Step 5: Describe your systems"},{"location":"ui/wizard/#step-6-view-your-data-map","text":"Congratulations! You have now provided everything Fides needs to build a data map of your systems and resources. From here, you can extend this map by scanning and adding additional systems.","title":"Step 6: View your data map"}]}